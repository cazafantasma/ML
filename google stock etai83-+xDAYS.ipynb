{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name,shift_window, normalized=0):\n",
    "    from pandas_datareader import data\n",
    "\n",
    "    # Only get the adjusted close.\n",
    "    df = data.DataReader(stock_name,\n",
    "                       start='2017-1-1',\n",
    "                       end='2018-08-20',\n",
    "                       data_source='yahoo')\n",
    "\n",
    "    df['Adj Close future'] = df['Adj Close'].shift(-shift_window)\n",
    "    #df['Difference'] = ( df['Adj Close'].shift(-shift_window) / df['Adj Close'] ) \n",
    "    #df['Difference'] = ( df['Difference'] -1 )\n",
    "    #print(df.head())\n",
    "    df['Volume'] /= 100\n",
    "    return df[:-shift_window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'TRAN.BA'\n",
    "df = get_stock_data(stock_name,10,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 High        Low       Open      Close    Volume  Adj Close  \\\n",
      "Date                                                                          \n",
      "2018-07-02  40.900002  36.700001  40.900002  38.450001  13008.83  38.450001   \n",
      "2018-07-03  44.000000  39.500000  39.500000  43.349998  11216.23  43.349998   \n",
      "2018-07-04  46.299999  42.750000  44.000000  45.849998   3616.27  45.849998   \n",
      "2018-07-05  48.000000  44.400002  45.900002  46.900002   3152.84  46.900002   \n",
      "2018-07-06  47.400002  44.049999  46.500000  46.900002   4350.53  46.900002   \n",
      "2018-07-10  49.049999  47.500000  48.000000  48.549999   4011.10  48.549999   \n",
      "2018-07-11  48.599998  45.299999  48.599998  46.549999   2142.89  46.549999   \n",
      "2018-07-12  48.000000  43.500000  46.500000  44.200001   2664.91  44.200001   \n",
      "2018-07-13  44.700001  42.250000  44.200001  44.150002   3425.94  44.150002   \n",
      "2018-07-16  44.150002  42.250000  44.150002  43.150002   2154.04  43.150002   \n",
      "2018-07-17  45.549999  42.250000  43.849998  45.150002   2532.08  45.150002   \n",
      "2018-07-18  45.500000  44.150002  45.099998  44.849998   1485.35  44.849998   \n",
      "2018-07-19  44.799999  43.750000  44.700001  44.549999    686.70  44.549999   \n",
      "2018-07-20  45.799999  44.549999  44.549999  45.549999   2345.66  45.549999   \n",
      "2018-07-23  47.500000  45.000000  45.000000  46.700001   4940.62  46.700001   \n",
      "2018-07-24  49.000000  47.700001  47.950001  48.700001   8705.30  48.700001   \n",
      "2018-07-25  52.000000  48.500000  48.500000  51.900002   2063.45  51.900002   \n",
      "2018-07-26  52.500000  49.849998  52.000000  50.349998   1434.49  50.349998   \n",
      "2018-07-27  51.500000  49.299999  50.750000  50.900002   3466.30  50.900002   \n",
      "2018-07-30  53.349998  49.599998  51.750000  52.950001   3483.24  52.950001   \n",
      "2018-07-31  53.000000  52.000000  52.000000  52.400002   8606.01  52.400002   \n",
      "2018-08-01  53.000000  51.500000  52.799999  52.200001   1028.04  52.200001   \n",
      "2018-08-02  53.000000  51.099998  52.099998  51.599998   1209.03  51.599998   \n",
      "2018-08-03  53.299999  51.599998  51.599998  53.150002   1855.86  53.150002   \n",
      "2018-08-06  53.500000  51.200001  53.299999  53.000000   2561.59  53.000000   \n",
      "\n",
      "            Adj Close future  \n",
      "Date                          \n",
      "2018-07-02         45.150002  \n",
      "2018-07-03         44.849998  \n",
      "2018-07-04         44.549999  \n",
      "2018-07-05         45.549999  \n",
      "2018-07-06         46.700001  \n",
      "2018-07-10         48.700001  \n",
      "2018-07-11         51.900002  \n",
      "2018-07-12         50.349998  \n",
      "2018-07-13         50.900002  \n",
      "2018-07-16         52.950001  \n",
      "2018-07-17         52.400002  \n",
      "2018-07-18         52.200001  \n",
      "2018-07-19         51.599998  \n",
      "2018-07-20         53.150002  \n",
      "2018-07-23         53.000000  \n",
      "2018-07-24         50.150002  \n",
      "2018-07-25         46.349998  \n",
      "2018-07-26         46.700001  \n",
      "2018-07-27         46.599998  \n",
      "2018-07-30         43.700001  \n",
      "2018-07-31         45.349998  \n",
      "2018-08-01         46.200001  \n",
      "2018-08-02         47.349998  \n",
      "2018-08-03         45.900002  \n",
      "2018-08-06         44.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  17.79999924,   16.60000038,   17.04999924,   17.54999924,\n",
       "       4638.35      ,   17.54999924,   16.95000076])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.tail(25))\n",
    "df_val = df.values\n",
    "df_val[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_NOT_USED(stock, seq_len):\n",
    "\n",
    "    data = stock\n",
    "    amount_of_features = len(data[::-1][0]) - 1\n",
    "    \n",
    "    \n",
    "    sequence_length = seq_len \n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length + 1])\n",
    "\n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1][:,-1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    print (\"x_test:\",x_test)\n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "    print (\"y_test:\",y_test)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_v2(stock, seq_len):\n",
    "\n",
    "    data_x = stock\n",
    "    data_y = stock\n",
    "    #print(\"DATA Y 0 :\",data_y)\n",
    "    print (\"Amount of features TOT :\",len(data_x[0]) )\n",
    "    data_x = np.delete(data_x,np.s_[len(stock[0])-1],axis=1)\n",
    "    data_y = np.delete(data_y,np.s_[0:len(stock[0])-1],axis=1)\n",
    "    #print(\"DATA Y :\",data_y)\n",
    "    amount_of_features = len(data_x[0]) \n",
    "    \n",
    "    print (\"Amount of features found:\",amount_of_features)\n",
    "    \n",
    "    sequence_length = seq_len \n",
    "    result_x = []\n",
    "    result_y = []\n",
    "    for index in range(len(data_x) - sequence_length ):\n",
    "        result_x.append(data_x[index: index + sequence_length + 1])\n",
    "        result_y.append(data_y[index: index + sequence_length + 1])\n",
    "\n",
    "    result_x = np.array(result_x)\n",
    "    result_y = np.array(result_y)\n",
    "    \n",
    "    row = round(0.92 * result_x.shape[0])\n",
    "    train_x = result_x[:int(row), :]\n",
    "    train_y = result_y[:int(row), :]\n",
    "    \n",
    "    x_train = train_x[:, :-1]\n",
    "    x_test = result_x[int(row):, :-1]\n",
    "   \n",
    "    y_train = train_y[:, -1]\n",
    "    y_test = result_y[int(row):, -1]\n",
    "    \n",
    "    #print (\"x_test before:\",x_test)\n",
    "    #print (\"y_test before:\",y_test)\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "    print (\"x_test:\",x_test)\n",
    "    print (\"y_test:\",y_test)\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features TOT : 7\n",
      "Amount of features found: 6\n",
      "x_test: [[[   59.95000076    57.25          59.25          58.54999924\n",
      "    6247.81          58.54999924]\n",
      "  [   60.70000076    57.65000153    58.70000076    57.90000153\n",
      "    5164.77          57.90000153]\n",
      "  [   58.5           55.15000153    57.5           55.45000076\n",
      "    3301.52          55.45000076]\n",
      "  ...\n",
      "  [   47.90000153    45.45000076    45.5           47.09999847\n",
      "   13498.93          47.09999847]\n",
      "  [   53.75          50.09999847    51.            53.45000076\n",
      "   12655.25          53.45000076]\n",
      "  [   54.            51.75          54.            52.20000076\n",
      "    1976.21          52.20000076]]\n",
      "\n",
      " [[   60.70000076    57.65000153    58.70000076    57.90000153\n",
      "    5164.77          57.90000153]\n",
      "  [   58.5           55.15000153    57.5           55.45000076\n",
      "    3301.52          55.45000076]\n",
      "  [   55.25          52.5           55.25          53.04999924\n",
      "    2644.94          53.04999924]\n",
      "  ...\n",
      "  [   53.75          50.09999847    51.            53.45000076\n",
      "   12655.25          53.45000076]\n",
      "  [   54.            51.75          54.            52.20000076\n",
      "    1976.21          52.20000076]\n",
      "  [   52.            49.            51.            51.84999847\n",
      "    1994.67          51.84999847]]\n",
      "\n",
      " [[   58.5           55.15000153    57.5           55.45000076\n",
      "    3301.52          55.45000076]\n",
      "  [   55.25          52.5           55.25          53.04999924\n",
      "    2644.94          53.04999924]\n",
      "  [   54.95000076    50.            53.            50.90000153\n",
      "    4801.71          50.90000153]\n",
      "  ...\n",
      "  [   54.            51.75          54.            52.20000076\n",
      "    1976.21          52.20000076]\n",
      "  [   52.            49.            51.            51.84999847\n",
      "    1994.67          51.84999847]\n",
      "  [   52.            49.75          52.            50.15000153\n",
      "    2362.11          50.15000153]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   44.79999924    43.75          44.70000076    44.54999924\n",
      "     686.7           44.54999924]\n",
      "  [   45.79999924    44.54999924    44.54999924    45.54999924\n",
      "    2345.66          45.54999924]\n",
      "  [   47.5           45.            45.            46.70000076\n",
      "    4940.62          46.70000076]\n",
      "  ...\n",
      "  [   53.34999847    49.59999847    51.75          52.95000076\n",
      "    3483.24          52.95000076]\n",
      "  [   53.            52.            52.            52.40000153\n",
      "    8606.01          52.40000153]\n",
      "  [   53.            51.5           52.79999924    52.20000076\n",
      "    1028.04          52.20000076]]\n",
      "\n",
      " [[   45.79999924    44.54999924    44.54999924    45.54999924\n",
      "    2345.66          45.54999924]\n",
      "  [   47.5           45.            45.            46.70000076\n",
      "    4940.62          46.70000076]\n",
      "  [   49.            47.70000076    47.95000076    48.70000076\n",
      "    8705.3           48.70000076]\n",
      "  ...\n",
      "  [   53.            52.            52.            52.40000153\n",
      "    8606.01          52.40000153]\n",
      "  [   53.            51.5           52.79999924    52.20000076\n",
      "    1028.04          52.20000076]\n",
      "  [   53.            51.09999847    52.09999847    51.59999847\n",
      "    1209.03          51.59999847]]\n",
      "\n",
      " [[   47.5           45.            45.            46.70000076\n",
      "    4940.62          46.70000076]\n",
      "  [   49.            47.70000076    47.95000076    48.70000076\n",
      "    8705.3           48.70000076]\n",
      "  [   52.            48.5           48.5           51.90000153\n",
      "    2063.45          51.90000153]\n",
      "  ...\n",
      "  [   53.            51.5           52.79999924    52.20000076\n",
      "    1028.04          52.20000076]\n",
      "  [   53.            51.09999847    52.09999847    51.59999847\n",
      "    1209.03          51.59999847]\n",
      "  [   53.29999924    51.59999847    51.59999847    53.15000153\n",
      "    1855.86          53.15000153]]]\n",
      "y_test: [[48.54999924]\n",
      " [46.54999924]\n",
      " [44.20000076]\n",
      " [44.15000153]\n",
      " [43.15000153]\n",
      " [45.15000153]\n",
      " [44.84999847]\n",
      " [44.54999924]\n",
      " [45.54999924]\n",
      " [46.70000076]\n",
      " [48.70000076]\n",
      " [51.90000153]\n",
      " [50.34999847]\n",
      " [50.90000153]\n",
      " [52.95000076]\n",
      " [52.40000153]\n",
      " [52.20000076]\n",
      " [51.59999847]\n",
      " [53.15000153]\n",
      " [53.        ]\n",
      " [50.15000153]\n",
      " [46.34999847]\n",
      " [46.70000076]\n",
      " [46.59999847]\n",
      " [43.70000076]\n",
      " [45.34999847]\n",
      " [46.20000076]\n",
      " [47.34999847]\n",
      " [45.90000153]\n",
      " [44.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[   16.39999962,    14.69999981,    15.14999962,    16.20000076,\n",
       "           4582.86      ,    16.20000076],\n",
       "         [   16.95000076,    16.20000076,    16.20000076,    16.64999962,\n",
       "           7303.17      ,    16.64999962],\n",
       "         [   17.14999962,    16.5       ,    16.60000038,    17.04999924,\n",
       "           2681.5       ,    17.04999924],\n",
       "         ...,\n",
       "         [   16.89999962,    16.        ,    16.89999962,    16.29999924,\n",
       "          10659.48      ,    16.29999924],\n",
       "         [   16.29999924,    15.5       ,    16.        ,    16.        ,\n",
       "           3148.29      ,    16.        ],\n",
       "         [   17.39999962,    15.69999981,    15.69999981,    17.35000038,\n",
       "           5197.5       ,    17.35000038]],\n",
       " \n",
       "        [[   16.95000076,    16.20000076,    16.20000076,    16.64999962,\n",
       "           7303.17      ,    16.64999962],\n",
       "         [   17.14999962,    16.5       ,    16.60000038,    17.04999924,\n",
       "           2681.5       ,    17.04999924],\n",
       "         [   17.79999924,    16.60000038,    17.04999924,    17.54999924,\n",
       "           4638.35      ,    17.54999924],\n",
       "         ...,\n",
       "         [   16.29999924,    15.5       ,    16.        ,    16.        ,\n",
       "           3148.29      ,    16.        ],\n",
       "         [   17.39999962,    15.69999981,    15.69999981,    17.35000038,\n",
       "           5197.5       ,    17.35000038],\n",
       "         [   17.85000038,    17.39999962,    17.39999962,    17.70000076,\n",
       "           2532.31      ,    17.70000076]],\n",
       " \n",
       "        [[   17.14999962,    16.5       ,    16.60000038,    17.04999924,\n",
       "           2681.5       ,    17.04999924],\n",
       "         [   17.79999924,    16.60000038,    17.04999924,    17.54999924,\n",
       "           4638.35      ,    17.54999924],\n",
       "         [   18.        ,    16.89999962,    18.        ,    17.45000076,\n",
       "           6279.5       ,    17.45000076],\n",
       "         ...,\n",
       "         [   17.39999962,    15.69999981,    15.69999981,    17.35000038,\n",
       "           5197.5       ,    17.35000038],\n",
       "         [   17.85000038,    17.39999962,    17.39999962,    17.70000076,\n",
       "           2532.31      ,    17.70000076],\n",
       "         [   17.95000076,    17.60000038,    17.95000076,    17.70000076,\n",
       "           4362.14      ,    17.70000076]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   56.        ,    51.        ,    51.        ,    54.54999924,\n",
       "           5871.03      ,    54.54999924],\n",
       "         [   57.25      ,    55.        ,    55.95000076,    57.09999847,\n",
       "           3833.62      ,    57.09999847],\n",
       "         [   57.5       ,    54.75      ,    57.        ,    56.95000076,\n",
       "           2762.89      ,    56.95000076],\n",
       "         ...,\n",
       "         [   54.95000076,    50.        ,    53.        ,    50.90000153,\n",
       "           4801.71      ,    50.90000153],\n",
       "         [   53.5       ,    49.5       ,    52.        ,    52.09999847,\n",
       "           2920.69      ,    52.09999847],\n",
       "         [   49.5       ,    45.5       ,    49.5       ,    45.70000076,\n",
       "           9657.72      ,    45.70000076]],\n",
       " \n",
       "        [[   57.25      ,    55.        ,    55.95000076,    57.09999847,\n",
       "           3833.62      ,    57.09999847],\n",
       "         [   57.5       ,    54.75      ,    57.        ,    56.95000076,\n",
       "           2762.89      ,    56.95000076],\n",
       "         [   59.95000076,    57.25      ,    59.25      ,    58.54999924,\n",
       "           6247.81      ,    58.54999924],\n",
       "         ...,\n",
       "         [   53.5       ,    49.5       ,    52.        ,    52.09999847,\n",
       "           2920.69      ,    52.09999847],\n",
       "         [   49.5       ,    45.5       ,    49.5       ,    45.70000076,\n",
       "           9657.72      ,    45.70000076],\n",
       "         [   47.90000153,    45.45000076,    45.5       ,    47.09999847,\n",
       "          13498.93      ,    47.09999847]],\n",
       " \n",
       "        [[   57.5       ,    54.75      ,    57.        ,    56.95000076,\n",
       "           2762.89      ,    56.95000076],\n",
       "         [   59.95000076,    57.25      ,    59.25      ,    58.54999924,\n",
       "           6247.81      ,    58.54999924],\n",
       "         [   60.70000076,    57.65000153,    58.70000076,    57.90000153,\n",
       "           5164.77      ,    57.90000153],\n",
       "         ...,\n",
       "         [   49.5       ,    45.5       ,    49.5       ,    45.70000076,\n",
       "           9657.72      ,    45.70000076],\n",
       "         [   47.90000153,    45.45000076,    45.5       ,    47.09999847,\n",
       "          13498.93      ,    47.09999847],\n",
       "         [   53.75      ,    50.09999847,    51.        ,    53.45000076,\n",
       "          12655.25      ,    53.45000076]]]), array([[17.29999924],\n",
       "        [18.60000038],\n",
       "        [18.39999962],\n",
       "        [18.10000038],\n",
       "        [17.54999924],\n",
       "        [17.25      ],\n",
       "        [17.10000038],\n",
       "        [17.        ],\n",
       "        [17.20000076],\n",
       "        [18.        ],\n",
       "        [18.54999924],\n",
       "        [18.5       ],\n",
       "        [18.35000038],\n",
       "        [18.79999924],\n",
       "        [19.95000076],\n",
       "        [20.89999962],\n",
       "        [21.25      ],\n",
       "        [22.10000038],\n",
       "        [21.39999962],\n",
       "        [20.89999962],\n",
       "        [21.60000038],\n",
       "        [21.10000038],\n",
       "        [21.        ],\n",
       "        [20.64999962],\n",
       "        [20.64999962],\n",
       "        [21.        ],\n",
       "        [20.5       ],\n",
       "        [20.14999962],\n",
       "        [20.79999924],\n",
       "        [20.95000076],\n",
       "        [20.79999924],\n",
       "        [20.70000076],\n",
       "        [20.70000076],\n",
       "        [21.45000076],\n",
       "        [21.20000076],\n",
       "        [21.64999962],\n",
       "        [21.39999962],\n",
       "        [21.35000038],\n",
       "        [22.20000076],\n",
       "        [23.29999924],\n",
       "        [24.29999924],\n",
       "        [23.64999962],\n",
       "        [23.39999962],\n",
       "        [23.14999962],\n",
       "        [23.75      ],\n",
       "        [24.04999924],\n",
       "        [23.64999962],\n",
       "        [24.10000038],\n",
       "        [24.29999924],\n",
       "        [24.70000076],\n",
       "        [24.25      ],\n",
       "        [24.14999962],\n",
       "        [24.04999924],\n",
       "        [24.10000038],\n",
       "        [24.        ],\n",
       "        [25.5       ],\n",
       "        [26.20000076],\n",
       "        [25.60000038],\n",
       "        [25.5       ],\n",
       "        [25.5       ],\n",
       "        [25.39999962],\n",
       "        [24.79999924],\n",
       "        [24.39999962],\n",
       "        [24.        ],\n",
       "        [23.79999924],\n",
       "        [23.79999924],\n",
       "        [24.5       ],\n",
       "        [25.10000038],\n",
       "        [25.25      ],\n",
       "        [25.70000076],\n",
       "        [25.95000076],\n",
       "        [26.10000038],\n",
       "        [26.20000076],\n",
       "        [26.75      ],\n",
       "        [26.        ],\n",
       "        [25.89999962],\n",
       "        [25.89999962],\n",
       "        [26.5       ],\n",
       "        [26.60000038],\n",
       "        [27.29999924],\n",
       "        [27.60000038],\n",
       "        [27.75      ],\n",
       "        [28.39999962],\n",
       "        [29.10000038],\n",
       "        [28.35000038],\n",
       "        [28.70000076],\n",
       "        [28.45000076],\n",
       "        [27.70000076],\n",
       "        [26.        ],\n",
       "        [26.79999924],\n",
       "        [26.85000038],\n",
       "        [27.        ],\n",
       "        [28.20000076],\n",
       "        [28.95000076],\n",
       "        [27.14999962],\n",
       "        [28.29999924],\n",
       "        [28.29999924],\n",
       "        [28.54999924],\n",
       "        [28.35000038],\n",
       "        [28.39999962],\n",
       "        [28.54999924],\n",
       "        [28.64999962],\n",
       "        [29.20000076],\n",
       "        [30.45000076],\n",
       "        [30.70000076],\n",
       "        [30.        ],\n",
       "        [29.89999962],\n",
       "        [30.        ],\n",
       "        [29.5       ],\n",
       "        [29.04999924],\n",
       "        [28.29999924],\n",
       "        [27.60000038],\n",
       "        [26.5       ],\n",
       "        [26.20000076],\n",
       "        [27.10000038],\n",
       "        [27.45000076],\n",
       "        [26.70000076],\n",
       "        [25.39999962],\n",
       "        [24.75      ],\n",
       "        [24.        ],\n",
       "        [24.60000038],\n",
       "        [25.95000076],\n",
       "        [26.10000038],\n",
       "        [25.70000076],\n",
       "        [25.70000076],\n",
       "        [25.79999924],\n",
       "        [25.5       ],\n",
       "        [24.60000038],\n",
       "        [24.70000076],\n",
       "        [24.45000076],\n",
       "        [25.85000038],\n",
       "        [26.70000076],\n",
       "        [30.60000038],\n",
       "        [32.25      ],\n",
       "        [33.15000153],\n",
       "        [32.20000076],\n",
       "        [32.5       ],\n",
       "        [32.70000076],\n",
       "        [33.5       ],\n",
       "        [33.79999924],\n",
       "        [34.90000153],\n",
       "        [36.5       ],\n",
       "        [37.29999924],\n",
       "        [36.15000153],\n",
       "        [36.5       ],\n",
       "        [36.5       ],\n",
       "        [36.79999924],\n",
       "        [36.79999924],\n",
       "        [36.79999924],\n",
       "        [36.79999924],\n",
       "        [36.79999924],\n",
       "        [36.79999924],\n",
       "        [34.        ],\n",
       "        [35.90000153],\n",
       "        [35.90000153],\n",
       "        [36.79999924],\n",
       "        [37.70000076],\n",
       "        [39.90000153],\n",
       "        [39.15000153],\n",
       "        [40.5       ],\n",
       "        [41.25      ],\n",
       "        [40.59999847],\n",
       "        [39.54999924],\n",
       "        [40.75      ],\n",
       "        [40.90000153],\n",
       "        [40.84999847],\n",
       "        [41.5       ],\n",
       "        [41.40000153],\n",
       "        [41.25      ],\n",
       "        [42.84999847],\n",
       "        [42.90000153],\n",
       "        [42.04999924],\n",
       "        [40.79999924],\n",
       "        [40.04999924],\n",
       "        [39.29999924],\n",
       "        [38.40000153],\n",
       "        [37.95000076],\n",
       "        [40.        ],\n",
       "        [40.90000153],\n",
       "        [42.5       ],\n",
       "        [41.20000076],\n",
       "        [41.70000076],\n",
       "        [41.        ],\n",
       "        [39.79999924],\n",
       "        [39.84999847],\n",
       "        [41.70000076],\n",
       "        [42.54999924],\n",
       "        [41.65000153],\n",
       "        [40.25      ],\n",
       "        [40.        ],\n",
       "        [42.95000076],\n",
       "        [44.09999847],\n",
       "        [43.04999924],\n",
       "        [42.09999847],\n",
       "        [41.34999847],\n",
       "        [41.95000076],\n",
       "        [44.34999847],\n",
       "        [43.84999847],\n",
       "        [45.5       ],\n",
       "        [45.        ],\n",
       "        [44.75      ],\n",
       "        [46.        ],\n",
       "        [43.84999847],\n",
       "        [44.29999924],\n",
       "        [44.84999847],\n",
       "        [45.84999847],\n",
       "        [45.59999847],\n",
       "        [44.        ],\n",
       "        [43.29999924],\n",
       "        [44.79999924],\n",
       "        [44.95000076],\n",
       "        [44.25      ],\n",
       "        [42.75      ],\n",
       "        [41.95000076],\n",
       "        [41.54999924],\n",
       "        [42.34999847],\n",
       "        [42.90000153],\n",
       "        [43.5       ],\n",
       "        [45.09999847],\n",
       "        [47.90000153],\n",
       "        [46.95000076],\n",
       "        [47.04999924],\n",
       "        [47.70000076],\n",
       "        [48.95000076],\n",
       "        [51.84999847],\n",
       "        [53.90000153],\n",
       "        [54.84999847],\n",
       "        [57.90000153],\n",
       "        [60.40000153],\n",
       "        [61.        ],\n",
       "        [59.65000153],\n",
       "        [59.75      ],\n",
       "        [59.84999847],\n",
       "        [59.79999924],\n",
       "        [59.90000153],\n",
       "        [60.40000153],\n",
       "        [61.        ],\n",
       "        [60.        ],\n",
       "        [59.90000153],\n",
       "        [59.95000076],\n",
       "        [63.54999924],\n",
       "        [63.25      ],\n",
       "        [63.65000153],\n",
       "        [63.95000076],\n",
       "        [63.54999924],\n",
       "        [64.40000153],\n",
       "        [65.05000305],\n",
       "        [61.15000153],\n",
       "        [56.09999847],\n",
       "        [54.90000153],\n",
       "        [57.84999847],\n",
       "        [55.45000076],\n",
       "        [51.75      ],\n",
       "        [54.45000076],\n",
       "        [55.04999924],\n",
       "        [57.09999847],\n",
       "        [58.65000153],\n",
       "        [58.04999924],\n",
       "        [57.40000153],\n",
       "        [56.45000076],\n",
       "        [55.59999847],\n",
       "        [54.45000076],\n",
       "        [52.79999924],\n",
       "        [53.45000076],\n",
       "        [51.29999924],\n",
       "        [56.54999924],\n",
       "        [58.75      ],\n",
       "        [58.65000153],\n",
       "        [59.59999847],\n",
       "        [59.45000076],\n",
       "        [61.29999924],\n",
       "        [62.29999924],\n",
       "        [61.5       ],\n",
       "        [61.45000076],\n",
       "        [61.40000153],\n",
       "        [61.15000153],\n",
       "        [59.65000153],\n",
       "        [58.59999847],\n",
       "        [59.70000076],\n",
       "        [58.15000153],\n",
       "        [56.70000076],\n",
       "        [57.40000153],\n",
       "        [56.54999924],\n",
       "        [56.70000076],\n",
       "        [57.90000153],\n",
       "        [57.59999847],\n",
       "        [58.20000076],\n",
       "        [57.90000153],\n",
       "        [60.09999847],\n",
       "        [62.        ],\n",
       "        [61.70000076],\n",
       "        [61.45000076],\n",
       "        [61.29999924],\n",
       "        [60.15000153],\n",
       "        [59.70000076],\n",
       "        [59.59999847],\n",
       "        [57.90000153],\n",
       "        [57.5       ],\n",
       "        [56.25      ],\n",
       "        [54.        ],\n",
       "        [52.65000153],\n",
       "        [49.90000153],\n",
       "        [52.65000153],\n",
       "        [51.20000076],\n",
       "        [49.25      ],\n",
       "        [48.95000076],\n",
       "        [46.40000153],\n",
       "        [42.25      ],\n",
       "        [46.90000153],\n",
       "        [50.        ],\n",
       "        [50.84999847],\n",
       "        [53.75      ],\n",
       "        [56.5       ],\n",
       "        [59.20000076],\n",
       "        [59.54999924],\n",
       "        [57.65000153],\n",
       "        [56.29999924],\n",
       "        [54.65000153],\n",
       "        [53.5       ],\n",
       "        [52.95000076],\n",
       "        [52.29999924],\n",
       "        [50.40000153],\n",
       "        [50.45000076],\n",
       "        [50.54999924],\n",
       "        [50.59999847],\n",
       "        [50.95000076],\n",
       "        [54.54999924],\n",
       "        [57.09999847],\n",
       "        [56.95000076],\n",
       "        [58.54999924],\n",
       "        [57.90000153],\n",
       "        [55.45000076],\n",
       "        [53.04999924],\n",
       "        [50.90000153],\n",
       "        [52.09999847],\n",
       "        [45.70000076],\n",
       "        [47.09999847],\n",
       "        [53.45000076],\n",
       "        [52.20000076],\n",
       "        [51.84999847],\n",
       "        [50.15000153],\n",
       "        [44.5       ],\n",
       "        [45.        ],\n",
       "        [40.90000153],\n",
       "        [38.45000076],\n",
       "        [43.34999847],\n",
       "        [45.84999847],\n",
       "        [46.90000153],\n",
       "        [46.90000153]]), array([[[   59.95000076,    57.25      ,    59.25      ,    58.54999924,\n",
       "           6247.81      ,    58.54999924],\n",
       "         [   60.70000076,    57.65000153,    58.70000076,    57.90000153,\n",
       "           5164.77      ,    57.90000153],\n",
       "         [   58.5       ,    55.15000153,    57.5       ,    55.45000076,\n",
       "           3301.52      ,    55.45000076],\n",
       "         ...,\n",
       "         [   47.90000153,    45.45000076,    45.5       ,    47.09999847,\n",
       "          13498.93      ,    47.09999847],\n",
       "         [   53.75      ,    50.09999847,    51.        ,    53.45000076,\n",
       "          12655.25      ,    53.45000076],\n",
       "         [   54.        ,    51.75      ,    54.        ,    52.20000076,\n",
       "           1976.21      ,    52.20000076]],\n",
       " \n",
       "        [[   60.70000076,    57.65000153,    58.70000076,    57.90000153,\n",
       "           5164.77      ,    57.90000153],\n",
       "         [   58.5       ,    55.15000153,    57.5       ,    55.45000076,\n",
       "           3301.52      ,    55.45000076],\n",
       "         [   55.25      ,    52.5       ,    55.25      ,    53.04999924,\n",
       "           2644.94      ,    53.04999924],\n",
       "         ...,\n",
       "         [   53.75      ,    50.09999847,    51.        ,    53.45000076,\n",
       "          12655.25      ,    53.45000076],\n",
       "         [   54.        ,    51.75      ,    54.        ,    52.20000076,\n",
       "           1976.21      ,    52.20000076],\n",
       "         [   52.        ,    49.        ,    51.        ,    51.84999847,\n",
       "           1994.67      ,    51.84999847]],\n",
       " \n",
       "        [[   58.5       ,    55.15000153,    57.5       ,    55.45000076,\n",
       "           3301.52      ,    55.45000076],\n",
       "         [   55.25      ,    52.5       ,    55.25      ,    53.04999924,\n",
       "           2644.94      ,    53.04999924],\n",
       "         [   54.95000076,    50.        ,    53.        ,    50.90000153,\n",
       "           4801.71      ,    50.90000153],\n",
       "         ...,\n",
       "         [   54.        ,    51.75      ,    54.        ,    52.20000076,\n",
       "           1976.21      ,    52.20000076],\n",
       "         [   52.        ,    49.        ,    51.        ,    51.84999847,\n",
       "           1994.67      ,    51.84999847],\n",
       "         [   52.        ,    49.75      ,    52.        ,    50.15000153,\n",
       "           2362.11      ,    50.15000153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   44.79999924,    43.75      ,    44.70000076,    44.54999924,\n",
       "            686.7       ,    44.54999924],\n",
       "         [   45.79999924,    44.54999924,    44.54999924,    45.54999924,\n",
       "           2345.66      ,    45.54999924],\n",
       "         [   47.5       ,    45.        ,    45.        ,    46.70000076,\n",
       "           4940.62      ,    46.70000076],\n",
       "         ...,\n",
       "         [   53.34999847,    49.59999847,    51.75      ,    52.95000076,\n",
       "           3483.24      ,    52.95000076],\n",
       "         [   53.        ,    52.        ,    52.        ,    52.40000153,\n",
       "           8606.01      ,    52.40000153],\n",
       "         [   53.        ,    51.5       ,    52.79999924,    52.20000076,\n",
       "           1028.04      ,    52.20000076]],\n",
       " \n",
       "        [[   45.79999924,    44.54999924,    44.54999924,    45.54999924,\n",
       "           2345.66      ,    45.54999924],\n",
       "         [   47.5       ,    45.        ,    45.        ,    46.70000076,\n",
       "           4940.62      ,    46.70000076],\n",
       "         [   49.        ,    47.70000076,    47.95000076,    48.70000076,\n",
       "           8705.3       ,    48.70000076],\n",
       "         ...,\n",
       "         [   53.        ,    52.        ,    52.        ,    52.40000153,\n",
       "           8606.01      ,    52.40000153],\n",
       "         [   53.        ,    51.5       ,    52.79999924,    52.20000076,\n",
       "           1028.04      ,    52.20000076],\n",
       "         [   53.        ,    51.09999847,    52.09999847,    51.59999847,\n",
       "           1209.03      ,    51.59999847]],\n",
       " \n",
       "        [[   47.5       ,    45.        ,    45.        ,    46.70000076,\n",
       "           4940.62      ,    46.70000076],\n",
       "         [   49.        ,    47.70000076,    47.95000076,    48.70000076,\n",
       "           8705.3       ,    48.70000076],\n",
       "         [   52.        ,    48.5       ,    48.5       ,    51.90000153,\n",
       "           2063.45      ,    51.90000153],\n",
       "         ...,\n",
       "         [   53.        ,    51.5       ,    52.79999924,    52.20000076,\n",
       "           1028.04      ,    52.20000076],\n",
       "         [   53.        ,    51.09999847,    52.09999847,    51.59999847,\n",
       "           1209.03      ,    51.59999847],\n",
       "         [   53.29999924,    51.59999847,    51.59999847,    53.15000153,\n",
       "           1855.86      ,    53.15000153]]]), array([[48.54999924],\n",
       "        [46.54999924],\n",
       "        [44.20000076],\n",
       "        [44.15000153],\n",
       "        [43.15000153],\n",
       "        [45.15000153],\n",
       "        [44.84999847],\n",
       "        [44.54999924],\n",
       "        [45.54999924],\n",
       "        [46.70000076],\n",
       "        [48.70000076],\n",
       "        [51.90000153],\n",
       "        [50.34999847],\n",
       "        [50.90000153],\n",
       "        [52.95000076],\n",
       "        [52.40000153],\n",
       "        [52.20000076],\n",
       "        [51.59999847],\n",
       "        [53.15000153],\n",
       "        [53.        ],\n",
       "        [50.15000153],\n",
       "        [46.34999847],\n",
       "        [46.70000076],\n",
       "        [46.59999847],\n",
       "        [43.70000076],\n",
       "        [45.34999847],\n",
       "        [46.20000076],\n",
       "        [47.34999847],\n",
       "        [45.90000153],\n",
       "        [44.        ]])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data_v2(df_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[2]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def build_model2(layers):\n",
    "        d = 0.2\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(Dense(16,kernel_initializer='uniform',activation='relu'))        \n",
    "        model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "        model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features TOT : 7\n",
      "Amount of features found: 6\n",
      "x_test: [[[ 0.0212   0.01965  0.0199   0.0209   8.44688  0.0209 ]\n",
      "  [ 0.02     0.01845  0.0189   0.01995  5.38881  0.01995]\n",
      "  [ 0.0188   0.0177   0.01835  0.0188   4.26191  0.0188 ]\n",
      "  [ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]]\n",
      "\n",
      " [[ 0.02     0.01845  0.0189   0.01995  5.38881  0.01995]\n",
      "  [ 0.0188   0.0177   0.01835  0.0188   4.26191  0.0188 ]\n",
      "  [ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]]\n",
      "\n",
      " [[ 0.0188   0.0177   0.01835  0.0188   4.26191  0.0188 ]\n",
      "  [ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]]\n",
      "\n",
      " [[ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]]\n",
      "\n",
      " [[ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]]\n",
      "\n",
      " [[ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]]\n",
      "\n",
      " [[ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]]\n",
      "\n",
      " [[ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]]\n",
      "\n",
      " [[ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]]\n",
      "\n",
      " [[ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]]\n",
      "\n",
      " [[ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]]\n",
      "\n",
      " [[ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]]\n",
      "\n",
      " [[ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]]\n",
      "\n",
      " [[ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]]\n",
      "\n",
      " [[ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]]\n",
      "\n",
      " [[ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]]\n",
      "\n",
      " [[ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]]\n",
      "\n",
      " [[ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]]\n",
      "\n",
      " [[ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]]\n",
      "\n",
      " [[ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]]\n",
      "\n",
      " [[ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]]\n",
      "\n",
      " [[ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]]\n",
      "\n",
      " [[ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]]\n",
      "\n",
      " [[ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]]\n",
      "\n",
      " [[ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]]\n",
      "\n",
      " [[ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]]\n",
      "\n",
      " [[ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]]\n",
      "\n",
      " [[ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]]\n",
      "\n",
      " [[ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]\n",
      "  [ 0.0178   0.0166   0.01705  0.01755  4.63835  0.01755]]\n",
      "\n",
      " [[ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]\n",
      "  [ 0.0178   0.0166   0.01705  0.01755  4.63835  0.01755]\n",
      "  [ 0.01715  0.0165   0.0166   0.01705  2.6815   0.01705]]\n",
      "\n",
      " [[ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]\n",
      "  [ 0.0178   0.0166   0.01705  0.01755  4.63835  0.01755]\n",
      "  [ 0.01715  0.0165   0.0166   0.01705  2.6815   0.01705]\n",
      "  [ 0.01695  0.0162   0.0162   0.01665  7.30317  0.01665]]]\n",
      "y_test: [[0.0216 ]\n",
      " [0.0209 ]\n",
      " [0.0214 ]\n",
      " [0.0221 ]\n",
      " [0.02125]\n",
      " [0.0209 ]\n",
      " [0.01995]\n",
      " [0.0188 ]\n",
      " [0.01835]\n",
      " [0.0185 ]\n",
      " [0.01855]\n",
      " [0.018  ]\n",
      " [0.0172 ]\n",
      " [0.017  ]\n",
      " [0.0171 ]\n",
      " [0.01725]\n",
      " [0.01755]\n",
      " [0.0181 ]\n",
      " [0.0184 ]\n",
      " [0.0186 ]\n",
      " [0.0173 ]\n",
      " [0.0176 ]\n",
      " [0.01735]\n",
      " [0.0175 ]\n",
      " [0.0176 ]\n",
      " [0.0175 ]\n",
      " [0.01725]\n",
      " [0.01695]\n",
      " [0.0176 ]\n",
      " [0.0177 ]\n",
      " [0.0177 ]]\n",
      "X_train (353, 5, 6)\n",
      "y_train (353, 1)\n",
      "X_test (31, 5, 6)\n",
      "y_test (31, 1)\n"
     ]
    }
   ],
   "source": [
    "df_val = df.values / 1000\n",
    "#for a in range(len(df_val[0])-2):\n",
    "#    df_val[:,a] /= 1000\n",
    "window  =  5\n",
    "X_train, y_train, X_test, y_test = load_data_v2(df_val[::-1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 317 samples, validate on 36 samples\n",
      "Epoch 1/250\n",
      "317/317 [==============================] - 5s 16ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 3.1214e-04 - val_acc: 0.0000e+00\n",
      "Epoch 2/250\n",
      "317/317 [==============================] - 0s 551us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 1.8728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/250\n",
      "317/317 [==============================] - 0s 667us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 8.5859e-05 - val_acc: 0.0000e+00\n",
      "Epoch 4/250\n",
      "317/317 [==============================] - 0s 565us/step - loss: 9.5748e-04 - acc: 0.0000e+00 - val_loss: 3.2259e-05 - val_acc: 0.0000e+00\n",
      "Epoch 5/250\n",
      "317/317 [==============================] - 0s 637us/step - loss: 6.4402e-04 - acc: 0.0000e+00 - val_loss: 6.6251e-05 - val_acc: 0.0000e+00\n",
      "Epoch 6/250\n",
      "317/317 [==============================] - 0s 563us/step - loss: 3.8478e-04 - acc: 0.0000e+00 - val_loss: 2.1981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/250\n",
      "317/317 [==============================] - 0s 613us/step - loss: 2.2940e-04 - acc: 0.0000e+00 - val_loss: 5.1245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/250\n",
      "317/317 [==============================] - 0s 574us/step - loss: 2.1920e-04 - acc: 0.0000e+00 - val_loss: 8.8139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/250\n",
      "317/317 [==============================] - 0s 611us/step - loss: 3.2625e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 10/250\n",
      "317/317 [==============================] - 0s 658us/step - loss: 4.3476e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 11/250\n",
      "317/317 [==============================] - 0s 555us/step - loss: 4.3489e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 12/250\n",
      "317/317 [==============================] - 0s 690us/step - loss: 3.8747e-04 - acc: 0.0000e+00 - val_loss: 8.5372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/250\n",
      "317/317 [==============================] - 0s 527us/step - loss: 2.9277e-04 - acc: 0.0000e+00 - val_loss: 6.4718e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/250\n",
      "317/317 [==============================] - 0s 618us/step - loss: 2.3602e-04 - acc: 0.0000e+00 - val_loss: 4.6699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/250\n",
      "317/317 [==============================] - 0s 669us/step - loss: 1.8101e-04 - acc: 0.0000e+00 - val_loss: 3.3144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/250\n",
      "317/317 [==============================] - 0s 572us/step - loss: 1.8102e-04 - acc: 0.0000e+00 - val_loss: 2.3844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/250\n",
      "317/317 [==============================] - 0s 610us/step - loss: 1.9920e-04 - acc: 0.0000e+00 - val_loss: 1.8155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/250\n",
      "317/317 [==============================] - 0s 640us/step - loss: 2.2147e-04 - acc: 0.0000e+00 - val_loss: 1.5124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/250\n",
      "317/317 [==============================] - 0s 535us/step - loss: 2.3617e-04 - acc: 0.0000e+00 - val_loss: 1.3988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/250\n",
      "317/317 [==============================] - 0s 631us/step - loss: 2.3433e-04 - acc: 0.0000e+00 - val_loss: 1.4229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/250\n",
      "317/317 [==============================] - 0s 530us/step - loss: 2.3589e-04 - acc: 0.0000e+00 - val_loss: 1.5644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/250\n",
      "317/317 [==============================] - 0s 612us/step - loss: 2.3549e-04 - acc: 0.0000e+00 - val_loss: 1.8165e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/250\n",
      "317/317 [==============================] - 0s 615us/step - loss: 2.1629e-04 - acc: 0.0000e+00 - val_loss: 2.1791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/250\n",
      "317/317 [==============================] - 0s 655us/step - loss: 1.9747e-04 - acc: 0.0000e+00 - val_loss: 2.6202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/250\n",
      "317/317 [==============================] - 0s 566us/step - loss: 1.7398e-04 - acc: 0.0000e+00 - val_loss: 3.0905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/250\n",
      "317/317 [==============================] - 0s 552us/step - loss: 1.7873e-04 - acc: 0.0000e+00 - val_loss: 3.6139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/250\n",
      "317/317 [==============================] - 0s 643us/step - loss: 1.6483e-04 - acc: 0.0000e+00 - val_loss: 4.1522e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/250\n",
      "317/317 [==============================] - 0s 570us/step - loss: 1.5946e-04 - acc: 0.0000e+00 - val_loss: 4.6694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/250\n",
      "317/317 [==============================] - 0s 563us/step - loss: 1.7225e-04 - acc: 0.0000e+00 - val_loss: 5.1177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/250\n",
      "317/317 [==============================] - 0s 623us/step - loss: 1.6872e-04 - acc: 0.0000e+00 - val_loss: 5.4502e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/250\n",
      "317/317 [==============================] - 0s 574us/step - loss: 1.7893e-04 - acc: 0.0000e+00 - val_loss: 5.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/250\n",
      "317/317 [==============================] - 0s 610us/step - loss: 1.7635e-04 - acc: 0.0000e+00 - val_loss: 5.6183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/250\n",
      "317/317 [==============================] - 0s 603us/step - loss: 1.7274e-04 - acc: 0.0000e+00 - val_loss: 5.4829e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/250\n",
      "317/317 [==============================] - 0s 627us/step - loss: 1.7926e-04 - acc: 0.0000e+00 - val_loss: 5.2238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/250\n",
      "317/317 [==============================] - 0s 648us/step - loss: 1.6876e-04 - acc: 0.0000e+00 - val_loss: 4.8969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/250\n",
      "317/317 [==============================] - 0s 613us/step - loss: 1.5927e-04 - acc: 0.0000e+00 - val_loss: 4.5414e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/250\n",
      "317/317 [==============================] - 0s 505us/step - loss: 1.5051e-04 - acc: 0.0000e+00 - val_loss: 4.1995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/250\n",
      "317/317 [==============================] - 0s 520us/step - loss: 1.6066e-04 - acc: 0.0000e+00 - val_loss: 3.8924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/250\n",
      "317/317 [==============================] - 0s 484us/step - loss: 1.5808e-04 - acc: 0.0000e+00 - val_loss: 3.6313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/250\n",
      "317/317 [==============================] - 0s 509us/step - loss: 1.5683e-04 - acc: 0.0000e+00 - val_loss: 3.4240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/250\n",
      "317/317 [==============================] - 0s 495us/step - loss: 1.5587e-04 - acc: 0.0000e+00 - val_loss: 3.2714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/250\n",
      "317/317 [==============================] - 0s 515us/step - loss: 1.5999e-04 - acc: 0.0000e+00 - val_loss: 3.1776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.5844e-04 - acc: 0.0000e+00 - val_loss: 3.1368e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/250\n",
      "317/317 [==============================] - 0s 491us/step - loss: 1.5285e-04 - acc: 0.0000e+00 - val_loss: 3.1501e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.5317e-04 - acc: 0.0000e+00 - val_loss: 3.2145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/250\n",
      "317/317 [==============================] - 0s 499us/step - loss: 1.5697e-04 - acc: 0.0000e+00 - val_loss: 3.3153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/250\n",
      "317/317 [==============================] - 0s 499us/step - loss: 1.5758e-04 - acc: 0.0000e+00 - val_loss: 3.4485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/250\n",
      "317/317 [==============================] - 0s 513us/step - loss: 1.5810e-04 - acc: 0.0000e+00 - val_loss: 3.6071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/250\n",
      "317/317 [==============================] - 0s 512us/step - loss: 1.5432e-04 - acc: 0.0000e+00 - val_loss: 3.7816e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.4699e-04 - acc: 0.0000e+00 - val_loss: 3.9648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/250\n",
      "317/317 [==============================] - 0s 517us/step - loss: 1.5454e-04 - acc: 0.0000e+00 - val_loss: 4.1366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/250\n",
      "317/317 [==============================] - 0s 505us/step - loss: 1.5157e-04 - acc: 0.0000e+00 - val_loss: 4.2878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/250\n",
      "317/317 [==============================] - 0s 490us/step - loss: 1.5245e-04 - acc: 0.0000e+00 - val_loss: 4.4024e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/250\n",
      "317/317 [==============================] - 0s 524us/step - loss: 1.5042e-04 - acc: 0.0000e+00 - val_loss: 4.4854e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/250\n",
      "317/317 [==============================] - 0s 510us/step - loss: 1.5315e-04 - acc: 0.0000e+00 - val_loss: 4.5221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/250\n",
      "317/317 [==============================] - 0s 522us/step - loss: 1.5030e-04 - acc: 0.0000e+00 - val_loss: 4.5096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/250\n",
      "317/317 [==============================] - 0s 492us/step - loss: 1.5565e-04 - acc: 0.0000e+00 - val_loss: 4.4613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/250\n",
      "317/317 [==============================] - 0s 487us/step - loss: 1.4998e-04 - acc: 0.0000e+00 - val_loss: 4.3880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/250\n",
      "317/317 [==============================] - 0s 503us/step - loss: 1.5009e-04 - acc: 0.0000e+00 - val_loss: 4.3020e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/250\n",
      "317/317 [==============================] - 0s 486us/step - loss: 1.5083e-04 - acc: 0.0000e+00 - val_loss: 4.2029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/250\n",
      "317/317 [==============================] - 0s 503us/step - loss: 1.4660e-04 - acc: 0.0000e+00 - val_loss: 4.1001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/250\n",
      "317/317 [==============================] - 0s 481us/step - loss: 1.4943e-04 - acc: 0.0000e+00 - val_loss: 4.0057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/250\n",
      "317/317 [==============================] - 0s 497us/step - loss: 1.4727e-04 - acc: 0.0000e+00 - val_loss: 3.9249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/250\n",
      "317/317 [==============================] - 0s 467us/step - loss: 1.4726e-04 - acc: 0.0000e+00 - val_loss: 3.8598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/250\n",
      "317/317 [==============================] - 0s 496us/step - loss: 1.4920e-04 - acc: 0.0000e+00 - val_loss: 3.8223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/250\n",
      "317/317 [==============================] - 0s 482us/step - loss: 1.5233e-04 - acc: 0.0000e+00 - val_loss: 3.8044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/250\n",
      "317/317 [==============================] - 0s 498us/step - loss: 1.4320e-04 - acc: 0.0000e+00 - val_loss: 3.8113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/250\n",
      "317/317 [==============================] - 0s 499us/step - loss: 1.5253e-04 - acc: 0.0000e+00 - val_loss: 3.8330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/250\n",
      "317/317 [==============================] - 0s 527us/step - loss: 1.4970e-04 - acc: 0.0000e+00 - val_loss: 3.8658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/250\n",
      "317/317 [==============================] - 0s 489us/step - loss: 1.5023e-04 - acc: 0.0000e+00 - val_loss: 3.9110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/250\n",
      "317/317 [==============================] - 0s 470us/step - loss: 1.4967e-04 - acc: 0.0000e+00 - val_loss: 3.9575e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/250\n",
      "317/317 [==============================] - 0s 493us/step - loss: 1.4673e-04 - acc: 0.0000e+00 - val_loss: 3.9957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/250\n",
      "317/317 [==============================] - 0s 539us/step - loss: 1.5397e-04 - acc: 0.0000e+00 - val_loss: 4.0316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/250\n",
      "317/317 [==============================] - 0s 474us/step - loss: 1.4269e-04 - acc: 0.0000e+00 - val_loss: 4.0647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/250\n",
      "317/317 [==============================] - 0s 484us/step - loss: 1.4486e-04 - acc: 0.0000e+00 - val_loss: 4.1023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/250\n",
      "317/317 [==============================] - 0s 487us/step - loss: 1.5203e-04 - acc: 0.0000e+00 - val_loss: 4.1256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/250\n",
      "317/317 [==============================] - 0s 484us/step - loss: 1.5260e-04 - acc: 0.0000e+00 - val_loss: 4.1327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/250\n",
      "317/317 [==============================] - 0s 512us/step - loss: 1.4310e-04 - acc: 0.0000e+00 - val_loss: 4.1378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/250\n",
      "317/317 [==============================] - 0s 484us/step - loss: 1.5062e-04 - acc: 0.0000e+00 - val_loss: 4.1276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/250\n",
      "317/317 [==============================] - 0s 536us/step - loss: 1.5011e-04 - acc: 0.0000e+00 - val_loss: 4.1093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.4389e-04 - acc: 0.0000e+00 - val_loss: 4.0907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/250\n",
      "317/317 [==============================] - 0s 531us/step - loss: 1.4671e-04 - acc: 0.0000e+00 - val_loss: 4.0681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/250\n",
      "317/317 [==============================] - 0s 492us/step - loss: 1.4591e-04 - acc: 0.0000e+00 - val_loss: 4.0524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/250\n",
      "317/317 [==============================] - 0s 514us/step - loss: 1.4555e-04 - acc: 0.0000e+00 - val_loss: 4.0455e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/250\n",
      "317/317 [==============================] - 0s 503us/step - loss: 1.4704e-04 - acc: 0.0000e+00 - val_loss: 4.0411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/250\n",
      "317/317 [==============================] - 0s 508us/step - loss: 1.4533e-04 - acc: 0.0000e+00 - val_loss: 4.0397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/250\n",
      "317/317 [==============================] - 0s 505us/step - loss: 1.4206e-04 - acc: 0.0000e+00 - val_loss: 4.0463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/250\n",
      "317/317 [==============================] - 0s 492us/step - loss: 1.4589e-04 - acc: 0.0000e+00 - val_loss: 4.0458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/250\n",
      "317/317 [==============================] - 0s 589us/step - loss: 1.4592e-04 - acc: 0.0000e+00 - val_loss: 4.0470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/250\n",
      "317/317 [==============================] - 0s 514us/step - loss: 1.4635e-04 - acc: 0.0000e+00 - val_loss: 4.0498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/250\n",
      "317/317 [==============================] - 0s 522us/step - loss: 1.5071e-04 - acc: 0.0000e+00 - val_loss: 4.0469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/250\n",
      "317/317 [==============================] - 0s 503us/step - loss: 1.4458e-04 - acc: 0.0000e+00 - val_loss: 4.0380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/250\n",
      "317/317 [==============================] - 0s 481us/step - loss: 1.4917e-04 - acc: 0.0000e+00 - val_loss: 4.0327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/250\n",
      "317/317 [==============================] - 0s 568us/step - loss: 1.4881e-04 - acc: 0.0000e+00 - val_loss: 4.0223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/250\n",
      "317/317 [==============================] - 0s 478us/step - loss: 1.4227e-04 - acc: 0.0000e+00 - val_loss: 4.0163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/250\n",
      "317/317 [==============================] - 0s 509us/step - loss: 1.4429e-04 - acc: 0.0000e+00 - val_loss: 4.0219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/250\n",
      "317/317 [==============================] - 0s 481us/step - loss: 1.4607e-04 - acc: 0.0000e+00 - val_loss: 4.0298e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/250\n",
      "317/317 [==============================] - 0s 517us/step - loss: 1.4133e-04 - acc: 0.0000e+00 - val_loss: 4.0516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/250\n",
      "317/317 [==============================] - 0s 509us/step - loss: 1.3972e-04 - acc: 0.0000e+00 - val_loss: 4.0775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/250\n",
      "317/317 [==============================] - 0s 485us/step - loss: 1.4512e-04 - acc: 0.0000e+00 - val_loss: 4.0989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/250\n",
      "317/317 [==============================] - 0s 496us/step - loss: 1.4613e-04 - acc: 0.0000e+00 - val_loss: 4.1111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/250\n",
      "317/317 [==============================] - 0s 497us/step - loss: 1.4771e-04 - acc: 0.0000e+00 - val_loss: 4.1181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/250\n",
      "317/317 [==============================] - 0s 484us/step - loss: 1.4416e-04 - acc: 0.0000e+00 - val_loss: 4.1129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.4369e-04 - acc: 0.0000e+00 - val_loss: 4.1037e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/250\n",
      "317/317 [==============================] - 0s 494us/step - loss: 1.4217e-04 - acc: 0.0000e+00 - val_loss: 4.0926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/250\n",
      "317/317 [==============================] - 0s 496us/step - loss: 1.4019e-04 - acc: 0.0000e+00 - val_loss: 4.0870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/250\n",
      "317/317 [==============================] - 0s 486us/step - loss: 1.4551e-04 - acc: 0.0000e+00 - val_loss: 4.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.4759e-04 - acc: 0.0000e+00 - val_loss: 4.0597e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/250\n",
      "317/317 [==============================] - 0s 478us/step - loss: 1.4162e-04 - acc: 0.0000e+00 - val_loss: 4.0556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/250\n",
      "317/317 [==============================] - 0s 483us/step - loss: 1.4407e-04 - acc: 0.0000e+00 - val_loss: 4.0558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/250\n",
      "317/317 [==============================] - 0s 502us/step - loss: 1.3669e-04 - acc: 0.0000e+00 - val_loss: 4.0557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/250\n",
      "317/317 [==============================] - 0s 492us/step - loss: 1.4285e-04 - acc: 0.0000e+00 - val_loss: 4.0513e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/250\n",
      "317/317 [==============================] - 0s 498us/step - loss: 1.4435e-04 - acc: 0.0000e+00 - val_loss: 4.0467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/250\n",
      "317/317 [==============================] - 0s 475us/step - loss: 1.4279e-04 - acc: 0.0000e+00 - val_loss: 4.0430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/250\n",
      "317/317 [==============================] - 0s 486us/step - loss: 1.4567e-04 - acc: 0.0000e+00 - val_loss: 4.0431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/250\n",
      "317/317 [==============================] - 0s 497us/step - loss: 1.4253e-04 - acc: 0.0000e+00 - val_loss: 4.0492e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/250\n",
      "317/317 [==============================] - 0s 509us/step - loss: 1.4368e-04 - acc: 0.0000e+00 - val_loss: 4.0598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/250\n",
      "317/317 [==============================] - 0s 499us/step - loss: 1.4142e-04 - acc: 0.0000e+00 - val_loss: 4.0705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/250\n",
      "317/317 [==============================] - 0s 499us/step - loss: 1.4271e-04 - acc: 0.0000e+00 - val_loss: 4.0851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.4542e-04 - acc: 0.0000e+00 - val_loss: 4.1051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/250\n",
      "317/317 [==============================] - 0s 512us/step - loss: 1.4167e-04 - acc: 0.0000e+00 - val_loss: 4.1205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/250\n",
      "317/317 [==============================] - 0s 525us/step - loss: 1.4147e-04 - acc: 0.0000e+00 - val_loss: 4.1344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/250\n",
      "317/317 [==============================] - 0s 512us/step - loss: 1.4254e-04 - acc: 0.0000e+00 - val_loss: 4.1458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/250\n",
      "317/317 [==============================] - 0s 507us/step - loss: 1.4646e-04 - acc: 0.0000e+00 - val_loss: 4.1482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/250\n",
      "317/317 [==============================] - 0s 472us/step - loss: 1.4023e-04 - acc: 0.0000e+00 - val_loss: 4.1443e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/250\n",
      "317/317 [==============================] - 0s 482us/step - loss: 1.4235e-04 - acc: 0.0000e+00 - val_loss: 4.1388e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/250\n",
      "317/317 [==============================] - 0s 481us/step - loss: 1.4330e-04 - acc: 0.0000e+00 - val_loss: 4.1237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/250\n",
      "317/317 [==============================] - 0s 518us/step - loss: 1.4514e-04 - acc: 0.0000e+00 - val_loss: 4.1116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/250\n",
      "317/317 [==============================] - 0s 498us/step - loss: 1.4646e-04 - acc: 0.0000e+00 - val_loss: 4.0952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/250\n",
      "317/317 [==============================] - 0s 488us/step - loss: 1.4281e-04 - acc: 0.0000e+00 - val_loss: 4.0729e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/250\n",
      "317/317 [==============================] - 0s 482us/step - loss: 1.4374e-04 - acc: 0.0000e+00 - val_loss: 4.0541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/250\n",
      "317/317 [==============================] - 0s 501us/step - loss: 1.4211e-04 - acc: 0.0000e+00 - val_loss: 4.0427e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/250\n",
      "317/317 [==============================] - 0s 511us/step - loss: 1.4304e-04 - acc: 0.0000e+00 - val_loss: 4.0336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/250\n",
      "317/317 [==============================] - 0s 528us/step - loss: 1.4271e-04 - acc: 0.0000e+00 - val_loss: 4.0296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/250\n",
      "317/317 [==============================] - 0s 498us/step - loss: 1.4780e-04 - acc: 0.0000e+00 - val_loss: 4.0305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/250\n",
      "317/317 [==============================] - 0s 517us/step - loss: 1.4109e-04 - acc: 0.0000e+00 - val_loss: 4.0366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/250\n",
      "317/317 [==============================] - 0s 491us/step - loss: 1.4081e-04 - acc: 0.0000e+00 - val_loss: 4.0525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/250\n",
      "317/317 [==============================] - 0s 559us/step - loss: 1.4392e-04 - acc: 0.0000e+00 - val_loss: 4.0723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/250\n",
      "317/317 [==============================] - 0s 505us/step - loss: 1.3873e-04 - acc: 0.0000e+00 - val_loss: 4.0992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/250\n",
      "317/317 [==============================] - 0s 546us/step - loss: 1.4254e-04 - acc: 0.0000e+00 - val_loss: 4.1190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/250\n",
      "317/317 [==============================] - 0s 779us/step - loss: 1.4104e-04 - acc: 0.0000e+00 - val_loss: 4.1271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/250\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 1.3721e-04 - acc: 0.0000e+00 - val_loss: 4.1421e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/250\n",
      "317/317 [==============================] - 0s 614us/step - loss: 1.4217e-04 - acc: 0.0000e+00 - val_loss: 4.1504e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.4324e-04 - acc: 0.0000e+00 - val_loss: 4.1452e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.3954e-04 - acc: 0.0000e+00 - val_loss: 4.1331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/250\n",
      "317/317 [==============================] - 0s 567us/step - loss: 1.3973e-04 - acc: 0.0000e+00 - val_loss: 4.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/250\n",
      "317/317 [==============================] - 0s 534us/step - loss: 1.4467e-04 - acc: 0.0000e+00 - val_loss: 4.0994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/250\n",
      "317/317 [==============================] - 0s 521us/step - loss: 1.3868e-04 - acc: 0.0000e+00 - val_loss: 4.0837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/250\n",
      "317/317 [==============================] - 0s 507us/step - loss: 1.4233e-04 - acc: 0.0000e+00 - val_loss: 4.0774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/250\n",
      "317/317 [==============================] - 0s 560us/step - loss: 1.4067e-04 - acc: 0.0000e+00 - val_loss: 4.0711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/250\n",
      "317/317 [==============================] - 0s 582us/step - loss: 1.4121e-04 - acc: 0.0000e+00 - val_loss: 4.0449e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/250\n",
      "317/317 [==============================] - 0s 571us/step - loss: 1.4309e-04 - acc: 0.0000e+00 - val_loss: 4.0137e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/250\n",
      "317/317 [==============================] - 0s 797us/step - loss: 1.3747e-04 - acc: 0.0000e+00 - val_loss: 4.0238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/250\n",
      "317/317 [==============================] - 0s 556us/step - loss: 1.4223e-04 - acc: 0.0000e+00 - val_loss: 4.0593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.3616e-04 - acc: 0.0000e+00 - val_loss: 4.0705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/250\n",
      "317/317 [==============================] - 0s 513us/step - loss: 1.3839e-04 - acc: 0.0000e+00 - val_loss: 4.0739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/250\n",
      "317/317 [==============================] - 0s 496us/step - loss: 1.4032e-04 - acc: 0.0000e+00 - val_loss: 4.0651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/250\n",
      "317/317 [==============================] - 0s 501us/step - loss: 1.4021e-04 - acc: 0.0000e+00 - val_loss: 4.0442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/250\n",
      "317/317 [==============================] - 0s 490us/step - loss: 1.4193e-04 - acc: 0.0000e+00 - val_loss: 4.0401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/250\n",
      "317/317 [==============================] - 0s 518us/step - loss: 1.3814e-04 - acc: 0.0000e+00 - val_loss: 4.0050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/250\n",
      "317/317 [==============================] - 0s 728us/step - loss: 1.4128e-04 - acc: 0.0000e+00 - val_loss: 3.9655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/250\n",
      "317/317 [==============================] - 0s 693us/step - loss: 1.4202e-04 - acc: 0.0000e+00 - val_loss: 3.9540e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/250\n",
      "317/317 [==============================] - 0s 471us/step - loss: 1.3894e-04 - acc: 0.0000e+00 - val_loss: 3.9431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/250\n",
      "317/317 [==============================] - 0s 515us/step - loss: 1.3757e-04 - acc: 0.0000e+00 - val_loss: 3.9650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/250\n",
      "317/317 [==============================] - 0s 494us/step - loss: 1.4116e-04 - acc: 0.0000e+00 - val_loss: 3.9980e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/250\n",
      "317/317 [==============================] - 0s 501us/step - loss: 1.4135e-04 - acc: 0.0000e+00 - val_loss: 4.0426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.3821e-04 - acc: 0.0000e+00 - val_loss: 4.0837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/250\n",
      "317/317 [==============================] - 0s 529us/step - loss: 1.3771e-04 - acc: 0.0000e+00 - val_loss: 4.1210e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/250\n",
      "317/317 [==============================] - 0s 482us/step - loss: 1.4041e-04 - acc: 0.0000e+00 - val_loss: 4.1396e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/250\n",
      "317/317 [==============================] - 0s 492us/step - loss: 1.3564e-04 - acc: 0.0000e+00 - val_loss: 4.1449e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/250\n",
      "317/317 [==============================] - 0s 515us/step - loss: 1.3733e-04 - acc: 0.0000e+00 - val_loss: 4.1443e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/250\n",
      "317/317 [==============================] - 0s 579us/step - loss: 1.3872e-04 - acc: 0.0000e+00 - val_loss: 4.1040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/250\n",
      "317/317 [==============================] - 0s 520us/step - loss: 1.3909e-04 - acc: 0.0000e+00 - val_loss: 4.0440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/250\n",
      "317/317 [==============================] - 0s 526us/step - loss: 1.4192e-04 - acc: 0.0000e+00 - val_loss: 3.9734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/250\n",
      "317/317 [==============================] - 0s 558us/step - loss: 1.3119e-04 - acc: 0.0000e+00 - val_loss: 3.9370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/250\n",
      "317/317 [==============================] - 0s 518us/step - loss: 1.3989e-04 - acc: 0.0000e+00 - val_loss: 3.9143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/250\n",
      "317/317 [==============================] - 0s 488us/step - loss: 1.3969e-04 - acc: 0.0000e+00 - val_loss: 3.9128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/250\n",
      "317/317 [==============================] - 0s 609us/step - loss: 1.3423e-04 - acc: 0.0000e+00 - val_loss: 3.9169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/250\n",
      "317/317 [==============================] - 0s 604us/step - loss: 1.3888e-04 - acc: 0.0000e+00 - val_loss: 3.9549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.3372e-04 - acc: 0.0000e+00 - val_loss: 4.0255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/250\n",
      "317/317 [==============================] - 0s 502us/step - loss: 1.3510e-04 - acc: 0.0000e+00 - val_loss: 4.0658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/250\n",
      "317/317 [==============================] - 0s 514us/step - loss: 1.4059e-04 - acc: 0.0000e+00 - val_loss: 4.1045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/250\n",
      "317/317 [==============================] - 0s 498us/step - loss: 1.4066e-04 - acc: 0.0000e+00 - val_loss: 4.1384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/250\n",
      "317/317 [==============================] - 0s 517us/step - loss: 1.3883e-04 - acc: 0.0000e+00 - val_loss: 4.1300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/250\n",
      "317/317 [==============================] - 0s 603us/step - loss: 1.3509e-04 - acc: 0.0000e+00 - val_loss: 4.0923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/250\n",
      "317/317 [==============================] - 0s 550us/step - loss: 1.3873e-04 - acc: 0.0000e+00 - val_loss: 4.0048e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/250\n",
      "317/317 [==============================] - 0s 539us/step - loss: 1.3602e-04 - acc: 0.0000e+00 - val_loss: 3.9205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/250\n",
      "317/317 [==============================] - 0s 617us/step - loss: 1.3227e-04 - acc: 0.0000e+00 - val_loss: 3.8544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/250\n",
      "317/317 [==============================] - 0s 463us/step - loss: 1.3431e-04 - acc: 0.0000e+00 - val_loss: 3.8376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/250\n",
      "317/317 [==============================] - 0s 550us/step - loss: 1.3598e-04 - acc: 0.0000e+00 - val_loss: 3.8692e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.3621e-04 - acc: 0.0000e+00 - val_loss: 3.9270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/250\n",
      "317/317 [==============================] - 0s 710us/step - loss: 1.3883e-04 - acc: 0.0000e+00 - val_loss: 4.0111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/250\n",
      "317/317 [==============================] - 0s 663us/step - loss: 1.3849e-04 - acc: 0.0000e+00 - val_loss: 4.1002e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/250\n",
      "317/317 [==============================] - 0s 627us/step - loss: 1.3549e-04 - acc: 0.0000e+00 - val_loss: 4.1896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/250\n",
      "317/317 [==============================] - 0s 656us/step - loss: 1.3490e-04 - acc: 0.0000e+00 - val_loss: 4.2133e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.3758e-04 - acc: 0.0000e+00 - val_loss: 4.1641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/250\n",
      "317/317 [==============================] - 0s 511us/step - loss: 1.3867e-04 - acc: 0.0000e+00 - val_loss: 4.0543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.3728e-04 - acc: 0.0000e+00 - val_loss: 3.9380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/250\n",
      "317/317 [==============================] - 0s 510us/step - loss: 1.3203e-04 - acc: 0.0000e+00 - val_loss: 3.8294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/250\n",
      "317/317 [==============================] - 0s 508us/step - loss: 1.3408e-04 - acc: 0.0000e+00 - val_loss: 3.7745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/250\n",
      "317/317 [==============================] - 0s 483us/step - loss: 1.3642e-04 - acc: 0.0000e+00 - val_loss: 3.7777e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/250\n",
      "317/317 [==============================] - 0s 528us/step - loss: 1.3719e-04 - acc: 0.0000e+00 - val_loss: 3.8043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/250\n",
      "317/317 [==============================] - 0s 494us/step - loss: 1.3424e-04 - acc: 0.0000e+00 - val_loss: 3.8582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/250\n",
      "317/317 [==============================] - 0s 507us/step - loss: 1.3315e-04 - acc: 0.0000e+00 - val_loss: 3.9514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/250\n",
      "317/317 [==============================] - 0s 505us/step - loss: 1.3477e-04 - acc: 0.0000e+00 - val_loss: 4.0598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/250\n",
      "317/317 [==============================] - 0s 548us/step - loss: 1.3734e-04 - acc: 0.0000e+00 - val_loss: 4.1328e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/250\n",
      "317/317 [==============================] - 0s 539us/step - loss: 1.3599e-04 - acc: 0.0000e+00 - val_loss: 4.1900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/250\n",
      "317/317 [==============================] - 0s 586us/step - loss: 1.3409e-04 - acc: 0.0000e+00 - val_loss: 4.1588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/250\n",
      "317/317 [==============================] - 0s 510us/step - loss: 1.3407e-04 - acc: 0.0000e+00 - val_loss: 4.1381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/250\n",
      "317/317 [==============================] - 0s 500us/step - loss: 1.3177e-04 - acc: 0.0000e+00 - val_loss: 4.1166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/250\n",
      "317/317 [==============================] - 0s 487us/step - loss: 1.3579e-04 - acc: 0.0000e+00 - val_loss: 4.0808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/250\n",
      "317/317 [==============================] - 0s 526us/step - loss: 1.3428e-04 - acc: 0.0000e+00 - val_loss: 4.0689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/250\n",
      "317/317 [==============================] - 0s 515us/step - loss: 1.3071e-04 - acc: 0.0000e+00 - val_loss: 4.0604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/250\n",
      "317/317 [==============================] - 0s 491us/step - loss: 1.3801e-04 - acc: 0.0000e+00 - val_loss: 4.0414e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/250\n",
      "317/317 [==============================] - 0s 547us/step - loss: 1.3548e-04 - acc: 0.0000e+00 - val_loss: 3.9876e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/250\n",
      "317/317 [==============================] - 0s 534us/step - loss: 1.3227e-04 - acc: 0.0000e+00 - val_loss: 3.9021e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/250\n",
      "317/317 [==============================] - 0s 499us/step - loss: 1.3410e-04 - acc: 0.0000e+00 - val_loss: 3.8410e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/250\n",
      "317/317 [==============================] - 0s 495us/step - loss: 1.3004e-04 - acc: 0.0000e+00 - val_loss: 3.7831e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/250\n",
      "317/317 [==============================] - 0s 518us/step - loss: 1.3205e-04 - acc: 0.0000e+00 - val_loss: 3.7289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.3280e-04 - acc: 0.0000e+00 - val_loss: 3.7413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/250\n",
      "317/317 [==============================] - 0s 507us/step - loss: 1.3411e-04 - acc: 0.0000e+00 - val_loss: 3.7927e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.3079e-04 - acc: 0.0000e+00 - val_loss: 3.8983e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/250\n",
      "317/317 [==============================] - 0s 466us/step - loss: 1.3217e-04 - acc: 0.0000e+00 - val_loss: 4.0102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/250\n",
      "317/317 [==============================] - 0s 514us/step - loss: 1.2936e-04 - acc: 0.0000e+00 - val_loss: 4.1096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/250\n",
      "317/317 [==============================] - 0s 496us/step - loss: 1.3191e-04 - acc: 0.0000e+00 - val_loss: 4.1280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/250\n",
      "317/317 [==============================] - 0s 518us/step - loss: 1.2867e-04 - acc: 0.0000e+00 - val_loss: 4.0940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/250\n",
      "317/317 [==============================] - 0s 494us/step - loss: 1.2610e-04 - acc: 0.0000e+00 - val_loss: 3.9891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/250\n",
      "317/317 [==============================] - 0s 511us/step - loss: 1.3153e-04 - acc: 0.0000e+00 - val_loss: 3.8611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/250\n",
      "317/317 [==============================] - 0s 487us/step - loss: 1.2910e-04 - acc: 0.0000e+00 - val_loss: 3.7657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/250\n",
      "317/317 [==============================] - 0s 496us/step - loss: 1.2952e-04 - acc: 0.0000e+00 - val_loss: 3.7522e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/250\n",
      "317/317 [==============================] - 0s 506us/step - loss: 1.3017e-04 - acc: 0.0000e+00 - val_loss: 3.8184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/250\n",
      "317/317 [==============================] - 0s 492us/step - loss: 1.2593e-04 - acc: 0.0000e+00 - val_loss: 3.9467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 233/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.3143e-04 - acc: 0.0000e+00 - val_loss: 4.1121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/250\n",
      "317/317 [==============================] - 0s 488us/step - loss: 1.2787e-04 - acc: 0.0000e+00 - val_loss: 4.2658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/250\n",
      "317/317 [==============================] - 0s 519us/step - loss: 1.2780e-04 - acc: 0.0000e+00 - val_loss: 4.2305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/250\n",
      "317/317 [==============================] - 0s 504us/step - loss: 1.3186e-04 - acc: 0.0000e+00 - val_loss: 3.9403e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/250\n",
      "317/317 [==============================] - 0s 490us/step - loss: 1.2425e-04 - acc: 0.0000e+00 - val_loss: 3.6598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/250\n",
      "317/317 [==============================] - 0s 524us/step - loss: 1.2613e-04 - acc: 0.0000e+00 - val_loss: 3.5141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/250\n",
      "317/317 [==============================] - 0s 513us/step - loss: 1.2621e-04 - acc: 0.0000e+00 - val_loss: 3.5015e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/250\n",
      "317/317 [==============================] - 0s 521us/step - loss: 1.2459e-04 - acc: 0.0000e+00 - val_loss: 3.6489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/250\n",
      "317/317 [==============================] - 0s 559us/step - loss: 1.2693e-04 - acc: 0.0000e+00 - val_loss: 3.8450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/250\n",
      "317/317 [==============================] - 0s 494us/step - loss: 1.2538e-04 - acc: 0.0000e+00 - val_loss: 4.0460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/250\n",
      "317/317 [==============================] - 0s 523us/step - loss: 1.2356e-04 - acc: 0.0000e+00 - val_loss: 4.1079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/250\n",
      "317/317 [==============================] - 0s 500us/step - loss: 1.2738e-04 - acc: 0.0000e+00 - val_loss: 3.8695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/250\n",
      "317/317 [==============================] - 0s 512us/step - loss: 1.2355e-04 - acc: 0.0000e+00 - val_loss: 3.5482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/250\n",
      "317/317 [==============================] - 0s 598us/step - loss: 1.2171e-04 - acc: 0.0000e+00 - val_loss: 3.3654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/250\n",
      "317/317 [==============================] - 0s 478us/step - loss: 1.2200e-04 - acc: 0.0000e+00 - val_loss: 3.4310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/250\n",
      "317/317 [==============================] - 0s 510us/step - loss: 1.1977e-04 - acc: 0.0000e+00 - val_loss: 3.6986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/250\n",
      "317/317 [==============================] - 0s 475us/step - loss: 1.1749e-04 - acc: 0.0000e+00 - val_loss: 3.7736e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/250\n",
      "317/317 [==============================] - 0s 489us/step - loss: 1.1713e-04 - acc: 0.0000e+00 - val_loss: 3.3845e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26445654e0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = build_model([3,lag,1])\n",
    "#model = build_model2([3,window,1])\n",
    "model = build_model2([len(df_val[0])-1,5,1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=576,\n",
    "    epochs=250,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 0s 408us/step\n",
      "Train Score: 0.00 MSE (0.01 RMSE)\n",
      "[[[ 0.0212   0.01965  0.0199   0.0209   8.44688  0.0209 ]\n",
      "  [ 0.02     0.01845  0.0189   0.01995  5.38881  0.01995]\n",
      "  [ 0.0188   0.0177   0.01835  0.0188   4.26191  0.0188 ]\n",
      "  [ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]]\n",
      "\n",
      " [[ 0.02     0.01845  0.0189   0.01995  5.38881  0.01995]\n",
      "  [ 0.0188   0.0177   0.01835  0.0188   4.26191  0.0188 ]\n",
      "  [ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]]\n",
      "\n",
      " [[ 0.0188   0.0177   0.01835  0.0188   4.26191  0.0188 ]\n",
      "  [ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]]\n",
      "\n",
      " [[ 0.01855  0.018    0.01855  0.01835  1.30398  0.01835]\n",
      "  [ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]]\n",
      "\n",
      " [[ 0.01875  0.0182   0.0185   0.0185   3.1078   0.0185 ]\n",
      "  [ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]]\n",
      "\n",
      " [[ 0.0189   0.018    0.0183   0.01855  4.40248  0.01855]\n",
      "  [ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]]\n",
      "\n",
      " [[ 0.01815  0.01725  0.01725  0.018    5.51568  0.018  ]\n",
      "  [ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]]\n",
      "\n",
      " [[ 0.0172   0.01695  0.0171   0.0172   4.46707  0.0172 ]\n",
      "  [ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]]\n",
      "\n",
      " [[ 0.01765  0.0165   0.0175   0.017    4.96482  0.017  ]\n",
      "  [ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]]\n",
      "\n",
      " [[ 0.0175   0.0167   0.0173   0.0171   2.01998  0.0171 ]\n",
      "  [ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]]\n",
      "\n",
      " [[ 0.01785  0.017    0.01755  0.01725  2.46667  0.01725]\n",
      "  [ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]]\n",
      "\n",
      " [[ 0.018    0.0175   0.018    0.01755  2.26234  0.01755]\n",
      "  [ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]]\n",
      "\n",
      " [[ 0.01855  0.01765  0.0184   0.0181   4.54144  0.0181 ]\n",
      "  [ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]]\n",
      "\n",
      " [[ 0.0186   0.0181   0.0186   0.0184   6.56251  0.0184 ]\n",
      "  [ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]]\n",
      "\n",
      " [[ 0.0186   0.0173   0.0174   0.0186   7.23901  0.0186 ]\n",
      "  [ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]]\n",
      "\n",
      " [[ 0.0176   0.017    0.0176   0.0173   1.94115  0.0173 ]\n",
      "  [ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]]\n",
      "\n",
      " [[ 0.0177   0.01695  0.01735  0.0176   1.31234  0.0176 ]\n",
      "  [ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]]\n",
      "\n",
      " [[ 0.0176   0.01715  0.0175   0.01735  2.42221  0.01735]\n",
      "  [ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]]\n",
      "\n",
      " [[ 0.01765  0.0173   0.0176   0.0175   1.66459  0.0175 ]\n",
      "  [ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]]\n",
      "\n",
      " [[ 0.0179   0.0172   0.0179   0.0176   3.47622  0.0176 ]\n",
      "  [ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]]\n",
      "\n",
      " [[ 0.01755  0.01705  0.0173   0.0175   2.80057  0.0175 ]\n",
      "  [ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]]\n",
      "\n",
      " [[ 0.01725  0.01675  0.0168   0.01725  1.64556  0.01725]\n",
      "  [ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]]\n",
      "\n",
      " [[ 0.01775  0.0169   0.0176   0.01695  2.7694   0.01695]\n",
      "  [ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]]\n",
      "\n",
      " [[ 0.01795  0.0175   0.0179   0.0176   2.93015  0.0176 ]\n",
      "  [ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]]\n",
      "\n",
      " [[ 0.01795  0.0176   0.01795  0.0177   4.36214  0.0177 ]\n",
      "  [ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]]\n",
      "\n",
      " [[ 0.01785  0.0174   0.0174   0.0177   2.53231  0.0177 ]\n",
      "  [ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]]\n",
      "\n",
      " [[ 0.0174   0.0157   0.0157   0.01735  5.1975   0.01735]\n",
      "  [ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]]\n",
      "\n",
      " [[ 0.0163   0.0155   0.016    0.016    3.14829  0.016  ]\n",
      "  [ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]]\n",
      "\n",
      " [[ 0.0169   0.016    0.0169   0.0163  10.65948  0.0163 ]\n",
      "  [ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]\n",
      "  [ 0.0178   0.0166   0.01705  0.01755  4.63835  0.01755]]\n",
      "\n",
      " [[ 0.01765  0.0168   0.01725  0.01695  4.04413  0.01695]\n",
      "  [ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]\n",
      "  [ 0.0178   0.0166   0.01705  0.01755  4.63835  0.01755]\n",
      "  [ 0.01715  0.0165   0.0166   0.01705  2.6815   0.01705]]\n",
      "\n",
      " [[ 0.0175   0.017    0.01745  0.0172   3.12659  0.0172 ]\n",
      "  [ 0.018    0.0169   0.018    0.01745  6.2795   0.01745]\n",
      "  [ 0.0178   0.0166   0.01705  0.01755  4.63835  0.01755]\n",
      "  [ 0.01715  0.0165   0.0166   0.01705  2.6815   0.01705]\n",
      "  [ 0.01695  0.0162   0.0162   0.01665  7.30317  0.01665]]]\n",
      "31/31 [==============================] - 0s 523us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.00 MSE (0.02 RMSE)\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "print (X_test)\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0175  0.017   0.01745 0.0172  3.12659 0.0172 ]\n",
      " [0.018   0.0169  0.018   0.01745 6.2795  0.01745]\n",
      " [0.0178  0.0166  0.01705 0.01755 4.63835 0.01755]\n",
      " [0.01715 0.0165  0.0166  0.01705 2.6815  0.01705]\n",
      " [0.01695 0.0162  0.0162  0.01665 7.30317 0.01665]]\n",
      "pred [[0.03976408]\n",
      " [0.03923462]\n",
      " [0.03967093]\n",
      " [0.04005292]\n",
      " [0.03981559]\n",
      " [0.039391  ]\n",
      " [0.03903204]\n",
      " [0.03883038]\n",
      " [0.03907786]\n",
      " [0.03992631]\n",
      " [0.04064935]\n",
      " [0.04048742]\n",
      " [0.03984754]\n",
      " [0.0394046 ]\n",
      " [0.03907932]\n",
      " [0.03946433]\n",
      " [0.03951492]\n",
      " [0.0391998 ]\n",
      " [0.03919501]\n",
      " [0.03896379]\n",
      " [0.03931542]\n",
      " [0.0393906 ]\n",
      " [0.03940313]\n",
      " [0.03933317]\n",
      " [0.0407383 ]\n",
      " [0.04127611]\n",
      " [0.04107039]\n",
      " [0.04125914]\n",
      " [0.04151941]\n",
      " [0.03955634]\n",
      " [0.040068  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "print (\"pred\",p)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    #print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot((p * 1000 ) ,color='red', label='prediction')\n",
    "plt2.plot(y_test * 1000,color='blue', label='y_test')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_last(stock_name ):\n",
    "    from pandas_datareader import data\n",
    "\n",
    "    # Only get the adjusted close.\n",
    "    df = data.DataReader(stock_name,\n",
    "                       start='2017-01-01',\n",
    "                       end='2018-09-21',\n",
    "                       data_source='yahoo')\n",
    "\n",
    "    df['Volume'] /= 100\n",
    "\n",
    "    df = df[-30:-1]\n",
    "\n",
    "    \n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_prediction(stock, seq_len):\n",
    "\n",
    "    data_x = stock\n",
    "    data_y = stock\n",
    "    #print(\"DATA Y 0 :\",data_y)\n",
    "    print (\"Amount of features TOT :\",len(data_x[0]) )\n",
    "    #data_x = np.delete(data_x,np.s_[len(stock[0])-1],axis=1)\n",
    "    data_y = np.delete(data_y,np.s_[0:len(stock[0])-1],axis=1)\n",
    "    #print(\"DATA Y :\",data_y)\n",
    "    amount_of_features = len(data_x[0]) \n",
    "    \n",
    "    print (\"Amount of features found:\",amount_of_features)\n",
    "    \n",
    "    sequence_length = seq_len \n",
    "    result_x = []\n",
    "    result_y = []\n",
    "    for index in range(len(data_x) - sequence_length ):\n",
    "        result_x.append(data_x[index: index + sequence_length + 1])\n",
    "        result_y.append(data_y[index: index + sequence_length + 1])\n",
    "\n",
    "    result_x = np.array(result_x)\n",
    "    result_y = np.array(result_y)\n",
    "    \n",
    "    #x_train = train_x[:, :-1]\n",
    "    x_test = result_x[:, :-1]\n",
    "    #x_test = result_x[:, :-1]\n",
    "   \n",
    "    #y_train = train_y[:, -1]\n",
    "    y_test = result_y[:, -1]\n",
    "    \n",
    "    #print (\"x_test before:\",x_test)\n",
    "    #print (\"y_test before:\",y_test)\n",
    "    \n",
    "    #x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "    print (\"x_test:\",x_test)\n",
    "    print (\"y_test:\",y_test)\n",
    "\n",
    "    return [x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2 = load_data_last ('TRAN.BA' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features TOT : 6\n",
      "Amount of features found: 6\n",
      "x_test: [[[ 0.04665  0.0435   0.0455   0.0466   4.31157  0.0466 ]\n",
      "  [ 0.0456   0.0427   0.045    0.0437   4.34113  0.0437 ]\n",
      "  [ 0.0464   0.044    0.044    0.04535  2.97752  0.04535]\n",
      "  [ 0.047    0.043    0.0449   0.0462   1.87038  0.0462 ]\n",
      "  [ 0.0481   0.04625  0.0463   0.04735  2.95647  0.04735]]\n",
      "\n",
      " [[ 0.0456   0.0427   0.045    0.0437   4.34113  0.0437 ]\n",
      "  [ 0.0464   0.044    0.044    0.04535  2.97752  0.04535]\n",
      "  [ 0.047    0.043    0.0449   0.0462   1.87038  0.0462 ]\n",
      "  [ 0.0481   0.04625  0.0463   0.04735  2.95647  0.04735]\n",
      "  [ 0.04735  0.0455   0.04735  0.0459   1.95428  0.0459 ]]\n",
      "\n",
      " [[ 0.0464   0.044    0.044    0.04535  2.97752  0.04535]\n",
      "  [ 0.047    0.043    0.0449   0.0462   1.87038  0.0462 ]\n",
      "  [ 0.0481   0.04625  0.0463   0.04735  2.95647  0.04735]\n",
      "  [ 0.04735  0.0455   0.04735  0.0459   1.95428  0.0459 ]\n",
      "  [ 0.04795  0.04365  0.047    0.044    5.28106  0.044  ]]\n",
      "\n",
      " [[ 0.047    0.043    0.0449   0.0462   1.87038  0.0462 ]\n",
      "  [ 0.0481   0.04625  0.0463   0.04735  2.95647  0.04735]\n",
      "  [ 0.04735  0.0455   0.04735  0.0459   1.95428  0.0459 ]\n",
      "  [ 0.04795  0.04365  0.047    0.044    5.28106  0.044  ]\n",
      "  [ 0.0458   0.0432   0.04445  0.04565  3.20753  0.04565]]\n",
      "\n",
      " [[ 0.0481   0.04625  0.0463   0.04735  2.95647  0.04735]\n",
      "  [ 0.04735  0.0455   0.04735  0.0459   1.95428  0.0459 ]\n",
      "  [ 0.04795  0.04365  0.047    0.044    5.28106  0.044  ]\n",
      "  [ 0.0458   0.0432   0.04445  0.04565  3.20753  0.04565]\n",
      "  [ 0.04665  0.045    0.045    0.0459   6.54971  0.0459 ]]\n",
      "\n",
      " [[ 0.04735  0.0455   0.04735  0.0459   1.95428  0.0459 ]\n",
      "  [ 0.04795  0.04365  0.047    0.044    5.28106  0.044  ]\n",
      "  [ 0.0458   0.0432   0.04445  0.04565  3.20753  0.04565]\n",
      "  [ 0.04665  0.045    0.045    0.0459   6.54971  0.0459 ]\n",
      "  [ 0.045    0.04     0.045    0.04205  6.30776  0.04205]]\n",
      "\n",
      " [[ 0.04795  0.04365  0.047    0.044    5.28106  0.044  ]\n",
      "  [ 0.0458   0.0432   0.04445  0.04565  3.20753  0.04565]\n",
      "  [ 0.04665  0.045    0.045    0.0459   6.54971  0.0459 ]\n",
      "  [ 0.045    0.04     0.045    0.04205  6.30776  0.04205]\n",
      "  [ 0.04385  0.04025  0.04205  0.0434   4.64999  0.0434 ]]\n",
      "\n",
      " [[ 0.0458   0.0432   0.04445  0.04565  3.20753  0.04565]\n",
      "  [ 0.04665  0.045    0.045    0.0459   6.54971  0.0459 ]\n",
      "  [ 0.045    0.04     0.045    0.04205  6.30776  0.04205]\n",
      "  [ 0.04385  0.04025  0.04205  0.0434   4.64999  0.0434 ]\n",
      "  [ 0.0429   0.04     0.042    0.042    6.22736  0.042  ]]\n",
      "\n",
      " [[ 0.04665  0.045    0.045    0.0459   6.54971  0.0459 ]\n",
      "  [ 0.045    0.04     0.045    0.04205  6.30776  0.04205]\n",
      "  [ 0.04385  0.04025  0.04205  0.0434   4.64999  0.0434 ]\n",
      "  [ 0.0429   0.04     0.042    0.042    6.22736  0.042  ]\n",
      "  [ 0.04275  0.04025  0.042    0.04055  3.67822  0.04055]]\n",
      "\n",
      " [[ 0.045    0.04     0.045    0.04205  6.30776  0.04205]\n",
      "  [ 0.04385  0.04025  0.04205  0.0434   4.64999  0.0434 ]\n",
      "  [ 0.0429   0.04     0.042    0.042    6.22736  0.042  ]\n",
      "  [ 0.04275  0.04025  0.042    0.04055  3.67822  0.04055]\n",
      "  [ 0.04145  0.0381   0.03945  0.04025 10.01068  0.04025]]\n",
      "\n",
      " [[ 0.04385  0.04025  0.04205  0.0434   4.64999  0.0434 ]\n",
      "  [ 0.0429   0.04     0.042    0.042    6.22736  0.042  ]\n",
      "  [ 0.04275  0.04025  0.042    0.04055  3.67822  0.04055]\n",
      "  [ 0.04145  0.0381   0.03945  0.04025 10.01068  0.04025]\n",
      "  [ 0.0446   0.041    0.041    0.0442  20.4847   0.0442 ]]\n",
      "\n",
      " [[ 0.0429   0.04     0.042    0.042    6.22736  0.042  ]\n",
      "  [ 0.04275  0.04025  0.042    0.04055  3.67822  0.04055]\n",
      "  [ 0.04145  0.0381   0.03945  0.04025 10.01068  0.04025]\n",
      "  [ 0.0446   0.041    0.041    0.0442  20.4847   0.0442 ]\n",
      "  [ 0.0442   0.042    0.0442   0.04235  6.92935  0.04235]]\n",
      "\n",
      " [[ 0.04275  0.04025  0.042    0.04055  3.67822  0.04055]\n",
      "  [ 0.04145  0.0381   0.03945  0.04025 10.01068  0.04025]\n",
      "  [ 0.0446   0.041    0.041    0.0442  20.4847   0.0442 ]\n",
      "  [ 0.0442   0.042    0.0442   0.04235  6.92935  0.04235]\n",
      "  [ 0.0425   0.0385   0.0409   0.04055  6.81713  0.04055]]\n",
      "\n",
      " [[ 0.04145  0.0381   0.03945  0.04025 10.01068  0.04025]\n",
      "  [ 0.0446   0.041    0.041    0.0442  20.4847   0.0442 ]\n",
      "  [ 0.0442   0.042    0.0442   0.04235  6.92935  0.04235]\n",
      "  [ 0.0425   0.0385   0.0409   0.04055  6.81713  0.04055]\n",
      "  [ 0.044    0.0412   0.0415   0.0437   3.92954  0.0437 ]]\n",
      "\n",
      " [[ 0.0446   0.041    0.041    0.0442  20.4847   0.0442 ]\n",
      "  [ 0.0442   0.042    0.0442   0.04235  6.92935  0.04235]\n",
      "  [ 0.0425   0.0385   0.0409   0.04055  6.81713  0.04055]\n",
      "  [ 0.044    0.0412   0.0415   0.0437   3.92954  0.0437 ]\n",
      "  [ 0.0475   0.0442   0.04515  0.04555  8.5979   0.04555]]\n",
      "\n",
      " [[ 0.0442   0.042    0.0442   0.04235  6.92935  0.04235]\n",
      "  [ 0.0425   0.0385   0.0409   0.04055  6.81713  0.04055]\n",
      "  [ 0.044    0.0412   0.0415   0.0437   3.92954  0.0437 ]\n",
      "  [ 0.0475   0.0442   0.04515  0.04555  8.5979   0.04555]\n",
      "  [ 0.0485   0.045    0.04555  0.04795 10.81823  0.04795]]\n",
      "\n",
      " [[ 0.0425   0.0385   0.0409   0.04055  6.81713  0.04055]\n",
      "  [ 0.044    0.0412   0.0415   0.0437   3.92954  0.0437 ]\n",
      "  [ 0.0475   0.0442   0.04515  0.04555  8.5979   0.04555]\n",
      "  [ 0.0485   0.045    0.04555  0.04795 10.81823  0.04795]\n",
      "  [ 0.0491   0.04665  0.048    0.04755  4.02354  0.04755]]\n",
      "\n",
      " [[ 0.044    0.0412   0.0415   0.0437   3.92954  0.0437 ]\n",
      "  [ 0.0475   0.0442   0.04515  0.04555  8.5979   0.04555]\n",
      "  [ 0.0485   0.045    0.04555  0.04795 10.81823  0.04795]\n",
      "  [ 0.0491   0.04665  0.048    0.04755  4.02354  0.04755]\n",
      "  [ 0.0485   0.046    0.047    0.0478   3.15377  0.0478 ]]\n",
      "\n",
      " [[ 0.0475   0.0442   0.04515  0.04555  8.5979   0.04555]\n",
      "  [ 0.0485   0.045    0.04555  0.04795 10.81823  0.04795]\n",
      "  [ 0.0491   0.04665  0.048    0.04755  4.02354  0.04755]\n",
      "  [ 0.0485   0.046    0.047    0.0478   3.15377  0.0478 ]\n",
      "  [ 0.0497   0.0472   0.04795  0.049    4.76569  0.049  ]]\n",
      "\n",
      " [[ 0.0485   0.045    0.04555  0.04795 10.81823  0.04795]\n",
      "  [ 0.0491   0.04665  0.048    0.04755  4.02354  0.04755]\n",
      "  [ 0.0485   0.046    0.047    0.0478   3.15377  0.0478 ]\n",
      "  [ 0.0497   0.0472   0.04795  0.049    4.76569  0.049  ]\n",
      "  [ 0.05095  0.0472   0.05     0.0478   6.41655  0.0478 ]]\n",
      "\n",
      " [[ 0.0491   0.04665  0.048    0.04755  4.02354  0.04755]\n",
      "  [ 0.0485   0.046    0.047    0.0478   3.15377  0.0478 ]\n",
      "  [ 0.0497   0.0472   0.04795  0.049    4.76569  0.049  ]\n",
      "  [ 0.05095  0.0472   0.05     0.0478   6.41655  0.0478 ]\n",
      "  [ 0.04825  0.04625  0.0477   0.0474   1.59208  0.0474 ]]\n",
      "\n",
      " [[ 0.0485   0.046    0.047    0.0478   3.15377  0.0478 ]\n",
      "  [ 0.0497   0.0472   0.04795  0.049    4.76569  0.049  ]\n",
      "  [ 0.05095  0.0472   0.05     0.0478   6.41655  0.0478 ]\n",
      "  [ 0.04825  0.04625  0.0477   0.0474   1.59208  0.0474 ]\n",
      "  [ 0.0495   0.04705  0.0474   0.049    4.22401  0.049  ]]\n",
      "\n",
      " [[ 0.0497   0.0472   0.04795  0.049    4.76569  0.049  ]\n",
      "  [ 0.05095  0.0472   0.05     0.0478   6.41655  0.0478 ]\n",
      "  [ 0.04825  0.04625  0.0477   0.0474   1.59208  0.0474 ]\n",
      "  [ 0.0495   0.04705  0.0474   0.049    4.22401  0.049  ]\n",
      "  [ 0.0519   0.04875  0.049    0.0509   5.62478  0.0509 ]]\n",
      "\n",
      " [[ 0.05095  0.0472   0.05     0.0478   6.41655  0.0478 ]\n",
      "  [ 0.04825  0.04625  0.0477   0.0474   1.59208  0.0474 ]\n",
      "  [ 0.0495   0.04705  0.0474   0.049    4.22401  0.049  ]\n",
      "  [ 0.0519   0.04875  0.049    0.0509   5.62478  0.0509 ]\n",
      "  [ 0.05235  0.0505   0.05175  0.0509   9.42133  0.0509 ]]]\n",
      "y_test: [[0.0459 ]\n",
      " [0.044  ]\n",
      " [0.04565]\n",
      " [0.0459 ]\n",
      " [0.04205]\n",
      " [0.0434 ]\n",
      " [0.042  ]\n",
      " [0.04055]\n",
      " [0.04025]\n",
      " [0.0442 ]\n",
      " [0.04235]\n",
      " [0.04055]\n",
      " [0.0437 ]\n",
      " [0.04555]\n",
      " [0.04795]\n",
      " [0.04755]\n",
      " [0.0478 ]\n",
      " [0.049  ]\n",
      " [0.0478 ]\n",
      " [0.0474 ]\n",
      " [0.049  ]\n",
      " [0.0509 ]\n",
      " [0.0509 ]\n",
      " [0.0529 ]]\n",
      "X_test (31, 5, 6)\n",
      "y_test (31, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_future, y_test_future = load_data_prediction(df_new2 / 1000, 5)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "#print(df_new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0175  0.017   0.01745 0.0172  3.12659 0.0172 ]\n",
      " [0.018   0.0169  0.018   0.01745 6.2795  0.01745]\n",
      " [0.0178  0.0166  0.01705 0.01755 4.63835 0.01755]\n",
      " [0.01715 0.0165  0.0166  0.01705 2.6815  0.01705]\n",
      " [0.01695 0.0162  0.0162  0.01665 7.30317 0.01665]]\n",
      "[[41.71251 ]\n",
      " [41.73867 ]\n",
      " [42.319824]\n",
      " [42.49669 ]\n",
      " [42.771164]\n",
      " [43.167076]\n",
      " [42.919952]\n",
      " [43.109478]\n",
      " [42.66053 ]\n",
      " [43.445156]\n",
      " [47.98227 ]\n",
      " [50.20374 ]\n",
      " [51.390484]\n",
      " [51.22215 ]\n",
      " [50.510406]\n",
      " [45.275436]\n",
      " [45.207596]\n",
      " [44.882664]\n",
      " [44.5483  ]\n",
      " [43.97974 ]\n",
      " [42.63468 ]\n",
      " [42.667984]\n",
      " [42.788185]\n",
      " [43.966393]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "pred = model.predict(X_test_future) \n",
    "print(pred * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXd4FFUXxt9LAkZqECLF0IQAKZCYBEikI01AFBUFAQsiKCCoSLOCXUFAivQmhqIg5UMsUUBQMZDAQmjSDL0GQgshZc/3x8mmkbKb3Z3Zcn7Ps89mNzNzz24m79w59xRFRBAEQRCcnxJ6GyAIgiDYBhF0QRAEF0EEXRAEwUUQQRcEQXARRNAFQRBcBBF0QRAEF0EEXRAEwUUQQRcEQXARRNAFQRBcBE8tB6tcuTLVrl1byyEFQRCcnri4uEtE5FPUdpoKeu3atREbG6vlkIIgCE6PUuq4OduJy0UQBMFFEEEXBEFwEUTQBUEQXARNfej5kZaWhlOnTiElJUVvUwSd8PLygq+vL0qWLKm3KYLg1Ogu6KdOnUK5cuVQu3ZtKKX0NkfQGCJCYmIiTp06hTp16uhtjiA4Nbq7XFJSUlCpUiURczdFKYVKlSrJHZog2ADdBR2AiLmbI39/QbANDiHogiAIrsrNm8BrrwHHjtl/LBF0O1C2bFkAwJkzZ/Dkk08Wuu2UKVOQnJyc9bpLly5ISkqyq32CIGjH0qXAV18Bp0/bfywRdDPJyMiweJ/q1atj5cqVhW6TV9A3bNgAb29vi8cSBMHxIAKmTweCg4EWLew/ngg6gISEBDRs2BB9+vSBv78/nnzySSQnJ6N27doYPXo0QkND8f333+Po0aPo3LkzwsLC0LJlSxw8eBAA8N9//yEyMhKNGjXCO++8k+u4QUFBAPiC8OabbyIoKAiNGzfGtGnTMHXqVJw5cwZt27ZF27ZtAXB5hEuXLgEAJk2ahKCgIAQFBWHKlClZx/T398dLL72EwMBAdOzYEbdu3dLy6xIEwUy2bgX27AGGDgW0WCrSPWwxF6+9BhgMtj1mSAiQKYaF8e+//2L+/Plo3rw5+vfvj6+//hoAUKlSJezcuRMA8NBDD2HWrFnw8/NDTEwMBg8ejI0bN2L48OF45ZVX8Oyzz2LGjBn5Hn/OnDlISEiAwWCAp6cnLl++jHvuuQeTJk3Cpk2bULly5Vzbx8XFYeHChYiJiQERoVmzZmjdujUqVqyIw4cPY9myZZg7dy6eeuoprFq1Cn379rXyixIEwdZMnw5UrAg884w248kMPZMaNWqgefPmAIC+ffvizz//BAA8/fTTAIAbN27g77//Rs+ePRESEoJBgwbh7NmzAIC//voLvXv3BgD069cv3+P/9ttvGDRoEDw9+Rp6zz33FGrPn3/+iR49eqBMmTIoW7YsHn/8cWzduhUAUKdOHYSEhAAAwsLCkJCQYMUnFwTBHpw6BfzwA/Dii0Dp0tqM6VgzdDNm0vYib+ic6XWZMmUAAEajEd7e3jAUcAehZejdXXfdlfWzh4eHuFwEwQGZPRswGoFXXtFuTJmhZ3LixAls27YNALB06VK0yLOCUb58edSpUwfff/89AM5w3L17NwCgefPmWL58OQAgKioq3+N36NABs2fPRnp6OgDg8uXLAIBy5crh+vXrd2zfsmVLrFmzBsnJybh58yZWr16Nli1b2uCTCoJgb27fBubMAbp1A+6/X7txRdAzadCgAWbMmAF/f39cuXIFr+RzWY2KisL8+fMRHByMwMBArF27FgDw1VdfYcaMGWjUqBFOFxCbNGDAANSsWRONGzdGcHAwli5dCgAYOHAgOnfunLUoaiI0NBTPP/88mjZtimbNmmHAgAF44IEHbPypBUGwB99/D1y4wIuhWqKISLPBwsPDKW+DiwMHDsDf318zG/IjISEB3bp1w969e3W1w51xhPNAEGxFRASQlATs3w+UsMG0WSkVR0ThRW0nM3RBEAQbsmMHEBMDDBliGzG3BBF0cOy3zM4FQbAF06cDZcsCzz2n/dhmRbkopRIAXAeQASCdiMKVUhMAPAIgFcBRAC8QkeSsC4Lgtly8CCxfDrz0ElC+vPbjWzJDb0tEITn8ONEAgoioMYBDAMba3DpBEAQnYu5cIDWV3S16UGyXCxH9SkTpmS//AeBrG5MEQRCcj/R0YOZMoH17QK/1fXMFnQD8qpSKU0oNzOf3/QH8lN+OSqmBSqlYpVTsxYsXi2unIAiCQ7N2LWeHah2qmBNzBb0FEYUCeBjAEKVUK9MvlFJvA0gHkG9GDRHNIaJwIgr38fGx2mBH5Pnnny+yqmLOQl2FbWOKT7eUNWvWQCmVVTCsKDsHDBiA/fv337FNWloaxowZAz8/P4SGhiIyMhI//cTX6pyFwwRByM306UCtWpxMpBdmCToRnc58vgBgNYCmAKCUeh5ANwB9SMuAdjtBRDAajbqNb42gL1u2DC1atMCyZcvM2n7evHkICAi44/13330XZ8+exd69e7Fz506sWbMm30xWQRCy2bsX2LwZGDwY8PDQz44iBV0pVUYpVc70M4COAPYqpToDGAWgOxElF3YMRyYhIQENGjTAs88+i6CgIJw8eRK//vorIiMjERoaip49e+LGjRsAgA8++ABNmjRBUFAQBg4ciKKuYXFxcQgODkZwcHCuKowJCQlo2bIlQkNDERoair///hsAMGbMGGzduhUhISGYPHlygdvl5caNG/jzzz8xf/78rBIEAF+ghg4digYNGqB9+/a4cOFC1u/atGmDvEleycnJmDt3LqZNm5ZVL6ZKlSp46qmn7hgzv9K+N2/eRNeuXREcHIygoCCsWLEi63to3bo1wsLC0KlTp6yiZoLgKkyfDnh5cSEuPTEnbLEKgNWZxac8ASwlop+VUkcA3AUgOvN3/xDRy9YYo1f13MOHD2Px4sWIiIjApUuX8NFHH+G3335DmTJl8Pnnn2PSpEl47733MHToULz33nsAuKri+vXr8cgjjxR43BdeeAHTp09Hq1atMHLkyKz37733XkRHR8PLywuHDx9G7969ERsbi88++wwTJ07E+vXrAbDA5rddXtauXYvOnTujfv36qFSpEuLi4hAWFobVq1fj33//xf79+3H+/HkEBASgf//+Bdp75MgR1KxZE+WLiLcqqLTvsWPHUL16dfz4448AgKtXryItLQ2vvvoq1q5dCx8fH6xYsQJvv/02FixYUOgYguAsJCUBS5ZwidxKlfS1pUhBJ6JjAILzeb+eXSzSgVq1aiEiIgIA8M8//2D//v1ZpXRTU1MRGRkJANi0aRO++OILJCcn4/LlywgMDCxQ0JOSkpCUlIRWrXi5oV+/flm+6LS0NAwdOhQGgwEeHh44dOhQvscwd7tly5Zh+PDhAIBevXph2bJlCAsLw5YtW9C7d294eHigevXqaNeuXTG/odzkLO0LIKu0b+fOnTFixAiMHj0a3bp1Q8uWLbF3717s3bsXHTp0AMCNPqpVq2YTOwTBEVi4EEhO1ncx1IRDlc/Vq3quSZgAdlN06NDhDl90SkoKBg8ejNjYWNSoUQPjxo1DSkpKscabPHkyqlSpgt27d8NoNMLLy6vY212+fBkbN25EfHw8lFLIyMiAUgoTJkyw2K569erhxIkTuHbtWpGz9PyoX78+du7ciQ0bNuCdd97BQw89hB49eiAwMDCrkqUguBJGIzBjBtC8OeAItfMk9T8PERER+Ouvv3DkyBEA7Bc+dOhQlnhXrlwZN27cKDKqxdvbG97e3lmNMnKW1b169SqqVauGEiVKYMmSJVn9SvOW0i1ou5ysXLkS/fr1w/Hjx5GQkICTJ0+iTp062Lp1K1q1aoUVK1YgIyMDZ8+exaZNmwq1uXTp0njxxRcxfPhwpKamAgAuXryYVTLYREGlfc+cOYPSpUujb9++GDlyJHbu3IkGDRrg4sWLWYKelpaGffv2FWqHIDgLv/wCHD3qGLNzQAT9Dnx8fLBo0SL07t0bjRs3RmRkJA4ePAhvb2+89NJLCAoKQqdOndCkSZMij7Vw4UIMGTIEISEhuRZQBw8ejMWLFyM4OBgHDx7MukNo3LgxPDw8EBwcjMmTJxe4XU6WLVuGHj165HrviSeeyHrfz88PAQEBePbZZ7NcRybya8rx0UcfwcfHBwEBAQgKCkK3bt3umK0XVNo3Pj4eTZs2RUhICMaPH4933nkHpUqVwsqVKzF69GgEBwcjJCSkwMVdQXA2pk0DqlYFHn9cb0sYKZ/rpjRq1Ajr1q1DnTp19DYFgIOeB0Yj0LcvEB8PhIYCYWH8HBLC1ZcEt+bIEcDPDxg3Dnj/ffuOZW75XIfyoQva0KFDBzRq1MhhxNxhmToVWLYMePBBIDoa+OYbfl8poGFDFnjTIyQEKFdOX3sFTZkxA/D0BAbmlzuvEyLobkh0dLTeJjg+e/YAo0cDjzzCOd1KAWfPAnFx2Y+NG4Fvv+XtlQLq188W+IceAoLvCA4TXIQbNzi6pWdPwJGCthxC0IlI0ybLgmPhcEnGt24BvXsD99wDzJ/PYg3wf263brlzu8+dyy3yf/wBLF3KnQ2mTOHVMjm3XY6oKODqVcdZDDWhu6B7eXkhMTERlSpVElF3Q4gIiYmJBYZu6sLIkdw77JdfgKLqD1WtCnTtyg8TZ88CL78MDBsGHDgAfPUVULKkfW0WNIOIF0MfeADIE2egO7oLuq+vL06dOgWpxOi+eHl5wdfXQaovr1/PztHXXwc6dizeMapVA374ARg7FpgwATh8mLsGe3vb1lZBF/74A9i3D1iwwPFuvnSPchEEh+HcOaBxYxbkmBguzmEtCxcCgwYB99/PF4t6LpNg7bY88QSL+smTwN13azOmRLkIgiUYjcALLwDXr3PZPFu5gF54AahbF+jRA2jWjGfurVvb5tiCVSQm8tq3JVy/DqxZw145rcTcEkTQBQHgcnk//8zulnzKCltFq1bA9u28mNqhAzBrFlBIkTRBGx5/HNiyxfL9PD15icQREUEXhPh4YNQoFtxXXrHPGHXrAtu2AU89xTVWDxwAPvtM3+LZbsz27Szmo0YBXbpYtm+VKkDt2nYxy2pE0AX3xhSi6O2dO0TRHnh7Axs2AMOHAxMnAocOcfybZJ1qzuTJQPnywDvvuFY+mNRyEdyb0aM5ZGHRIuDee+0/nqcnu3WmTwd+/BFo0QI4ccL+4wpZnDjBQUcDB7qWmAMi6II7s2EDBxQPHw507qzt2EOGsKD/9x/QtClH1QiaMG0aP7/6qr522AMRdME9OX+eI1AaN2Zfth506sR+9TJlgDZtgBztAwX7cP06MGcOp+zXrKm3NbZHBF1wP4hYzK9d4zR9PbNUAwJ4dt6kCfvyDx/WzxY3YMEC/rO//rreltgHEXTB/Zg+HfjpJ16YDAzU2xqgcmW2CQB27tTXFhcmI4PL67RowV4uV0QEXXAv4uM5K6RrV2DwYL2tyaZ+fS7odeCA3pa4LKtXAwkJwBtv6G2J/RBBF9yHW7e4Nbu3t+MV4vDy4vIAIuh2Y9Ik/oq7d9fbEvshceiC+zBmDLB3L7tbtAhRtBR/f67yKNicbdv4MXWqa+dymTVDV0olKKXilVIGpVRs5nv3KKWilVKHM58r2tdUQbCC//7j/+YhQ7QPUTQXf39ONkpP19sSl2PyZKBCBV4Ld2Uscbm0JaKQHBW/xgD4nYj8APye+VoQHJPFi9nFMmqU3pYUTEAAkJoKHDumtyUuRUICsGoVF7109aRca3zojwJYnPnzYgCPWW+OINgBo5HL2Hbo4NjBx6Ym2eJHtylTp/J6sysmEuXFXEEnAL8qpeKUUqaWqFWI6Gzmz+cAVLG5dYJgCzZu5HxvR7/fNgm6+NFtxtWrwLx5XBPNUXqo2BNzF0VbENFppdS9AKKVUgdz/pKISCmVb6eMzAvAQACo6cizI8F1WbiQI1sec/CbyHLlWHVkhm4z5s/n7FBXDlXMiVkzdCI6nfl8AcBqAE0BnFdKVQOAzOcLBew7h4jCiSjcp6j+jIJga5KSuKnEM8/omxFqLv7+Iug2Ij2d27m2bg2EheltjTYUKehKqTJKqXKmnwF0BLAXwDoAz2Vu9hyAtfYyUhCKzfLlQEqK8zSUCAhgQTca9bbE6fnhB/a0ucvsHDDP5VIFwGrFSRieAJYS0c9KqR0AvlNKvQjgOICn7GemIBSTBQuARo2A0FC9LTEPf3/g5k3g1CnHXsB1cIiAL7/kFq7duultjXYUKehEdAxAcD7vJwJ4yB5GCYJN2LsX2LGDg5AdKSu0MEzt7/bvF0G3gr//5q5EM2ZwhIu74EYfVXA7Fi4ESpYE+vTR2xLzkdBFmzBpElCxIvDcc0Vv60qIoAuuSVoasGQJ8MgjgDMtxleuzA8JXSw2R49yIa6XX+ZS8+6ECLrgmvz4I3DxovMshubEtDAqFIupU7nT39CheluiPSLogmuyYAFQrRp3BXI2TEW6KN/UDqEQkpI49rxXL6B6db2t0R4RdMH1OHeO+4U++yxP1ZyNgADgyhXgQr6pHUIhzJ3LQUKu2pGoKETQBddjyRJuT+Poqf4FIQujxSItjd0tbdsCDzygtzX6IIIuuBZEHN3y4INAgwZ6W1M8pKZLsVi5ksP33SmRKC8i6IJrERPDM1tnXAw1cd99XNdFZuhmQ8Shig0aAF266G2Nfjihg1EQCmHhQqB0aS6v56woJTVdLOTPP4HYWGDWLPdKJMqLG390weVITgaWLQN69uQZrjMTEOBQLpfYWGDFCr2tKJgvvwQqVQL69dPbEn0RQRdch1WruFaqsy6G5sTfHzh7luPwdObcOeDhhzkU8Jdf9LbmTnbuBNau5e6CpUvrbY2+iKALrsPChUDdukCrVnpbYj2mmi46u12I+Pp44wYXunr+eeDSJV1NuoO33wbuuce9F0NNiKALrsGxY8CmTaw4zlKIqzAcJHRxxgzg55+BiRM5iuTyZeCllxwn5+mPP9i+MWO4CbS7I4IuuAamJtCuUo2pdm3grrt09aPv3w+MHMnulsGDgeBg4JNPgDVrOBFXb4iAsWM5I9Qd0/zzQwRdcH6MRmDRIqBjR6BGDb2tsQ0eHkDDhrrN0G/f5iKVZcuyeJtuel5/HWjXDhg+HDh8WBfTsvjf/4Bt24D33wfuvltfWxwFEXTB+XGWJtCWomPo4rvvAgYDi3nVqtnvlyjBN0OlSgF9+3J2ph5kZLDv3M/P9f7s1iCCLjg/CxZw8etHH9XbEtsSEAAkJHA4poZs2sQ+80GDuPpwXnx9gdmzuYHERx9paloWS5dy/5IPP+SS9wIjgi44N1euOFcTaEvw92dH8b//ajbklStc08zPj2O7C6JnT97uo4+4O5CWpKYC773H9Vp69tR2bEdHBF1wbpYvZ4evM6f6F4TGNV2IgFde4bjzqKiim0NMmwbUqsWul2vXNDERADBnDt+4fPKJe2eF5od8HYJzs2AB0Lixa5bX8/PjxVGN/OhRUZwNOn48EB5e9Pbly3Nhy+PHeZFUC27c4LuC1q2ds9S9vRFBF5yX+HjOSe/f3zViz/NSqhRn82gg6AkJnGnZogUwerT5+zVvDrz1FgcZrVxpL+uy+eor4Px54NNPXfNPbi0i6ILz4oxNoC1Fg5ouGRnZNVCWLOGbAkt47z2gaVNg4EAuX2svEhOBL74AuncHIiPtN44zY7agK6U8lFK7lFLrM18/pJTaqZQyKKX+VErVs5+ZgpCH1FTg22/5v7tyZb2tsR/+/sCRI/x57cTnn3O1whkzOJ/JUkqW5D/F7ducqGs02tpC5vPPuVTPxx/b5/iugCUz9OEAct77zQTQh4hCACwF8I4tDROEQnHmJtCW4O8PpKezqNuB2FhOzHn6aetudPz8gClTgN9/52dbc/o0L8L27QsEBdn++K6CWYKulPIF0BXAvBxvE4DymT9XAHDGtqYJQiGYmkB37Ki3JfbFjkW6bt5kEa9WDZg503qf9IABnAowdiywZ49tbDTxwQfsGho/3rbHdTXMnaFPATAKQM6bqQEANiilTgHoB+AzG9smCPlz7hzw009ct8UZm0AXwOXL+bxpaqNnBz/6iBGcvr94MedlWYtSwLx5XPmwTx8gJcX6YwJs4/z5nOhUp45tjumqFCnoSqluAC4QUVyeX70OoAsR+QJYCGBSAfsPVErFKqViL168aLXBgoDNm3m69uSTeltiM9av5wYN7dsDv/2Wo5phmTLs2LbxDH3dOs72fPNNbqpsKypX5rXqvXu5AqItePddrlP2jjh1i8ScGXpzAN2VUgkAlgNop5T6EUAwEcVkbrMCwIP57UxEc4gonIjCfXx8bGGz4O4YDLwS16iR3pbYjPnzeZa8fz/QoQPQrBknwBqNsHlNl3PngBdfBEJCOHXe1nTuDLz6KocY/vqrdcfatYtj419/HahSxTb2uTJFCjoRjSUiXyKqDaAXgI0AHgVQQSlVP3OzDsi9YCoI9mP3bvYtlyqltyU24coVYMMGjhA5doxnzpcvA088AQQGAouMzyLtwBG+K7GCI0dYZDt14gSdqCie+dqDzz/nP1G/fhwBk55evOO89RZf6N5807b2uSrFikMnonQALwFYpZTaDfahj7SlYYJQIAYDTy9dhFWrOCqxTx8uRzNwIHDwILdHLVUKeOGXXqh7ex+mjr9iUZ2utDQutDViBFfi9fMDXnuN3//mm+z1Vntw993Ad98BPj4s6n5+wNdfA7dumX8MU/OKsWMBb2/72epSEJFmj7CwMBIEqzh7lgggmjRJb0tsRtu2RPXrExmNd/7OaCT6ccI+aoEtBBBVrkz04YdEly/nf6wLF4gWLybq2ZOofHn+qkqVIurYkWjqVKKjR+37WfKSkUG0di1RRATbUqUK0aefEiUlFb6f0UgUGUlUvTpRcrI2tjoyAGLJDI0VQReci59/5tN240a9LbEJp04RKUU0blwhG12+TATQ1leiqEsX/vjlyhGNHEl0+jTRrl0s8hERfCyAqFo1ogEDiFavJrp+XbOPUyBGI9GmTXxhAfhiM3Ys0fnz+W+/bh1vN3u2pmY6LCLogmvy+ed82iYm6m2JTZg4kT/OoUNFbFi1KtELLxARkcFA1KsXUYkSvK/p0bQp0fjxRHFxPDN2VGJj+Q5CKSIvL6IhQ4j++y/79+npREFBRPXqEaWm6mamQ2GuoCvKio+yP+Hh4RQbG6vZeIIL8swzwF9/cYk/FyAsjGunbN9exIYPPcSZQP/8k/XWkSPsC69Th/t+5uws5AwcOsS1Wb75hqN5nnmGC4Pt2sV+9+XLOYNVAJRScURUZA1MEXTBuQgI4BW2tWv1tsRqDh7kiMTJk3mxslCGDuXKWUlJLldm8NQpYNIkju5JTubQez8/IC5O6p2bMFfQ5esSnIfkZO7eExystyU2YelSFiyzZqH+/txF4ozrVdjw9WVBP3GC68pUr84XORFzy5GvTHAe9u7le3MXCFkkYkFv145rqRSJHWu6OAqVKgHjxrErpk0bva1xTkTQBedh925+dgFB37EDOHqU/cZmoXE7OsE5EUEXnAeDgfueFadot4NhytJ8/HEzd6hShVMmXXiGLliPCLrgPBgM7D93cudqejrXJ+nWDahQwcydlLJ5TRfB9XDu/wzBfTAa2eXiAguimzZxX0yz3S0m/P3F5SIUigi64BwcO8Zx2C7gP4+K4pl5ly4W7hgQwF2aLl2yi12C8yOCLjgHBgM/O7mg37rFZXGfeIILcVmEaWFU3C5CAYigC86BwcAplYGBeltiFT/+yI2OLXa3AG4RuihYhwi64BwYDFwD1uJprWMRFcVx58WKs65RAyhdWgRdKBARdME5cIEa6KZGFr168c2GxZQowRc1WRgVCkAEXXB8Ll0CTp92ekH/4QduZFEsd4uJgACZoQsFIoIuOD4ukiEaFQXUr88VFouNvz9w8iQ74gUhDyLoguNjinBx4hj006eBzZt5dm5VsUTTwujBg7YwS3AxRNAFx8dg4BJ8Pj56W1JsVqzgglxWuVsAqekiFIoIuuD4uMCCaFQU0KQJ1/m2irp1gZIlxY8u5IsIuuDYpKSwe8GJBf3gQWDnThvMzgHA05Md8SLoQj6IoAuOzf79XM3KiQV92TILGlmYg9R0EQrAbEFXSnkopXYppdZnvlZKqY+VUoeUUgeUUsPsZ6bgtjh5yj8Ru1vMbmRhDgEBXNsmJcVGBxRcBUtm6MMB5LzPex5ADQANicgfwHIb2iUIjMHATSbr1tXbkmJhcSMLc/D35+qThw7Z8KCCK2CWoCulfAF0BTAvx9uvAPiAiIwAQEQXbG+e4Pbs3g00buy0NdCXLrWwkYU5SE0XoQDM/S+ZAmAUAGOO9+oCeFopFauU+kkpZe36vSDkhsipI1zS04Hly4GuXS1oZGEO9evzBU4EXchDkYKulOoG4AIRxeX51V0AUogoHMBcAAsK2H9gpujHXrx4sVhGpqU59hpQcjKQkaG3FS5IQgJ3undSQTc1sujTx8YH9vIC6tRx7H8KQRfMmaE3B9BdKZUA9pO3U0p9C+AUgB8yt1kNoHF+OxPRHCIKJ6Jwn2ImhgwYwItKt28Xa3ebQ8STowkTuGpe+fLAyJF6W+WCOPmC6NKlfG5Y3MjCHKSmi5APRQo6EY0lIl8iqg2gF4CNRNQXwBoAbTM3aw3Abis0/frxTGfZMnuNUDQpKcAvvwDDhvH6XEAAMGoUkJQE1KwJ/Pqrfra5LAYDuxaCgvS2xGJu3QJWrSpmIwtz8PcH/v2X/TqCkIk1K02fAXhCKRUP4FMAA2xj0p089BCvi02axLNjrThzBpg3D3jsMaByZaBzZ34dGAjMmgWcOMGa8/zzfPd79ap2trkFu3ezv7h0ab0tsRhTIwubu1tMBASwL/LYMTsNIDgjnpZsTESbAWzO/DkJHPlid5QC3niDhfP334H27e031p49PLNav56z+wCegT/3HC9utW0L3H137n0iI/lCs3070KGD/WxzOwwG/nKdkKVLgapVi9nIwhxy1nSpX99OgwjOhtPEgvXqxf8gX35pvzF27gRCQ4GPPmLR/vRTFviEBGDGDPaF5hVzAGjalC86//w88fs/AAAfEklEQVRjP9vcjitXgOPHndJ/fuUKz9CL3cjCHBo25Gfxows5sGiGrid33QUMHQq88w6wb599Wku++y4vYu3bZ1lWX4UKPGESQbchphroTlgyd9UqbmRhN3cLwCeqr68IupALp5mhA8CgQTxDnjLF9sfeto3bg40aVbwU7chIFnQtffwujZNGuBAB06ezi9uqRhbmIDVdhDw4laBXrsy+7CVLgAs2zkt9910utz10aPH2j4gALl8GDh+2rV1uy+7dQJUq7GdzIn77jU0fMcLKRhbmEBDApRyNxqK3FdwCpxJ0AHjtNY5HnznTdsf84w9ebB07FihbtnjHiIjgZ3G72AgnzRCdMIHv8OzqbjHh7w/cvMkt6QQBTijoDRoA3brxIqUtis0R8ey8enXg5ZeLf5yAAHZriqDbgNRUXshwMkHftQuIjuZchbvu0mBAU6TL0qV84h05wrGz4vdzW5xmUTQnb7zBmaNRUcCLL1p3rOhoYOtW9nvmF8FiLiVKcLTLtm3W2SOAF/rS0pxuQXTiRL7Ds2ZiYBGNGnHW0ltv5X7f05P9kz4+BT83aQLcf79Ghgpa4ZSC3qYNT94mTQL69y++r9I0O69Zk8sLWEtEBPDJJ3wXXKaM9cdzW0wRLk40Qz9+nPuGDh8OeHtrNGjFipzdlpAAXLwIXLqU/7PBwM9XruTev00bnhE9/rhTJm8Jd+KUgm5KNHr2WU6579SpeMdZv56TgebOtc0tcmQkr0/FxgKtW1t/PLfFYODbJSdKmJkyhc/L117TeGAfH/ObZ6enA4mJwLlzfPIvWMB1NYYMAXr35tlRkyYarOYK9kKRhv628PBwio2NtcmxUlOB2rW5zEdx6qgYjRxWdu0aBwqULGm9TYmJfEf76afAmDHWH89tadeOb3NiYvS2xCyuXAFq1AB69OAILKfBaAS2bGFhX7mSC9AEBvKsvW9f8y8Ugt1RSsVlVrYtFKdbFDVRqhTw6qvsA4+Pt3z/1at5IjhunG3EHAAqVeKu7rIwagVOWAN91iy+/rz5pt6WWEiJEux2+eYb4OxZYPZsXgR44w2OEnjiCU55lQJgToPTCjrAiUalSwOTJ1u2X0YG8N57nD1t09ZgYD+6JBhZwcmTPOV1kgXRlBTgq6+Ajh2dxuT8qVABGDiQT974eA7V2bqVQ8pq1eKFV0mycHicWtDvuYcLdkVFsVvQXFas4AS78eNtX2sjMpJL/SYk2Pa4boOTLYh++y3/vV2qHn5QEBdNOnUK+OEHLnD0+ee8ptG2LYdJSoNqh8SpBR3gRai0NODrr83bPj2d3SyNGwNPPml7eyTByEoMBl6Ua9RIb0uKxGjkUMUHHuASzy5HqVK8MPC///Gd08cfczhPnz7AfffxP9++fXpbKeTA6QXdzw/o3p0F/datordfsoTvHMePt0/f4UaN2A0kgl5MDAagXj2gXDm9LSmS9eu5x8TIkW4QGFK9Ortdjhzhhav27fmfLigIePBBYOFCXkgQdMXpBR3gNZzExKIjDFJTgQ8+4OiWRx+1jy2enhz5JQlGxcSJFkQnTGD3cs+eeluiISVKsJivWAGcPs23KJcvc8hj9erA4MGcMivogksIesuWLNKTJxdep2jBAvZtf/ihfWdUERF8TptzxyDk4No17sDjBKuL27YBf/4JvP46X8TdEh8frkJ24AAXROrenWfqoaFAeDhHzVy7preVboVLCLop0ejgQeDnn/PfJiWFG1c8+CC3krMnERHsq5eJioXs2cPPTjBDnzCBEzWtLT3hEigFtGrFt8hnzgBTp/Lt8Msvc4D+3LkS9qURLiHoAN/23ndfwR2NZs/mO0R7z86B7IVRcbtYiJPUQD90CFizhr0Lxa3O6bJUrMgJIrt380JSWBiHQz78sFSF1ACXEfSSJTl0duPGbF0wkZzM2Ztt2nASor2pWpWzWGVh1EIMBk61rV5db0sKZdKk7MQ2oQCUApo14wLxM2ZwTHtQELtkZLZuN1xG0AHgpZe4KFbeRKMZMzhW+MMPtbPFlGAkWIDBwP5zBw4ZuXABWLSI6whVqaK3NU5AiRJ8KxMfz3de/ftzstLp03pb5pK4lKBXrMjny7Jl7MoDgOvXOSeiUyegRQvtbImI4LyMU6e0G9OpSU8H9u51eHfL9OnsHh4xQm9LnIz77wc2beK02k2beLa+ZInM1m2MSwk6wOVL09N5Vg7w+ZOYqO3sHOCMUUBm6UXx33/AnDkAHfyXW1E5sKDfvMnnVffu3GhFsJASJdgvumcPFwF79lngsccsS/MWCsVsQVdKeSildiml1ud5f6pS6obtTSsedevyOTJrVnaYbPfuHBuuJSEhXJJXBL1wpkzhmjx/fZd5C+7Agr5gAYdcjxqltyVOTr16HOY4aRKXSg0M5Ntqma1bjSUz9OEADuR8QykVDqCiTS2yAW+8wf947dtzR64PPtDehlKlOBxXBL1wTBVyJyy9j6+ADjr1TU9n/XnwQX4IVuLhwUH8BgPXiHnmGa7ueP683pY5NWYJulLKF0BXAPNyvOcBYAIAh5uvNG/OM/KDBzmcUa88lchIbnaRmqrP+I7O7dscq1+hArDuaCAO1u1qu1rGNmbVKk5Kc6kiXI5AgwacoTVhArBhA8/Wv/tOb6tszw1tnBjmztCngIU7Zx7mUADriOhsYTsqpQYqpWKVUrEXL14sppmWoRTw9tsc8TJ+vCZD5ktEBIuWqYCgkJvdu/li99mnBC/cwpfpw/U2KV+IWG/q12f3nWBjPDy4mPyuXbx4+vTTnIzkKuzZwzUiitOJx0KKFHSlVDcAF4goLsd71QH0BDCtqP2JaA4RhRNRuI+GHVAefZTdLabG6HoglRcLx+Ru6Rp+Hs9jEb452twh18c2bwbi4jiyxR4F3YRM/P2Bv//mEr0jR3LTDWcnOZnb+5UqxWU57Yw5p2dzAN2VUgkAlgNoB2AfgHoAjmS+X1opdcReRhYXW9c6t5QaNTh7VTJG8ycmBqhWDfC9sBNvYBLSjCUwdareVt3JF18A997LQRmCnfH05LTulBQdGrTagTff5OYL33yjSUu/IgWdiMYSkS8R1QbQC8BGIqpIRFWJqHbm+8lEVM/OtjolkmBUMDExnEyodhvghyPo0S0dM2dy7oCjEB/P9YGGDQO8vPS2xk3w8wPeeYd96Rs26G1N8Vm7Fpg5k0W9QwdNhpQbSDsTEcGx1rJ4n5vERC6t3awZ2Jlepw5GvV0SSUnA/Pl6W5fNpEm8FvPKK3pb4maMGgUEBHCWqTPWWT99mrMcQ0O5MYhGWCToRLSZiLrl876UKCoA8aPnz/bt/NysGbJqoDdrxqWQJ0/mLlR6k5HBRbh69uR2h4KGlCrFrpfjx4H339fbGsswGtk/l5LC7fpKldJsaJmh25mwMHYLiqDnZvt2jkYKb3iDW0hlJhSNHAmcOAF8/73OBoJDTpOSuGyEoAMtWnDW2eTJwM6deltjPhMncpXAqVM1z6sQQbczd9/NWiWCnpuYGA45LpcQz3GBmYLetSvQsCGHCeqdOBgdzc8u2S/UWfjsM16RHjiQs7scndhYjpl+8kl2uWiMCLoGREQAO3bY5nwsrCOTs0DEM/RmzcAzGSBL0EuU4DUkg4Err+pJdDRHmmkYbSvkxdubCzLFxXFlNEfmxg0OUaxWjQsU6VA1VARdAyIjeV1n717rjjN3LodCHjtmG7v04uhRXhRtlvIH8O67XKS+Ro2s3/ftyzXlJ0zQz8YbNzjcVKPgBKEwevYEunThyJcTJ/S2pmCGDeOT+9tvufSrDoiga4AtFkZPnuQaNWfOcEVJZybmH/alNI0axv+o//tfrtnMXXfxZ4yOvrNZiVZs2cILsyLoDoBSXOaSCBg6VH9fXH6sWMHNO95+m9vx6YQIugbUqcO37dYI+quvctTFq68C69cD69bZzj5NIULMl3+iNG4isFdjYPVqoHTpOzZ7+WVu7zZxog42gi8mXl7a1tAXCqF2ba6y97//AT/8oLc1uTl+nBdvIyKA997T1RQRdA1Qit0uxc0YXbOGcxTGDbuML5ssR2D9NAwbxlnFTkV6OtC/P2IMpRBe/Qw8oxYXWIzL25s7UC1frs9ddnQ0i7kkEzkQw4fzosarr3JdD0cgPR3o04cXt6KidC8uJ4KuERER3Fw4MdGy/a5dA4YOSkVj7+N4fUJ1lHy2N2Ycao/jx4FPO2zkSnW2XP2/eZOLl3z5JfsdbEVKCtCzJ24vWgqDRxiaPVOvyMIopszvKVNsZ4Y5nDkD7Nsn7haHw9OTF5LOnwfGjtXbGuaTT4C//uKM0Pvv19sagIg0e4SFhZG7snEjEUC0YYOZOxiNRFu20LDaa0ghg/7xak30xhtEf/9N9MUX1LfKL1QKKXQI9YgqViTq1YtoyRKiixfNN8poJDp2jCgqimjIEKLQUCIPDzbU9OjUiSgurjgfOZtr14jatiUC6J/XlxNAtHKlebv27UtUpgzR5cvWmWAJixfzR9+5U7sxBQt47TUipfh/QU/+/JOoRAk+Se0MgFgyQ2NF0DXi+nX+27/7bhEbZmQQrV1LFBlJ2xFOChk0pNl2osTEXJudPUtUvryROgafJeNzzxPdey//OZUiiowk+vBDViSjMXun5GSirVuJvviCqEcPoipVsoW7TBkW3bfeIlq/nujUKaIJE/hiARA9/TTRoUOWf/ALF4jCw/lCsWQJTZ3Khzt50rzdDQbe/pNPLB+6uPTtS+Tjw38KwQG5fp2oRg2ioCCi1FR9bEhKIqpVi6hOHaKrV+0+nAi6AxIcTNShQwG/TE0lWrSIKCCACKC0WnUpxPcCVauaQUlJ+e/y1Vf8F/z+e2L12b6daNw4oiZNsoW6WjWevTdtSlSyZPb7deuycn39NdGuXURpafkPcuUK0dtvE5UuzaI8cCCLvTmcOEHUsCGRlxfRunVERNSnD1H16ubtbqJjR6KqVYlSUizbrzgYjTxWr172H0uwgnXrtL/SmzAa+QTx8CDatk2TIUXQHZBBg4jKl88z87txg2jKFJ5xAESNGhFFRdHEL9KLdE2kpRGFhBDddx9PWnJx7hxfIHr2ZAVt1Ypo9Gie/Z8/b7nxZ88SDR3KFwUvL6JRo+64a8jFwYP8mcqXJ/rjj6y369XjmwNLiI7mr2bePMvNtpT4eB5r/nz7jyVYyZNP8rl45Ii245p8ch99pNmQIugOyMKF/I3v3UssuO+/T3TPPfxmy5ZEP/5IZDTSf//xhPiRR3J7TPLj779595Ej7W8/EbHPvV8/du1UqED08cd8UcpJXBz7LHx8cjmiL11iWz/7zLIhjUa+cDVsaH83yKRJbOPx4/YdR7ABp0/zhKF9+6L/UawhI4N9hBs3Es2cSVS2LE+Q0tPtN2YeRNAdkIObz/JM0+8zFkSAqHt3or/+ytrGaCTq0oVd2uaKSv/+RJ6eRPv22cnw/Nizh20H2Bc/YwbR7dtEmzcTlStHVLMm0b//5tplwwbefNMmy4eLiuJ9Mz03duPhh4nq17fvGIIN+fprPjGWLLHuOBkZ/A/3++9Es2YRvfkm0WOPEQUG8l1AzkABX192J2qIuYKueFttCA8Pp9jYWM3GcwiOHeMOw6tWwRizHZVxCU94b8TcYfFAr1539Mj7/nvgqae4Dvfrr5s3xMWLXNQtOJhLo2haQuLvvzmEbMsWTv44e5YzqaKjAV/fXJuOG8e5IVevAuXKWTZMWhr3PahRA9i61WbW5+L2bS6T+8ILjl82RMjEaOSEgcOHgU2bOBQ2OZnDb5OTC3/cvMkhkEeOcMr+7dvZx73rLqBuXaBePT7x6tXL/tnXV/N2aEqpOCIKL3JDc1TfVg+3maHv389RJiEh2Vf10FCijz+mzi2vU2Bg/rtducILcqGhBa9RFsSsWTxMVJT15luM0Uj0009EYWFEDz5YYOhk584cmFBcpkzhz2ivdahNm/j4a9bY5/iCnYiP51vUnLPowh4eHnwXWbUqz8Afe4xn5LNm8Qz9+HGHC3GCzNA1hIiLjmTOxHHwIL8fGQk88QTw+OM8awXPUMeNA65cASpUyH2YwYO5pv/27VxH3RIyMjh56dQpHj7vsfWGCKhcGejRA5g3r3jHuHEDqFmTewivWmVb+wCu/fTZZ5z85Wjfn1AEO3ZwNljp0kU/SpbUpRKiNZg7Q/fUwhiX4+pVLue5Ywerb0wMt5wqUYIL8wwZwsp133137BoRweK2YwfQvn32+9u2AbNmcXazpWIO8B3gzJlA06bc4EXr7MqiOHoUuHw5s2RuMSlbllvBffop32H7+dnOPoC9RM2aiZg7JU2a8MPNkdT/orh9m0V7+nTguefY512xInc9GDOG+2G2bMn1j8+dYz/e0KH5ijnAggvkLtSVlsb1+++7j2fwxSU8nGsETZvGZjkSMTH8bI2gA1zGo2RJXmOwJVeucG+CnBdZQXA2ZIael8OHuTbD9u08jd69O7vBZZUqrMh9+vBsIDwcqFTJosN7e3Pv25yFur78kmulr11r+WJhXj7+GFi5km8StmwpslyKZsTEcLPlwEDrjlO1Kl9XFy4Exo/nZja2YONGXl+T+i2CU2OOo91WD4deFE1OJho+PHvhpFw5onbtOBln1SoOU7JRrGv//hx+bjRyToSXl+XJNoWxYAF/hIULbXdMa2nalKh1a9sc6+BBjvp8+23bHI+Ik77KldMvk1wQCgMSh24B27dz1grA2ZAHDth1lXvOHB7q3385rb1cOfOz6c0hI4ODTXx8tC1qVRApKUSlSnFyqa144gkib2/bldG4/35O5BIER8RcQTf7hlwp5aGU2qWUWp/5Okop9a9Saq9SaoFSSt9CwMUhLY1XECMjOYQiOpod0A0b2tVXYepg9MYbwK+/cgXOAlzuxaJECW7wkpjIDVT0xmAAUlOt95/nZPRoICmJo4Ks5dgxfoi7RXB2LFGt4QAO5HgdBaAhgEYA7gYwwIZ22Z/9+1lZP/gAeOYZID5esxWxgAD2lf/4I7vkX3nF9mOEhPDa7KxZvNinJ7ZaEM1Jkya8Lj1pEpdatwZTM2oRdMHZMUvQlVK+ALoCyIogJqINOW4HtgPwLWh/h8JoZBUIDeVWOKtWAd98w6uVGuHhwULu4cEzTHslnX3wAa/jDh7MH1svYmKA6tVtexcCcILquXP857OG6Gi2rUED29glCHph7gx9CoBRAO6QhUxXSz8AP9vQLvuQkMAd5keMADp14tCSxx/XxZTPP+dolJAQ+41RoQL35NyxA5g/337jFEVMjG1n5ybateNAoy++4MSq4pCRAfz+O8/OnSzXRBDuoEhBV0p1A3CBiOIK2ORrAFuIKN8KG0qpgUqpWKVU7MWLF60w1QqIWNEaNQJ27uSYtzVrePqqE2FhwGOP2X+cZ57hMPm33mKfs9YkJnJSkT0EXSmepR89WvzM0Z07OQZd3C2CK2DODL05gO5KqQQAywG0U0p9CwBKqfcB+AB4o6CdiWgOEYUTUbiPj48NTLaQc+eA7t2BAQN4OhcfDzz/vNtMx5QCpk7lLM3x47Uff/t2fraHoAN8UWzQgLNHi1PFIjqanyWhSHAFihR0IhpLRL5EVBtALwAbiaivUmoAgE4AehORjh7aPGRkcCW1y5eB774DgoJ41WvyZL63rlVLbws1JyQEeOklDuDZv1/bsWNiOOomvOg6ccWiRAmOeDEYOGLIUn77jatU2ipBSRD0xKLiXEqpNgDeJKJuSql0AMcBXM/89Q9EVGjierGLc82eDaxfz+EMRT3S0/MOyqtmecrUuhuXLnHtk/BwFj6tblAefpjL3OzZY78xUlO50mndusDmzebvl5zMVRyGDQMmTLCbeYJgNXYpzkVEmwFszvxZu7IBiYnAmTOAlxc/ypfP/vmuu7J/zvvw8QGefJKLf7g5lStz1MuwYVxiQAv/PRG7XOy97lyqFK9zv/46l1SIjDRvvy1b+GIg7hbBVZDyuW5Eejq7X5KT2fXi5WXf8Q4fBurXB+bO5SUMe3LjBnvTWrbk9W5zGDGCa65ducJVVQXBUTF3hu4gpZsELfD05AXS//7jgmD2xh4JRQVRtmz23ce+febtEx3NzW5EzAVXQQTdzWjXjntufPIJN8OwJ6YKiwEB9h3HxNChLM5ffFH0tufOccCThCsKroQIuhsycSJnjo4aZd9xYmJ4EVar9ouVKnFd+aVLgePHC9/299/5WQRdcCVE0N2Q2rVZzJcts2/DZYNBG3dLTkaM4AieolxK0dHcEPqBB7SxSxC0QATdTRk9GqhRg/3OxU2bLwyDgYtZai3ovr5A377ct7SgxGQiFvSHHnKcBiCCYAvkdHZTSpdm14vBUPymzYWh5YJoXkaN4pSEqVPz//2BAxwFK+4WwdUQQXdjevYEWrfmmulXrtj22DExXMHQ1hUWzaFhQ+7RPX06cP36nb83pfuLoAuuhgi6G6MU8NVXLObvv2/bY9urwqK5jBlTcAOM334D6tXjtQRBcCVE0N2c4GBg0CDg66+5mrAtuHTJfhUWzSVnA4zbt7PfT0vj8gAyOxdcERF0AR9+yNUUhg8vXsXCvNi7wqK5jB0LnD2buwHGP/9wVqkIuuCKiKALqFSJRX3jRmD1auuPZ6qwGBZm/bGsIb8GGNHRbFvbtvraJgj2QARdAMBul0aNuHH1rVvWHWv7diAwkNPx9UQp9qUfOZLdACM6mt0xGnYcFATNEEEXAGTXeTl+nMMZi4upwqLe7hYTPXpwA4zPPuNF0u3bxd0iuC4i6EIWbdpwKOOnn3L/7OJw5Aj3FnEUQS9RguPSd+3iNnxGowi64LqIoAu5mDCBZ9nFrfOiZ0JRQfTty/HwM2dysbCICL0tEgT7IIIu5KJWLfY7r1jBfbVTUizbPyaGfedaVVg0B1MDDIDvQkqV0tUcQbAbIujCHYwaxa1YBwwAqlYFXnyRI2DMqfmidYVFc3npJV707dNHb0sEwX6IoAt3cPfd7HP+9VduVff995ykU7Mmz3R37sw/Xj0lRZ8Ki+ZQtiz3Ne3dW29LBMF+iKAL+eLpyYuHixYB588D333H4X7TpnF8eUAAx64fPZq9j14VFgVBYETQhSK5+26Oflmzhjv9zJ4NVKkCvPce10SJjGSh37CBtxdBFwR9kCbRQrE5eZKbZERFsTsD4HrkJ0/qa5cguBo2bxKtlPJQSu1SSq3PfF1HKRWjlDqilFqhlJLYATejRg1eQN29m/tzvv02J/AIgqAPlrhchgM4kOP15wAmE1E9AFcAvGhLwwTnIigI+OgjiSIRBD0xS9CVUr4AugKYl/laAWgHYGXmJosBPGYPAwVBEATzMHeGPgXAKADGzNeVACQRUXrm61MAdOhNIwiCIJgoUtCVUt0AXCCiuOIMoJQaqJSKVUrFXiyoa68gCIJgNebM0JsD6K6USgCwHOxq+QqAt1LKM3MbXwCn89uZiOYQUTgRhfv4+NjAZEEQBCE/ihR0IhpLRL5EVBtALwAbiagPgE0Anszc7DkAa+1mpSAIglAk1iQWjQbwhlLqCNinPt82JgmCIAjFwbPoTbIhos0ANmf+fAxAU9ubJAiCIBQHSf0XBEFwETRN/VdKXQRwvJi7VwZwyYbmOCvyPWQj3wUj3wPjyt9DLSIqMqpEU0G3BqVUrDm1DFwd+R6yke+Cke+Bke9BXC6CIAgugwi6IAiCi+BMgj5HbwMcBPkespHvgpHvgXH778FpfOiCIAhC4TjTDF0QBEEoBKcQdKVUZ6XUv5nNNMbobY9eKKUSlFLxSimDUsptWj8ppRYopS4opfbmeO8epVS0Uupw5nNFPW3UggK+h3FKqdOZ54RBKdVFTxu1QClVQym1SSm1Xym1Tyk1PPN9tzsn8uLwgq6U8gAwA8DDAAIA9FZKBehrla60JaIQNwvPWgSgc573xgD4nYj8APye+drVWYQ7vweAG82EZD42aGyTHqQDGEFEAQAiAAzJ1AR3PCdy4fCCDi4vcISIjhFRKrji46M62yRoCBFtAXA5z9uPghurAG7SYKWA78HtIKKzRLQz8+fr4E5q98ENz4m8OIOg3wcgZ9thd26mQQB+VUrFKaUG6m2MzlQhorOZP58DUEVPY3RmqFJqT6ZLxq3cDEqp2gAeABADOSecQtCFbFoQUSjY/TREKdVKb4McAeJQLXcN15oJoC6AEABnAXyprznaoZQqC2AVgNeI6FrO37nrOeEMgn4aQI0crwtspuHqENHpzOcLAFbDvatdnldKVQOAzOcLOtujC0R0nogyiMgIYC7c5JxQSpUEi3kUEf2Q+bbbnxPOIOg7APgppeoopUqBm2ys09kmzVFKlVFKlTP9DKAjgL2F7+XSrAM3VgHcuMGKScAy6QE3OCcym9TPB3CAiCbl+JXbnxNOkViUGYo1BYAHgAVE9LHOJmmOUup+8Kwc4Dr2S93le1BKLQPQBlxN7zyA9wGsAfAdgJrgCp5PEZFLLxgW8D20AbtbCEACgEE5/MguiVKqBYCtAOKR3bj+LbAf3a3Oibw4haALgiAIReMMLhdBEATBDETQBUEQXAQRdEEQBBdBBF0QBMFFEEEXBEFwEUTQBUEQXAQRdEEQBBdBBF0QBMFF+D8ICZv/yN98OwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot((pred * 1000 ) ,color='red', label='prediction')\n",
    "plt2.plot(y_test_future * 1000,color='blue', label='real data Adj Close')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
