{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name,shift_window, normalized=0):\n",
    "    from pandas_datareader import data\n",
    "\n",
    "    # Only get the adjusted close.\n",
    "    df = data.DataReader(stock_name,\n",
    "                       start='2017-1-1',\n",
    "                       end='2018-08-20',\n",
    "                       data_source='yahoo')\n",
    "\n",
    "    df['Adj Close'] = df['Adj Close'].shift(-shift_window)\n",
    "    df['Difference'] = ( df['Adj Close'].shift(-shift_window) / df['Adj Close'] ) \n",
    "    df['Difference'] = df['Difference'] * 10000 - 10000\n",
    "    print(df.head())\n",
    "    df = df[shift_window*2:-shift_window*2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  High         Low        Open       Close   Volume  \\\n",
      "Date                                                                  \n",
      "2017-01-02  285.000000  281.000000  281.000000  284.000000  12161.0   \n",
      "2017-01-03  289.000000  283.000000  284.000000  285.000000  40930.0   \n",
      "2017-01-04  289.500000  283.049988  284.899994  288.500000  71984.0   \n",
      "2017-01-05  290.200012  288.000000  288.649994  288.000000  32706.0   \n",
      "2017-01-06  288.000000  283.600006  287.950012  284.299988  24804.0   \n",
      "\n",
      "             Adj Close  Difference  \n",
      "Date                                \n",
      "2017-01-02  280.925018  106.382690  \n",
      "2017-01-03  278.932617  107.143670  \n",
      "2017-01-04  282.817749   91.581518  \n",
      "2017-01-05  282.668335   79.295212  \n",
      "2017-01-06  282.917358  211.268137  \n"
     ]
    }
   ],
   "source": [
    "stock_name = 'TS.BA'\n",
    "df = get_stock_data(stock_name,5,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  High         Low        Open  Close   Volume   Adj Close  \\\n",
      "Date                                                                         \n",
      "2017-01-16  285.500000  283.250000  284.000000  285.0  11588.0  285.905945   \n",
      "2017-01-17  284.600006  280.000000  284.500000  283.0  15736.0  290.886841   \n",
      "2017-01-18  288.950012  280.000000  283.200012  286.5  23484.0  293.875427   \n",
      "2017-01-19  288.950012  285.500000  286.399994  286.0  22531.0  291.285370   \n",
      "2017-01-20  290.500000  286.399994  286.399994  290.0  35837.0  287.350403   \n",
      "\n",
      "            Difference  \n",
      "Date                    \n",
      "2017-01-16 -357.143238  \n",
      "2017-01-17 -520.548103  \n",
      "2017-01-18 -576.271767  \n",
      "2017-01-19 -560.877978  \n",
      "2017-01-20 -466.285850  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  288.95001221,   285.5       ,   286.3999939 ,   286.        ,\n",
       "       22531.        ,   291.28536987,  -560.87797814])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head(5))\n",
    "df_val = df.values\n",
    "df_val[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "\n",
    "    data = stock\n",
    "    amount_of_features = len(data[::-1][0]) - 1\n",
    "    \n",
    "    \n",
    "    sequence_length = seq_len \n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length + 1])\n",
    "\n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1][:,-1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    print (\"x_test:\",x_test)\n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "    print (\"y_test:\",y_test)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_v2(stock, seq_len):\n",
    "\n",
    "    data_x = stock\n",
    "    data_y = stock\n",
    "    #print(\"DATA Y 0 :\",data_y)\n",
    "    print (\"Amount of features TOT :\",len(data_x[0]) )\n",
    "    data_x = np.delete(data_x,np.s_[len(stock[0])-1],axis=1)\n",
    "    data_y = np.delete(data_y,np.s_[0:len(stock[0])-1],axis=1)\n",
    "    #print(\"DATA Y :\",data_y)\n",
    "    amount_of_features = len(data_x[0]) \n",
    "    \n",
    "    print (\"Amount of features found:\",amount_of_features)\n",
    "    \n",
    "    sequence_length = seq_len \n",
    "    result_x = []\n",
    "    result_y = []\n",
    "    for index in range(len(data_x) - sequence_length ):\n",
    "        result_x.append(data_x[index: index + sequence_length + 1])\n",
    "        result_y.append(data_y[index: index + sequence_length + 1])\n",
    "\n",
    "    result_x = np.array(result_x)\n",
    "    result_y = np.array(result_y)\n",
    "    \n",
    "    row = round(0.92 * result_x.shape[0])\n",
    "    train_x = result_x[:int(row), :]\n",
    "    train_y = result_y[:int(row), :]\n",
    "    \n",
    "    x_train = train_x[:, :-1]\n",
    "    x_test = result_x[int(row):, :-1]\n",
    "   \n",
    "    y_train = train_y[:, -1]\n",
    "    y_test = result_y[int(row):, -1]\n",
    "    \n",
    "    #print (\"x_test before:\",x_test)\n",
    "    #print (\"y_test before:\",y_test)\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "    print (\"x_test:\",x_test)\n",
    "    print (\"y_test:\",y_test)\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features TOT : 7\n",
      "Amount of features found: 6\n",
      "x_test: [[[   507.8500061     485.            507.8500061     503.29998779\n",
      "    38753.            476.04998779]\n",
      "  [   497.95001221    476.04998779    497.95001221    481.1000061\n",
      "    59136.            481.        ]\n",
      "  [   488.            480.            481.            487.1499939\n",
      "    50405.            500.5       ]\n",
      "  [   500.            476.04998779    499.95001221    480.29998779\n",
      "   101013.            516.34997559]\n",
      "  [   502.5           489.04998779    489.04998779    493.8999939\n",
      "    52305.            521.95001221]]\n",
      "\n",
      " [[   497.95001221    476.04998779    497.95001221    481.1000061\n",
      "    59136.            481.        ]\n",
      "  [   488.            480.            481.            487.1499939\n",
      "    50405.            500.5       ]\n",
      "  [   500.            476.04998779    499.95001221    480.29998779\n",
      "   101013.            516.34997559]\n",
      "  [   502.5           489.04998779    489.04998779    493.8999939\n",
      "    52305.            521.95001221]\n",
      "  [   494.5           471.            494.5           476.04998779\n",
      "    21512.            516.09997559]]\n",
      "\n",
      " [[   488.            480.            481.            487.1499939\n",
      "    50405.            500.5       ]\n",
      "  [   500.            476.04998779    499.95001221    480.29998779\n",
      "   101013.            516.34997559]\n",
      "  [   502.5           489.04998779    489.04998779    493.8999939\n",
      "    52305.            521.95001221]\n",
      "  [   494.5           471.            494.5           476.04998779\n",
      "    21512.            516.09997559]\n",
      "  [   488.95001221    470.            476.            481.\n",
      "    29171.            508.5       ]]\n",
      "\n",
      " [[   500.            476.04998779    499.95001221    480.29998779\n",
      "   101013.            516.34997559]\n",
      "  [   502.5           489.04998779    489.04998779    493.8999939\n",
      "    52305.            521.95001221]\n",
      "  [   494.5           471.            494.5           476.04998779\n",
      "    21512.            516.09997559]\n",
      "  [   488.95001221    470.            476.            481.\n",
      "    29171.            508.5       ]\n",
      "  [   509.95001221    491.04998779    491.04998779    500.5\n",
      "    84024.            505.45001221]]\n",
      "\n",
      " [[   502.5           489.04998779    489.04998779    493.8999939\n",
      "    52305.            521.95001221]\n",
      "  [   494.5           471.            494.5           476.04998779\n",
      "    21512.            516.09997559]\n",
      "  [   488.95001221    470.            476.            481.\n",
      "    29171.            508.5       ]\n",
      "  [   509.95001221    491.04998779    491.04998779    500.5\n",
      "    84024.            505.45001221]\n",
      "  [   519.            500.5           500.5           516.34997559\n",
      "    70129.            523.95001221]]\n",
      "\n",
      " [[   494.5           471.            494.5           476.04998779\n",
      "    21512.            516.09997559]\n",
      "  [   488.95001221    470.            476.            481.\n",
      "    29171.            508.5       ]\n",
      "  [   509.95001221    491.04998779    491.04998779    500.5\n",
      "    84024.            505.45001221]\n",
      "  [   519.            500.5           500.5           516.34997559\n",
      "    70129.            523.95001221]\n",
      "  [   539.            519.            520.            521.95001221\n",
      "    99087.            528.20001221]]\n",
      "\n",
      " [[   488.95001221    470.            476.            481.\n",
      "    29171.            508.5       ]\n",
      "  [   509.95001221    491.04998779    491.04998779    500.5\n",
      "    84024.            505.45001221]\n",
      "  [   519.            500.5           500.5           516.34997559\n",
      "    70129.            523.95001221]\n",
      "  [   539.            519.            520.            521.95001221\n",
      "    99087.            528.20001221]\n",
      "  [   532.            510.04998779    521.75          516.09997559\n",
      "    68575.            529.95001221]]\n",
      "\n",
      " [[   509.95001221    491.04998779    491.04998779    500.5\n",
      "    84024.            505.45001221]\n",
      "  [   519.            500.5           500.5           516.34997559\n",
      "    70129.            523.95001221]\n",
      "  [   539.            519.            520.            521.95001221\n",
      "    99087.            528.20001221]\n",
      "  [   532.            510.04998779    521.75          516.09997559\n",
      "    68575.            529.95001221]\n",
      "  [   525.            507.            521.            508.5\n",
      "    35018.            510.        ]]\n",
      "\n",
      " [[   519.            500.5           500.5           516.34997559\n",
      "    70129.            523.95001221]\n",
      "  [   539.            519.            520.            521.95001221\n",
      "    99087.            528.20001221]\n",
      "  [   532.            510.04998779    521.75          516.09997559\n",
      "    68575.            529.95001221]\n",
      "  [   525.            507.            521.            508.5\n",
      "    35018.            510.        ]\n",
      "  [   518.95001221    505.            510.            505.45001221\n",
      "     9916.            511.1499939 ]]\n",
      "\n",
      " [[   539.            519.            520.            521.95001221\n",
      "    99087.            528.20001221]\n",
      "  [   532.            510.04998779    521.75          516.09997559\n",
      "    68575.            529.95001221]\n",
      "  [   525.            507.            521.            508.5\n",
      "    35018.            510.        ]\n",
      "  [   518.95001221    505.            510.            505.45001221\n",
      "     9916.            511.1499939 ]\n",
      "  [   529.5           505.45001221    505.45001221    523.95001221\n",
      "    90748.            512.84997559]]\n",
      "\n",
      " [[   532.            510.04998779    521.75          516.09997559\n",
      "    68575.            529.95001221]\n",
      "  [   525.            507.            521.            508.5\n",
      "    35018.            510.        ]\n",
      "  [   518.95001221    505.            510.            505.45001221\n",
      "     9916.            511.1499939 ]\n",
      "  [   529.5           505.45001221    505.45001221    523.95001221\n",
      "    90748.            512.84997559]\n",
      "  [   534.65002441    520.            524.            528.20001221\n",
      "    21074.            509.1000061 ]]\n",
      "\n",
      " [[   525.            507.            521.            508.5\n",
      "    35018.            510.        ]\n",
      "  [   518.95001221    505.            510.            505.45001221\n",
      "     9916.            511.1499939 ]\n",
      "  [   529.5           505.45001221    505.45001221    523.95001221\n",
      "    90748.            512.84997559]\n",
      "  [   534.65002441    520.            524.            528.20001221\n",
      "    21074.            509.1000061 ]\n",
      "  [   550.            529.            549.95001221    529.95001221\n",
      "    16203.            510.6499939 ]]\n",
      "\n",
      " [[   518.95001221    505.            510.            505.45001221\n",
      "     9916.            511.1499939 ]\n",
      "  [   529.5           505.45001221    505.45001221    523.95001221\n",
      "    90748.            512.84997559]\n",
      "  [   534.65002441    520.            524.            528.20001221\n",
      "    21074.            509.1000061 ]\n",
      "  [   550.            529.            549.95001221    529.95001221\n",
      "    16203.            510.6499939 ]\n",
      "  [   525.            505.            513.            510.\n",
      "    28814.            514.20001221]]\n",
      "\n",
      " [[   529.5           505.45001221    505.45001221    523.95001221\n",
      "    90748.            512.84997559]\n",
      "  [   534.65002441    520.            524.            528.20001221\n",
      "    21074.            509.1000061 ]\n",
      "  [   550.            529.            549.95001221    529.95001221\n",
      "    16203.            510.6499939 ]\n",
      "  [   525.            505.            513.            510.\n",
      "    28814.            514.20001221]\n",
      "  [   517.90002441    505.            515.            511.1499939\n",
      "    17046.            514.95001221]]\n",
      "\n",
      " [[   534.65002441    520.            524.            528.20001221\n",
      "    21074.            509.1000061 ]\n",
      "  [   550.            529.            549.95001221    529.95001221\n",
      "    16203.            510.6499939 ]\n",
      "  [   525.            505.            513.            510.\n",
      "    28814.            514.20001221]\n",
      "  [   517.90002441    505.            515.            511.1499939\n",
      "    17046.            514.95001221]\n",
      "  [   519.95001221    508.            510.            512.84997559\n",
      "    30776.            514.20001221]]\n",
      "\n",
      " [[   550.            529.            549.95001221    529.95001221\n",
      "    16203.            510.6499939 ]\n",
      "  [   525.            505.            513.            510.\n",
      "    28814.            514.20001221]\n",
      "  [   517.90002441    505.            515.            511.1499939\n",
      "    17046.            514.95001221]\n",
      "  [   519.95001221    508.            510.            512.84997559\n",
      "    30776.            514.20001221]\n",
      "  [   514.            505.1499939     513.            509.1000061\n",
      "    29730.            509.6000061 ]]\n",
      "\n",
      " [[   525.            505.            513.            510.\n",
      "    28814.            514.20001221]\n",
      "  [   517.90002441    505.            515.            511.1499939\n",
      "    17046.            514.95001221]\n",
      "  [   519.95001221    508.            510.            512.84997559\n",
      "    30776.            514.20001221]\n",
      "  [   514.            505.1499939     513.            509.1000061\n",
      "    29730.            509.6000061 ]\n",
      "  [   515.            506.            509.            510.6499939\n",
      "    16934.            507.29998779]]\n",
      "\n",
      " [[   517.90002441    505.            515.            511.1499939\n",
      "    17046.            514.95001221]\n",
      "  [   519.95001221    508.            510.            512.84997559\n",
      "    30776.            514.20001221]\n",
      "  [   514.            505.1499939     513.            509.1000061\n",
      "    29730.            509.6000061 ]\n",
      "  [   515.            506.            509.            510.6499939\n",
      "    16934.            507.29998779]\n",
      "  [   524.95001221    508.1000061     524.95001221    514.20001221\n",
      "    14281.            501.95001221]]\n",
      "\n",
      " [[   519.95001221    508.            510.            512.84997559\n",
      "    30776.            514.20001221]\n",
      "  [   514.            505.1499939     513.            509.1000061\n",
      "    29730.            509.6000061 ]\n",
      "  [   515.            506.            509.            510.6499939\n",
      "    16934.            507.29998779]\n",
      "  [   524.95001221    508.1000061     524.95001221    514.20001221\n",
      "    14281.            501.95001221]\n",
      "  [   516.            509.1499939     514.            514.95001221\n",
      "    18044.            497.70001221]]\n",
      "\n",
      " [[   514.            505.1499939     513.            509.1000061\n",
      "    29730.            509.6000061 ]\n",
      "  [   515.            506.            509.            510.6499939\n",
      "    16934.            507.29998779]\n",
      "  [   524.95001221    508.1000061     524.95001221    514.20001221\n",
      "    14281.            501.95001221]\n",
      "  [   516.            509.1499939     514.            514.95001221\n",
      "    18044.            497.70001221]\n",
      "  [   517.95001221    512.            512.            514.20001221\n",
      "    12171.            491.1000061 ]]\n",
      "\n",
      " [[   515.            506.            509.            510.6499939\n",
      "    16934.            507.29998779]\n",
      "  [   524.95001221    508.1000061     524.95001221    514.20001221\n",
      "    14281.            501.95001221]\n",
      "  [   516.            509.1499939     514.            514.95001221\n",
      "    18044.            497.70001221]\n",
      "  [   517.95001221    512.            512.            514.20001221\n",
      "    12171.            491.1000061 ]\n",
      "  [   514.            505.            510.            509.6000061\n",
      "    28270.            496.04998779]]\n",
      "\n",
      " [[   524.95001221    508.1000061     524.95001221    514.20001221\n",
      "    14281.            501.95001221]\n",
      "  [   516.            509.1499939     514.            514.95001221\n",
      "    18044.            497.70001221]\n",
      "  [   517.95001221    512.            512.            514.20001221\n",
      "    12171.            491.1000061 ]\n",
      "  [   514.            505.            510.            509.6000061\n",
      "    28270.            496.04998779]\n",
      "  [   512.15002441    499.5           510.            507.29998779\n",
      "    51163.            504.8999939 ]]\n",
      "\n",
      " [[   516.            509.1499939     514.            514.95001221\n",
      "    18044.            497.70001221]\n",
      "  [   517.95001221    512.            512.            514.20001221\n",
      "    12171.            491.1000061 ]\n",
      "  [   514.            505.            510.            509.6000061\n",
      "    28270.            496.04998779]\n",
      "  [   512.15002441    499.5           510.            507.29998779\n",
      "    51163.            504.8999939 ]\n",
      "  [   504.            494.            500.            501.95001221\n",
      "    78438.            510.1499939 ]]\n",
      "\n",
      " [[   517.95001221    512.            512.            514.20001221\n",
      "    12171.            491.1000061 ]\n",
      "  [   514.            505.            510.            509.6000061\n",
      "    28270.            496.04998779]\n",
      "  [   512.15002441    499.5           510.            507.29998779\n",
      "    51163.            504.8999939 ]\n",
      "  [   504.            494.            500.            501.95001221\n",
      "    78438.            510.1499939 ]\n",
      "  [   504.5           491.04998779    499.95001221    497.70001221\n",
      "    57708.            469.1000061 ]]\n",
      "\n",
      " [[   514.            505.            510.            509.6000061\n",
      "    28270.            496.04998779]\n",
      "  [   512.15002441    499.5           510.            507.29998779\n",
      "    51163.            504.8999939 ]\n",
      "  [   504.            494.            500.            501.95001221\n",
      "    78438.            510.1499939 ]\n",
      "  [   504.5           491.04998779    499.95001221    497.70001221\n",
      "    57708.            469.1000061 ]\n",
      "  [   501.            481.            486.            491.1000061\n",
      "    45939.            467.1499939 ]]\n",
      "\n",
      " [[   512.15002441    499.5           510.            507.29998779\n",
      "    51163.            504.8999939 ]\n",
      "  [   504.            494.            500.            501.95001221\n",
      "    78438.            510.1499939 ]\n",
      "  [   504.5           491.04998779    499.95001221    497.70001221\n",
      "    57708.            469.1000061 ]\n",
      "  [   501.            481.            486.            491.1000061\n",
      "    45939.            467.1499939 ]\n",
      "  [   503.5           493.04998779    493.04998779    496.04998779\n",
      "    18605.            468.3500061 ]]\n",
      "\n",
      " [[   504.            494.            500.            501.95001221\n",
      "    78438.            510.1499939 ]\n",
      "  [   504.5           491.04998779    499.95001221    497.70001221\n",
      "    57708.            469.1000061 ]\n",
      "  [   501.            481.            486.            491.1000061\n",
      "    45939.            467.1499939 ]\n",
      "  [   503.5           493.04998779    493.04998779    496.04998779\n",
      "    18605.            468.3500061 ]\n",
      "  [   507.04998779    496.1499939     496.1499939     504.8999939\n",
      "    19630.            472.25      ]]\n",
      "\n",
      " [[   504.5           491.04998779    499.95001221    497.70001221\n",
      "    57708.            469.1000061 ]\n",
      "  [   501.            481.            486.            491.1000061\n",
      "    45939.            467.1499939 ]\n",
      "  [   503.5           493.04998779    493.04998779    496.04998779\n",
      "    18605.            468.3500061 ]\n",
      "  [   507.04998779    496.1499939     496.1499939     504.8999939\n",
      "    19630.            472.25      ]\n",
      "  [   512.95001221    500.            504.            510.1499939\n",
      "    16766.            487.04998779]]\n",
      "\n",
      " [[   501.            481.            486.            491.1000061\n",
      "    45939.            467.1499939 ]\n",
      "  [   503.5           493.04998779    493.04998779    496.04998779\n",
      "    18605.            468.3500061 ]\n",
      "  [   507.04998779    496.1499939     496.1499939     504.8999939\n",
      "    19630.            472.25      ]\n",
      "  [   512.95001221    500.            504.            510.1499939\n",
      "    16766.            487.04998779]\n",
      "  [   484.6499939     467.            484.6499939     469.1000061\n",
      "   153200.            490.8999939 ]]\n",
      "\n",
      " [[   503.5           493.04998779    493.04998779    496.04998779\n",
      "    18605.            468.3500061 ]\n",
      "  [   507.04998779    496.1499939     496.1499939     504.8999939\n",
      "    19630.            472.25      ]\n",
      "  [   512.95001221    500.            504.            510.1499939\n",
      "    16766.            487.04998779]\n",
      "  [   484.6499939     467.            484.6499939     469.1000061\n",
      "   153200.            490.8999939 ]\n",
      "  [   479.            467.            475.04998779    467.1499939\n",
      "    26690.            502.54998779]]]\n",
      "y_test: [[ 268.35956745]\n",
      " [  29.49852507]\n",
      " [ 112.77043331]\n",
      " [-211.85296999]\n",
      " [-361.60555968]\n",
      " [-364.18563763]\n",
      " [  82.35318053]\n",
      " [  74.34252873]\n",
      " [  26.32420172]\n",
      " [   9.82125307]\n",
      " [ -65.60278358]\n",
      " [-238.23414448]\n",
      " [-334.98397109]\n",
      " [-449.24164829]\n",
      " [-265.89517559]\n",
      " [ -47.30916527]\n",
      " [ 163.36251599]\n",
      " [-574.64346799]\n",
      " [-487.68095926]\n",
      " [-558.41109507]\n",
      " [-646.66259242]\n",
      " [-452.80812271]\n",
      " [ 464.71940971]\n",
      " [ 757.78645743]\n",
      " [ 840.18374273]\n",
      " [ 597.14160311]\n",
      " [  37.98390617]\n",
      " [  84.53847928]\n",
      " [ -69.64481315]\n",
      " [-105.37730894]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[   285.5       ,    283.25      ,    284.        ,\n",
       "             285.        ,  11588.        ,    285.90594482],\n",
       "         [   284.6000061 ,    280.        ,    284.5       ,\n",
       "             283.        ,  15736.        ,    290.88684082],\n",
       "         [   288.95001221,    280.        ,    283.20001221,\n",
       "             286.5       ,  23484.        ,    293.87542725],\n",
       "         [   288.95001221,    285.5       ,    286.3999939 ,\n",
       "             286.        ,  22531.        ,    291.28536987],\n",
       "         [   290.5       ,    286.3999939 ,    286.3999939 ,\n",
       "             290.        ,  35837.        ,    287.35040283]],\n",
       " \n",
       "        [[   284.6000061 ,    280.        ,    284.5       ,\n",
       "             283.        ,  15736.        ,    290.88684082],\n",
       "         [   288.95001221,    280.        ,    283.20001221,\n",
       "             286.5       ,  23484.        ,    293.87542725],\n",
       "         [   288.95001221,    285.5       ,    286.3999939 ,\n",
       "             286.        ,  22531.        ,    291.28536987],\n",
       "         [   290.5       ,    286.3999939 ,    286.3999939 ,\n",
       "             290.        ,  35837.        ,    287.35040283],\n",
       "         [   293.95001221,    286.        ,    291.        ,\n",
       "             287.        ,  38158.        ,    275.69500732]],\n",
       " \n",
       "        [[   288.95001221,    280.        ,    283.20001221,\n",
       "             286.5       ,  23484.        ,    293.87542725],\n",
       "         [   288.95001221,    285.5       ,    286.3999939 ,\n",
       "             286.        ,  22531.        ,    291.28536987],\n",
       "         [   290.5       ,    286.3999939 ,    286.3999939 ,\n",
       "             290.        ,  35837.        ,    287.35040283],\n",
       "         [   293.95001221,    286.        ,    291.        ,\n",
       "             287.        ,  38158.        ,    275.69500732],\n",
       "         [   292.        ,    285.1000061 ,    288.5       ,\n",
       "             292.        ,  49430.        ,    275.74478149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   484.20001221,    470.        ,    484.20001221,\n",
       "             472.        ,  29258.        ,    487.1499939 ],\n",
       "         [   483.        ,    464.        ,    472.        ,\n",
       "             479.        ,  30241.        ,    480.29998779],\n",
       "         [   527.95001221,    481.        ,    481.        ,\n",
       "             516.45001221,  87800.        ,    493.8999939 ],\n",
       "         [   507.8500061 ,    485.        ,    507.8500061 ,\n",
       "             503.29998779,  38753.        ,    476.04998779],\n",
       "         [   497.95001221,    476.04998779,    497.95001221,\n",
       "             481.1000061 ,  59136.        ,    481.        ]],\n",
       " \n",
       "        [[   483.        ,    464.        ,    472.        ,\n",
       "             479.        ,  30241.        ,    480.29998779],\n",
       "         [   527.95001221,    481.        ,    481.        ,\n",
       "             516.45001221,  87800.        ,    493.8999939 ],\n",
       "         [   507.8500061 ,    485.        ,    507.8500061 ,\n",
       "             503.29998779,  38753.        ,    476.04998779],\n",
       "         [   497.95001221,    476.04998779,    497.95001221,\n",
       "             481.1000061 ,  59136.        ,    481.        ],\n",
       "         [   488.        ,    480.        ,    481.        ,\n",
       "             487.1499939 ,  50405.        ,    500.5       ]],\n",
       " \n",
       "        [[   527.95001221,    481.        ,    481.        ,\n",
       "             516.45001221,  87800.        ,    493.8999939 ],\n",
       "         [   507.8500061 ,    485.        ,    507.8500061 ,\n",
       "             503.29998779,  38753.        ,    476.04998779],\n",
       "         [   497.95001221,    476.04998779,    497.95001221,\n",
       "             481.1000061 ,  59136.        ,    481.        ],\n",
       "         [   488.        ,    480.        ,    481.        ,\n",
       "             487.1499939 ,  50405.        ,    500.5       ],\n",
       "         [   500.        ,    476.04998779,    499.95001221,\n",
       "             480.29998779, 101013.        ,    516.34997559]]]),\n",
       " array([[ -207.7679214 ],\n",
       "        [ -209.53549873],\n",
       "        [ -451.43809043],\n",
       "        [ -371.37507228],\n",
       "        [ -309.09178812],\n",
       "        [ -142.06767434],\n",
       "        [ -184.50247488],\n",
       "        [  -16.95189684],\n",
       "        [ -141.11056035],\n",
       "        [  -93.80667429],\n",
       "        [ -230.20663716],\n",
       "        [   37.59388538],\n",
       "        [   75.47149745],\n",
       "        [ -164.1206629 ],\n",
       "        [ -325.75809881],\n",
       "        [  -95.78459517],\n",
       "        [ -524.34490662],\n",
       "        [ -486.89182193],\n",
       "        [ -263.87330952],\n",
       "        [ -133.12452231],\n",
       "        [ -408.12543944],\n",
       "        [ -553.35945407],\n",
       "        [ -374.01598426],\n",
       "        [ -135.51277232],\n",
       "        [ -384.92072296],\n",
       "        [  163.33938855],\n",
       "        [  606.69424827],\n",
       "        [  400.8189711 ],\n",
       "        [  222.22226348],\n",
       "        [  226.99200618],\n",
       "        [  -39.68243597],\n",
       "        [ -181.4593363 ],\n",
       "        [ -129.76836788],\n",
       "        [  355.73090464],\n",
       "        [  456.01305582],\n",
       "        [  567.72972977],\n",
       "        [  646.84651952],\n",
       "        [  557.76929142],\n",
       "        [   95.4201865 ],\n",
       "        [ -119.64543126],\n",
       "        [ -122.52703359],\n",
       "        [ -196.22635577],\n",
       "        [ -135.84892661],\n",
       "        [   75.61301148],\n",
       "        [  -78.12539265],\n",
       "        [ -499.9995323 ],\n",
       "        [ -469.59180367],\n",
       "        [ -608.26368236],\n",
       "        [ -600.37375073],\n",
       "        [ -255.90545127],\n",
       "        [   40.1766725 ],\n",
       "        [  238.28667337],\n",
       "        [  448.06587073],\n",
       "        [ -167.66410753],\n",
       "        [ -202.02029579],\n",
       "        [ -396.15779674],\n",
       "        [ -571.99183277],\n",
       "        [ -935.67298606],\n",
       "        [ -302.47727221],\n",
       "        [ -127.83497315],\n",
       "        [  -62.50047068],\n",
       "        [  167.36357697],\n",
       "        [  335.48377746],\n",
       "        [   18.84106058],\n",
       "        [  294.48589844],\n",
       "        [  440.25169754],\n",
       "        [  127.57256924],\n",
       "        [  642.94609468],\n",
       "        [  964.78124343],\n",
       "        [  495.40403794],\n",
       "        [  333.58540038],\n",
       "        [  388.16383494],\n",
       "        [ -234.99817751],\n",
       "        [ -632.87604892],\n",
       "        [ -449.43852828],\n",
       "        [ -457.64388362],\n",
       "        [ -278.32214649],\n",
       "        [ -152.48737424],\n",
       "        [  -10.19436157],\n",
       "        [  -81.1363705 ],\n",
       "        [ -265.30579016],\n",
       "        [ -241.93625424],\n",
       "        [  105.9495804 ],\n",
       "        [   10.20476467],\n",
       "        [  184.04952462],\n",
       "        [  230.60801482],\n",
       "        [   61.98319965],\n",
       "        [   40.32219546],\n",
       "        [  193.6797825 ],\n",
       "        [ -180.7233205 ],\n",
       "        [  -61.47576411],\n",
       "        [  -41.06737386],\n",
       "        [ -240.96401812],\n",
       "        [ -220.00065294],\n",
       "        [  276.07397438],\n",
       "        [  593.81333827],\n",
       "        [  659.79511916],\n",
       "        [  814.81298846],\n",
       "        [  715.7462065 ],\n",
       "        [  587.06502769],\n",
       "        [  354.22504785],\n",
       "        [  112.1844314 ],\n",
       "        [    5.71000657],\n",
       "        [  190.84080794],\n",
       "        [  159.77363037],\n",
       "        [  338.3455104 ],\n",
       "        [  529.83900863],\n",
       "        [  496.29061379],\n",
       "        [  404.49417878],\n",
       "        [  453.283809  ],\n",
       "        [   90.90850481],\n",
       "        [   -9.08214981],\n",
       "        [  -36.2309892 ],\n",
       "        [   25.19834897],\n",
       "        [ -159.2918841 ],\n",
       "        [   72.07249285],\n",
       "        [  272.726626  ],\n",
       "        [  163.63619791],\n",
       "        [ -256.73275346],\n",
       "        [ -280.57475563],\n",
       "        [ -912.34329049],\n",
       "        [-1008.84896   ],\n",
       "        [-1042.9331843 ],\n",
       "        [ -818.13197478],\n",
       "        [ -769.80095193],\n",
       "        [ -236.2200318 ],\n",
       "        [ -236.2200318 ],\n",
       "        [ -509.28686213],\n",
       "        [ -608.06713971],\n",
       "        [ -597.43352718],\n",
       "        [ -483.87127589],\n",
       "        [ -443.54846413],\n",
       "        [ -143.09833185],\n",
       "        [   38.46097573],\n",
       "        [  -42.64417061],\n",
       "        [  -63.55968838],\n",
       "        [ -172.9962576 ],\n",
       "        [    4.27001004],\n",
       "        [  -23.41409445],\n",
       "        [  -94.21726243],\n",
       "        [ -155.64978882],\n",
       "        [  -32.20219223],\n",
       "        [  -91.76244376],\n",
       "        [  -93.87618036],\n",
       "        [   36.74849224],\n",
       "        [   56.31368236],\n",
       "        [    0.        ],\n",
       "        [  256.30022418],\n",
       "        [  256.30022418],\n",
       "        [  256.30022418],\n",
       "        [  256.30022418],\n",
       "        [  256.30022418],\n",
       "        [  470.38967878],\n",
       "        [  373.7919588 ],\n",
       "        [  394.79101659],\n",
       "        [  436.79041601],\n",
       "        [  491.38937849],\n",
       "        [   18.05027814],\n",
       "        [   40.48606294],\n",
       "        [   48.48537695],\n",
       "        [  -60.36190697],\n",
       "        [ -146.11700325],\n",
       "        [ -122.12197535],\n",
       "        [ -179.43552624],\n",
       "        [ -154.80538476],\n",
       "        [ -210.52653725],\n",
       "        [ -264.06629143],\n",
       "        [ -372.92251022],\n",
       "        [ -256.62040636],\n",
       "        [ -220.5437182 ],\n",
       "        [ -281.22425989],\n",
       "        [ -358.85630684],\n",
       "        [ -250.5260936 ],\n",
       "        [ -286.55783057],\n",
       "        [ -446.85641972],\n",
       "        [  -78.72399002],\n",
       "        [ -121.18631852],\n",
       "        [   34.55036863],\n",
       "        [  210.41216779],\n",
       "        [  537.70506787],\n",
       "        [  407.46342264],\n",
       "        [  591.45679398],\n",
       "        [ 1588.11977996],\n",
       "        [ 1383.04515063],\n",
       "        [ 1099.3550385 ],\n",
       "        [  840.71742954],\n",
       "        [  833.50529881],\n",
       "        [ -391.82838069],\n",
       "        [ -442.32852265],\n",
       "        [ -616.70565898],\n",
       "        [ -556.92853577],\n",
       "        [ -578.46537719],\n",
       "        [ -357.5573052 ],\n",
       "        [  -53.39842278],\n",
       "        [  222.41555182],\n",
       "        [  299.24833043],\n",
       "        [  307.29673974],\n",
       "        [   25.26879612],\n",
       "        [ -176.7826692 ],\n",
       "        [ -177.3885625 ],\n",
       "        [  -31.28702901],\n",
       "        [  263.57161585],\n",
       "        [  232.046366  ],\n",
       "        [   17.99592356],\n",
       "        [   55.56692733],\n",
       "        [  343.27296647],\n",
       "        [  270.2189348 ],\n",
       "        [  451.6128724 ],\n",
       "        [  544.9097838 ],\n",
       "        [  392.73654785],\n",
       "        [  237.05561415],\n",
       "        [  113.82817977],\n",
       "        [  316.12439466],\n",
       "        [  728.75242688],\n",
       "        [  816.55834153],\n",
       "        [  816.96968133],\n",
       "        [  647.59946544],\n",
       "        [  790.57124246],\n",
       "        [  409.31650281],\n",
       "        [  414.32670904],\n",
       "        [  315.12246466],\n",
       "        [  674.06067728],\n",
       "        [  551.16761662],\n",
       "        [  676.27138058],\n",
       "        [  542.81866198],\n",
       "        [  180.97270126],\n",
       "        [  389.60999025],\n",
       "        [  331.26291377],\n",
       "        [  525.48035924],\n",
       "        [  223.85764375],\n",
       "        [  684.93228493],\n",
       "        [  273.4383839 ],\n",
       "        [  209.64922006],\n",
       "        [  312.21674126],\n",
       "        [  936.8152454 ],\n",
       "        [  773.80900755],\n",
       "        [  722.43334347],\n",
       "        [  768.53526387],\n",
       "        [  219.39491362],\n",
       "        [ -184.47009825],\n",
       "        [ -366.90771409],\n",
       "        [ -190.07194805],\n",
       "        [ -795.0091451 ],\n",
       "        [ -780.01988538],\n",
       "        [ -523.01946172],\n",
       "        [ -588.23587556],\n",
       "        [ -828.51335086],\n",
       "        [ -495.049892  ],\n",
       "        [  135.05095938],\n",
       "        [ -139.89103972],\n",
       "        [  446.87559344],\n",
       "        [  901.78172848],\n",
       "        [  737.18056057],\n",
       "        [  188.38947189],\n",
       "        [  862.17596046],\n",
       "        [  480.10821492],\n",
       "        [  601.59161282],\n",
       "        [  722.38895211],\n",
       "        [  548.70779621],\n",
       "        [  312.90415775],\n",
       "        [  248.32174382],\n",
       "        [ -234.61971244],\n",
       "        [   29.23042233],\n",
       "        [  215.19076076],\n",
       "        [  182.32411863],\n",
       "        [  495.75404801],\n",
       "        [  381.33699897],\n",
       "        [   29.14607768],\n",
       "        [   57.19928032],\n",
       "        [ -291.14373799],\n",
       "        [ -500.19911423],\n",
       "        [ -384.82206796],\n",
       "        [   27.6779431 ],\n",
       "        [  456.37417897],\n",
       "        [ -412.50160116],\n",
       "        [ -625.69878553],\n",
       "        [ -253.28825209],\n",
       "        [ -553.40803767],\n",
       "        [-1034.75736252],\n",
       "        [  281.93893867],\n",
       "        [  441.00134381],\n",
       "        [  343.14439807],\n",
       "        [  286.33993148],\n",
       "        [  535.66171418],\n",
       "        [  497.00076193],\n",
       "        [  664.95415077],\n",
       "        [  451.13857831],\n",
       "        [  474.36487788],\n",
       "        [  396.06721106],\n",
       "        [  107.48305247],\n",
       "        [  140.48697934],\n",
       "        [   92.97379807],\n",
       "        [  317.2879955 ],\n",
       "        [  313.42957813],\n",
       "        [  257.09990088],\n",
       "        [  -34.30521499],\n",
       "        [  177.65465588],\n",
       "        [  105.13907333],\n",
       "        [  717.84057036],\n",
       "        [ 1551.18255461],\n",
       "        [ 1198.19960048],\n",
       "        [ 1060.25372309],\n",
       "        [ 1314.86500888],\n",
       "        [  795.64917561],\n",
       "        [  131.78680856],\n",
       "        [ 1116.10312585],\n",
       "        [ 1345.56892771],\n",
       "        [  770.11416268],\n",
       "        [  877.39080555],\n",
       "        [ 1032.74388848],\n",
       "        [  560.14770081],\n",
       "        [   69.11187513],\n",
       "        [  161.99578843],\n",
       "        [  -69.92918046],\n",
       "        [ -414.99505246],\n",
       "        [ -937.14081671],\n",
       "        [ -718.16389037],\n",
       "        [ -205.02576491],\n",
       "        [ -533.05338712],\n",
       "        [ -339.70276008],\n",
       "        [ -151.31259202],\n",
       "        [ -111.47875923],\n",
       "        [ -270.50184449],\n",
       "        [  175.12732852],\n",
       "        [  273.62664191],\n",
       "        [  939.90071238],\n",
       "        [  536.88999079],\n",
       "        [  569.28479916],\n",
       "        [ 1251.63425288],\n",
       "        [  766.92640175],\n",
       "        [  -64.02325538],\n",
       "        [  320.97444696],\n",
       "        [   27.13961989],\n",
       "        [ -436.63506201],\n",
       "        [ -541.42659767],\n",
       "        [   -2.07869678],\n",
       "        [  274.04303132],\n",
       "        [  750.57232374],\n",
       "        [  567.92910826],\n",
       "        [  841.29794811],\n",
       "        [  571.72557173],\n",
       "        [   98.9013428 ],\n",
       "        [  147.18770176],\n",
       "        [  119.74326763]]),\n",
       " array([[[   507.8500061 ,    485.        ,    507.8500061 ,\n",
       "             503.29998779,  38753.        ,    476.04998779],\n",
       "         [   497.95001221,    476.04998779,    497.95001221,\n",
       "             481.1000061 ,  59136.        ,    481.        ],\n",
       "         [   488.        ,    480.        ,    481.        ,\n",
       "             487.1499939 ,  50405.        ,    500.5       ],\n",
       "         [   500.        ,    476.04998779,    499.95001221,\n",
       "             480.29998779, 101013.        ,    516.34997559],\n",
       "         [   502.5       ,    489.04998779,    489.04998779,\n",
       "             493.8999939 ,  52305.        ,    521.95001221]],\n",
       " \n",
       "        [[   497.95001221,    476.04998779,    497.95001221,\n",
       "             481.1000061 ,  59136.        ,    481.        ],\n",
       "         [   488.        ,    480.        ,    481.        ,\n",
       "             487.1499939 ,  50405.        ,    500.5       ],\n",
       "         [   500.        ,    476.04998779,    499.95001221,\n",
       "             480.29998779, 101013.        ,    516.34997559],\n",
       "         [   502.5       ,    489.04998779,    489.04998779,\n",
       "             493.8999939 ,  52305.        ,    521.95001221],\n",
       "         [   494.5       ,    471.        ,    494.5       ,\n",
       "             476.04998779,  21512.        ,    516.09997559]],\n",
       " \n",
       "        [[   488.        ,    480.        ,    481.        ,\n",
       "             487.1499939 ,  50405.        ,    500.5       ],\n",
       "         [   500.        ,    476.04998779,    499.95001221,\n",
       "             480.29998779, 101013.        ,    516.34997559],\n",
       "         [   502.5       ,    489.04998779,    489.04998779,\n",
       "             493.8999939 ,  52305.        ,    521.95001221],\n",
       "         [   494.5       ,    471.        ,    494.5       ,\n",
       "             476.04998779,  21512.        ,    516.09997559],\n",
       "         [   488.95001221,    470.        ,    476.        ,\n",
       "             481.        ,  29171.        ,    508.5       ]],\n",
       " \n",
       "        [[   500.        ,    476.04998779,    499.95001221,\n",
       "             480.29998779, 101013.        ,    516.34997559],\n",
       "         [   502.5       ,    489.04998779,    489.04998779,\n",
       "             493.8999939 ,  52305.        ,    521.95001221],\n",
       "         [   494.5       ,    471.        ,    494.5       ,\n",
       "             476.04998779,  21512.        ,    516.09997559],\n",
       "         [   488.95001221,    470.        ,    476.        ,\n",
       "             481.        ,  29171.        ,    508.5       ],\n",
       "         [   509.95001221,    491.04998779,    491.04998779,\n",
       "             500.5       ,  84024.        ,    505.45001221]],\n",
       " \n",
       "        [[   502.5       ,    489.04998779,    489.04998779,\n",
       "             493.8999939 ,  52305.        ,    521.95001221],\n",
       "         [   494.5       ,    471.        ,    494.5       ,\n",
       "             476.04998779,  21512.        ,    516.09997559],\n",
       "         [   488.95001221,    470.        ,    476.        ,\n",
       "             481.        ,  29171.        ,    508.5       ],\n",
       "         [   509.95001221,    491.04998779,    491.04998779,\n",
       "             500.5       ,  84024.        ,    505.45001221],\n",
       "         [   519.        ,    500.5       ,    500.5       ,\n",
       "             516.34997559,  70129.        ,    523.95001221]],\n",
       " \n",
       "        [[   494.5       ,    471.        ,    494.5       ,\n",
       "             476.04998779,  21512.        ,    516.09997559],\n",
       "         [   488.95001221,    470.        ,    476.        ,\n",
       "             481.        ,  29171.        ,    508.5       ],\n",
       "         [   509.95001221,    491.04998779,    491.04998779,\n",
       "             500.5       ,  84024.        ,    505.45001221],\n",
       "         [   519.        ,    500.5       ,    500.5       ,\n",
       "             516.34997559,  70129.        ,    523.95001221],\n",
       "         [   539.        ,    519.        ,    520.        ,\n",
       "             521.95001221,  99087.        ,    528.20001221]],\n",
       " \n",
       "        [[   488.95001221,    470.        ,    476.        ,\n",
       "             481.        ,  29171.        ,    508.5       ],\n",
       "         [   509.95001221,    491.04998779,    491.04998779,\n",
       "             500.5       ,  84024.        ,    505.45001221],\n",
       "         [   519.        ,    500.5       ,    500.5       ,\n",
       "             516.34997559,  70129.        ,    523.95001221],\n",
       "         [   539.        ,    519.        ,    520.        ,\n",
       "             521.95001221,  99087.        ,    528.20001221],\n",
       "         [   532.        ,    510.04998779,    521.75      ,\n",
       "             516.09997559,  68575.        ,    529.95001221]],\n",
       " \n",
       "        [[   509.95001221,    491.04998779,    491.04998779,\n",
       "             500.5       ,  84024.        ,    505.45001221],\n",
       "         [   519.        ,    500.5       ,    500.5       ,\n",
       "             516.34997559,  70129.        ,    523.95001221],\n",
       "         [   539.        ,    519.        ,    520.        ,\n",
       "             521.95001221,  99087.        ,    528.20001221],\n",
       "         [   532.        ,    510.04998779,    521.75      ,\n",
       "             516.09997559,  68575.        ,    529.95001221],\n",
       "         [   525.        ,    507.        ,    521.        ,\n",
       "             508.5       ,  35018.        ,    510.        ]],\n",
       " \n",
       "        [[   519.        ,    500.5       ,    500.5       ,\n",
       "             516.34997559,  70129.        ,    523.95001221],\n",
       "         [   539.        ,    519.        ,    520.        ,\n",
       "             521.95001221,  99087.        ,    528.20001221],\n",
       "         [   532.        ,    510.04998779,    521.75      ,\n",
       "             516.09997559,  68575.        ,    529.95001221],\n",
       "         [   525.        ,    507.        ,    521.        ,\n",
       "             508.5       ,  35018.        ,    510.        ],\n",
       "         [   518.95001221,    505.        ,    510.        ,\n",
       "             505.45001221,   9916.        ,    511.1499939 ]],\n",
       " \n",
       "        [[   539.        ,    519.        ,    520.        ,\n",
       "             521.95001221,  99087.        ,    528.20001221],\n",
       "         [   532.        ,    510.04998779,    521.75      ,\n",
       "             516.09997559,  68575.        ,    529.95001221],\n",
       "         [   525.        ,    507.        ,    521.        ,\n",
       "             508.5       ,  35018.        ,    510.        ],\n",
       "         [   518.95001221,    505.        ,    510.        ,\n",
       "             505.45001221,   9916.        ,    511.1499939 ],\n",
       "         [   529.5       ,    505.45001221,    505.45001221,\n",
       "             523.95001221,  90748.        ,    512.84997559]],\n",
       " \n",
       "        [[   532.        ,    510.04998779,    521.75      ,\n",
       "             516.09997559,  68575.        ,    529.95001221],\n",
       "         [   525.        ,    507.        ,    521.        ,\n",
       "             508.5       ,  35018.        ,    510.        ],\n",
       "         [   518.95001221,    505.        ,    510.        ,\n",
       "             505.45001221,   9916.        ,    511.1499939 ],\n",
       "         [   529.5       ,    505.45001221,    505.45001221,\n",
       "             523.95001221,  90748.        ,    512.84997559],\n",
       "         [   534.65002441,    520.        ,    524.        ,\n",
       "             528.20001221,  21074.        ,    509.1000061 ]],\n",
       " \n",
       "        [[   525.        ,    507.        ,    521.        ,\n",
       "             508.5       ,  35018.        ,    510.        ],\n",
       "         [   518.95001221,    505.        ,    510.        ,\n",
       "             505.45001221,   9916.        ,    511.1499939 ],\n",
       "         [   529.5       ,    505.45001221,    505.45001221,\n",
       "             523.95001221,  90748.        ,    512.84997559],\n",
       "         [   534.65002441,    520.        ,    524.        ,\n",
       "             528.20001221,  21074.        ,    509.1000061 ],\n",
       "         [   550.        ,    529.        ,    549.95001221,\n",
       "             529.95001221,  16203.        ,    510.6499939 ]],\n",
       " \n",
       "        [[   518.95001221,    505.        ,    510.        ,\n",
       "             505.45001221,   9916.        ,    511.1499939 ],\n",
       "         [   529.5       ,    505.45001221,    505.45001221,\n",
       "             523.95001221,  90748.        ,    512.84997559],\n",
       "         [   534.65002441,    520.        ,    524.        ,\n",
       "             528.20001221,  21074.        ,    509.1000061 ],\n",
       "         [   550.        ,    529.        ,    549.95001221,\n",
       "             529.95001221,  16203.        ,    510.6499939 ],\n",
       "         [   525.        ,    505.        ,    513.        ,\n",
       "             510.        ,  28814.        ,    514.20001221]],\n",
       " \n",
       "        [[   529.5       ,    505.45001221,    505.45001221,\n",
       "             523.95001221,  90748.        ,    512.84997559],\n",
       "         [   534.65002441,    520.        ,    524.        ,\n",
       "             528.20001221,  21074.        ,    509.1000061 ],\n",
       "         [   550.        ,    529.        ,    549.95001221,\n",
       "             529.95001221,  16203.        ,    510.6499939 ],\n",
       "         [   525.        ,    505.        ,    513.        ,\n",
       "             510.        ,  28814.        ,    514.20001221],\n",
       "         [   517.90002441,    505.        ,    515.        ,\n",
       "             511.1499939 ,  17046.        ,    514.95001221]],\n",
       " \n",
       "        [[   534.65002441,    520.        ,    524.        ,\n",
       "             528.20001221,  21074.        ,    509.1000061 ],\n",
       "         [   550.        ,    529.        ,    549.95001221,\n",
       "             529.95001221,  16203.        ,    510.6499939 ],\n",
       "         [   525.        ,    505.        ,    513.        ,\n",
       "             510.        ,  28814.        ,    514.20001221],\n",
       "         [   517.90002441,    505.        ,    515.        ,\n",
       "             511.1499939 ,  17046.        ,    514.95001221],\n",
       "         [   519.95001221,    508.        ,    510.        ,\n",
       "             512.84997559,  30776.        ,    514.20001221]],\n",
       " \n",
       "        [[   550.        ,    529.        ,    549.95001221,\n",
       "             529.95001221,  16203.        ,    510.6499939 ],\n",
       "         [   525.        ,    505.        ,    513.        ,\n",
       "             510.        ,  28814.        ,    514.20001221],\n",
       "         [   517.90002441,    505.        ,    515.        ,\n",
       "             511.1499939 ,  17046.        ,    514.95001221],\n",
       "         [   519.95001221,    508.        ,    510.        ,\n",
       "             512.84997559,  30776.        ,    514.20001221],\n",
       "         [   514.        ,    505.1499939 ,    513.        ,\n",
       "             509.1000061 ,  29730.        ,    509.6000061 ]],\n",
       " \n",
       "        [[   525.        ,    505.        ,    513.        ,\n",
       "             510.        ,  28814.        ,    514.20001221],\n",
       "         [   517.90002441,    505.        ,    515.        ,\n",
       "             511.1499939 ,  17046.        ,    514.95001221],\n",
       "         [   519.95001221,    508.        ,    510.        ,\n",
       "             512.84997559,  30776.        ,    514.20001221],\n",
       "         [   514.        ,    505.1499939 ,    513.        ,\n",
       "             509.1000061 ,  29730.        ,    509.6000061 ],\n",
       "         [   515.        ,    506.        ,    509.        ,\n",
       "             510.6499939 ,  16934.        ,    507.29998779]],\n",
       " \n",
       "        [[   517.90002441,    505.        ,    515.        ,\n",
       "             511.1499939 ,  17046.        ,    514.95001221],\n",
       "         [   519.95001221,    508.        ,    510.        ,\n",
       "             512.84997559,  30776.        ,    514.20001221],\n",
       "         [   514.        ,    505.1499939 ,    513.        ,\n",
       "             509.1000061 ,  29730.        ,    509.6000061 ],\n",
       "         [   515.        ,    506.        ,    509.        ,\n",
       "             510.6499939 ,  16934.        ,    507.29998779],\n",
       "         [   524.95001221,    508.1000061 ,    524.95001221,\n",
       "             514.20001221,  14281.        ,    501.95001221]],\n",
       " \n",
       "        [[   519.95001221,    508.        ,    510.        ,\n",
       "             512.84997559,  30776.        ,    514.20001221],\n",
       "         [   514.        ,    505.1499939 ,    513.        ,\n",
       "             509.1000061 ,  29730.        ,    509.6000061 ],\n",
       "         [   515.        ,    506.        ,    509.        ,\n",
       "             510.6499939 ,  16934.        ,    507.29998779],\n",
       "         [   524.95001221,    508.1000061 ,    524.95001221,\n",
       "             514.20001221,  14281.        ,    501.95001221],\n",
       "         [   516.        ,    509.1499939 ,    514.        ,\n",
       "             514.95001221,  18044.        ,    497.70001221]],\n",
       " \n",
       "        [[   514.        ,    505.1499939 ,    513.        ,\n",
       "             509.1000061 ,  29730.        ,    509.6000061 ],\n",
       "         [   515.        ,    506.        ,    509.        ,\n",
       "             510.6499939 ,  16934.        ,    507.29998779],\n",
       "         [   524.95001221,    508.1000061 ,    524.95001221,\n",
       "             514.20001221,  14281.        ,    501.95001221],\n",
       "         [   516.        ,    509.1499939 ,    514.        ,\n",
       "             514.95001221,  18044.        ,    497.70001221],\n",
       "         [   517.95001221,    512.        ,    512.        ,\n",
       "             514.20001221,  12171.        ,    491.1000061 ]],\n",
       " \n",
       "        [[   515.        ,    506.        ,    509.        ,\n",
       "             510.6499939 ,  16934.        ,    507.29998779],\n",
       "         [   524.95001221,    508.1000061 ,    524.95001221,\n",
       "             514.20001221,  14281.        ,    501.95001221],\n",
       "         [   516.        ,    509.1499939 ,    514.        ,\n",
       "             514.95001221,  18044.        ,    497.70001221],\n",
       "         [   517.95001221,    512.        ,    512.        ,\n",
       "             514.20001221,  12171.        ,    491.1000061 ],\n",
       "         [   514.        ,    505.        ,    510.        ,\n",
       "             509.6000061 ,  28270.        ,    496.04998779]],\n",
       " \n",
       "        [[   524.95001221,    508.1000061 ,    524.95001221,\n",
       "             514.20001221,  14281.        ,    501.95001221],\n",
       "         [   516.        ,    509.1499939 ,    514.        ,\n",
       "             514.95001221,  18044.        ,    497.70001221],\n",
       "         [   517.95001221,    512.        ,    512.        ,\n",
       "             514.20001221,  12171.        ,    491.1000061 ],\n",
       "         [   514.        ,    505.        ,    510.        ,\n",
       "             509.6000061 ,  28270.        ,    496.04998779],\n",
       "         [   512.15002441,    499.5       ,    510.        ,\n",
       "             507.29998779,  51163.        ,    504.8999939 ]],\n",
       " \n",
       "        [[   516.        ,    509.1499939 ,    514.        ,\n",
       "             514.95001221,  18044.        ,    497.70001221],\n",
       "         [   517.95001221,    512.        ,    512.        ,\n",
       "             514.20001221,  12171.        ,    491.1000061 ],\n",
       "         [   514.        ,    505.        ,    510.        ,\n",
       "             509.6000061 ,  28270.        ,    496.04998779],\n",
       "         [   512.15002441,    499.5       ,    510.        ,\n",
       "             507.29998779,  51163.        ,    504.8999939 ],\n",
       "         [   504.        ,    494.        ,    500.        ,\n",
       "             501.95001221,  78438.        ,    510.1499939 ]],\n",
       " \n",
       "        [[   517.95001221,    512.        ,    512.        ,\n",
       "             514.20001221,  12171.        ,    491.1000061 ],\n",
       "         [   514.        ,    505.        ,    510.        ,\n",
       "             509.6000061 ,  28270.        ,    496.04998779],\n",
       "         [   512.15002441,    499.5       ,    510.        ,\n",
       "             507.29998779,  51163.        ,    504.8999939 ],\n",
       "         [   504.        ,    494.        ,    500.        ,\n",
       "             501.95001221,  78438.        ,    510.1499939 ],\n",
       "         [   504.5       ,    491.04998779,    499.95001221,\n",
       "             497.70001221,  57708.        ,    469.1000061 ]],\n",
       " \n",
       "        [[   514.        ,    505.        ,    510.        ,\n",
       "             509.6000061 ,  28270.        ,    496.04998779],\n",
       "         [   512.15002441,    499.5       ,    510.        ,\n",
       "             507.29998779,  51163.        ,    504.8999939 ],\n",
       "         [   504.        ,    494.        ,    500.        ,\n",
       "             501.95001221,  78438.        ,    510.1499939 ],\n",
       "         [   504.5       ,    491.04998779,    499.95001221,\n",
       "             497.70001221,  57708.        ,    469.1000061 ],\n",
       "         [   501.        ,    481.        ,    486.        ,\n",
       "             491.1000061 ,  45939.        ,    467.1499939 ]],\n",
       " \n",
       "        [[   512.15002441,    499.5       ,    510.        ,\n",
       "             507.29998779,  51163.        ,    504.8999939 ],\n",
       "         [   504.        ,    494.        ,    500.        ,\n",
       "             501.95001221,  78438.        ,    510.1499939 ],\n",
       "         [   504.5       ,    491.04998779,    499.95001221,\n",
       "             497.70001221,  57708.        ,    469.1000061 ],\n",
       "         [   501.        ,    481.        ,    486.        ,\n",
       "             491.1000061 ,  45939.        ,    467.1499939 ],\n",
       "         [   503.5       ,    493.04998779,    493.04998779,\n",
       "             496.04998779,  18605.        ,    468.3500061 ]],\n",
       " \n",
       "        [[   504.        ,    494.        ,    500.        ,\n",
       "             501.95001221,  78438.        ,    510.1499939 ],\n",
       "         [   504.5       ,    491.04998779,    499.95001221,\n",
       "             497.70001221,  57708.        ,    469.1000061 ],\n",
       "         [   501.        ,    481.        ,    486.        ,\n",
       "             491.1000061 ,  45939.        ,    467.1499939 ],\n",
       "         [   503.5       ,    493.04998779,    493.04998779,\n",
       "             496.04998779,  18605.        ,    468.3500061 ],\n",
       "         [   507.04998779,    496.1499939 ,    496.1499939 ,\n",
       "             504.8999939 ,  19630.        ,    472.25      ]],\n",
       " \n",
       "        [[   504.5       ,    491.04998779,    499.95001221,\n",
       "             497.70001221,  57708.        ,    469.1000061 ],\n",
       "         [   501.        ,    481.        ,    486.        ,\n",
       "             491.1000061 ,  45939.        ,    467.1499939 ],\n",
       "         [   503.5       ,    493.04998779,    493.04998779,\n",
       "             496.04998779,  18605.        ,    468.3500061 ],\n",
       "         [   507.04998779,    496.1499939 ,    496.1499939 ,\n",
       "             504.8999939 ,  19630.        ,    472.25      ],\n",
       "         [   512.95001221,    500.        ,    504.        ,\n",
       "             510.1499939 ,  16766.        ,    487.04998779]],\n",
       " \n",
       "        [[   501.        ,    481.        ,    486.        ,\n",
       "             491.1000061 ,  45939.        ,    467.1499939 ],\n",
       "         [   503.5       ,    493.04998779,    493.04998779,\n",
       "             496.04998779,  18605.        ,    468.3500061 ],\n",
       "         [   507.04998779,    496.1499939 ,    496.1499939 ,\n",
       "             504.8999939 ,  19630.        ,    472.25      ],\n",
       "         [   512.95001221,    500.        ,    504.        ,\n",
       "             510.1499939 ,  16766.        ,    487.04998779],\n",
       "         [   484.6499939 ,    467.        ,    484.6499939 ,\n",
       "             469.1000061 , 153200.        ,    490.8999939 ]],\n",
       " \n",
       "        [[   503.5       ,    493.04998779,    493.04998779,\n",
       "             496.04998779,  18605.        ,    468.3500061 ],\n",
       "         [   507.04998779,    496.1499939 ,    496.1499939 ,\n",
       "             504.8999939 ,  19630.        ,    472.25      ],\n",
       "         [   512.95001221,    500.        ,    504.        ,\n",
       "             510.1499939 ,  16766.        ,    487.04998779],\n",
       "         [   484.6499939 ,    467.        ,    484.6499939 ,\n",
       "             469.1000061 , 153200.        ,    490.8999939 ],\n",
       "         [   479.        ,    467.        ,    475.04998779,\n",
       "             467.1499939 ,  26690.        ,    502.54998779]]]),\n",
       " array([[ 268.35956745],\n",
       "        [  29.49852507],\n",
       "        [ 112.77043331],\n",
       "        [-211.85296999],\n",
       "        [-361.60555968],\n",
       "        [-364.18563763],\n",
       "        [  82.35318053],\n",
       "        [  74.34252873],\n",
       "        [  26.32420172],\n",
       "        [   9.82125307],\n",
       "        [ -65.60278358],\n",
       "        [-238.23414448],\n",
       "        [-334.98397109],\n",
       "        [-449.24164829],\n",
       "        [-265.89517559],\n",
       "        [ -47.30916527],\n",
       "        [ 163.36251599],\n",
       "        [-574.64346799],\n",
       "        [-487.68095926],\n",
       "        [-558.41109507],\n",
       "        [-646.66259242],\n",
       "        [-452.80812271],\n",
       "        [ 464.71940971],\n",
       "        [ 757.78645743],\n",
       "        [ 840.18374273],\n",
       "        [ 597.14160311],\n",
       "        [  37.98390617],\n",
       "        [  84.53847928],\n",
       "        [ -69.64481315],\n",
       "        [-105.37730894]])]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data_v2(df_val, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[2]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def build_model2(layers):\n",
    "        d = 0.2\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(Dense(16,kernel_initializer='uniform',activation='relu'))        \n",
    "        model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "        model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features TOT : 7\n",
      "Amount of features found: 6\n",
      "x_test: [[[ 0.254       0.249       0.252       0.252      39.183\n",
      "    0.24137633]\n",
      "  [ 0.256       0.248       0.256       0.25089999 25.495\n",
      "    0.2465565 ]\n",
      "  [ 0.25595     0.253       0.253       0.254      26.239\n",
      "    0.24356793]\n",
      "  [ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]]\n",
      "\n",
      " [[ 0.256       0.248       0.256       0.25089999 25.495\n",
      "    0.2465565 ]\n",
      "  [ 0.25595     0.253       0.253       0.254      26.239\n",
      "    0.24356793]\n",
      "  [ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]]\n",
      "\n",
      " [[ 0.25595     0.253       0.253       0.254      26.239\n",
      "    0.24356793]\n",
      "  [ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]]\n",
      "\n",
      " [[ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]]\n",
      "\n",
      " [[ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]]\n",
      "\n",
      " [[ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]]\n",
      "\n",
      " [[ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]]\n",
      "\n",
      " [[ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]]\n",
      "\n",
      " [[ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]]\n",
      "\n",
      " [[ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]]\n",
      "\n",
      " [[ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]]\n",
      "\n",
      " [[ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]]\n",
      "\n",
      " [[ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]]\n",
      "\n",
      " [[ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]]\n",
      "\n",
      " [[ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]]\n",
      "\n",
      " [[ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]]\n",
      "\n",
      " [[ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]]\n",
      "\n",
      " [[ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]]\n",
      "\n",
      " [[ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]]\n",
      "\n",
      " [[ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]]\n",
      "\n",
      " [[ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]]\n",
      "\n",
      " [[ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]]\n",
      "\n",
      " [[ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]]\n",
      "\n",
      " [[ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]]\n",
      "\n",
      " [[ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]]\n",
      "\n",
      " [[ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]]\n",
      "\n",
      " [[ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]]\n",
      "\n",
      " [[ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]\n",
      "  [ 0.28895001  0.2855      0.28639999  0.286      22.531\n",
      "    0.29128537]]\n",
      "\n",
      " [[ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]\n",
      "  [ 0.28895001  0.2855      0.28639999  0.286      22.531\n",
      "    0.29128537]\n",
      "  [ 0.28895001  0.28        0.28320001  0.2865     23.484\n",
      "    0.29387543]]\n",
      "\n",
      " [[ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]\n",
      "  [ 0.28895001  0.2855      0.28639999  0.286      22.531\n",
      "    0.29128537]\n",
      "  [ 0.28895001  0.28        0.28320001  0.2865     23.484\n",
      "    0.29387543]\n",
      "  [ 0.28460001  0.28        0.2845      0.283      15.736\n",
      "    0.29088684]]]\n",
      "y_test: [[-0.38492072]\n",
      " [-0.13551277]\n",
      " [-0.37401598]\n",
      " [-0.55335945]\n",
      " [-0.40812544]\n",
      " [-0.13312452]\n",
      " [-0.26387331]\n",
      " [-0.48689182]\n",
      " [-0.52434491]\n",
      " [-0.0957846 ]\n",
      " [-0.3257581 ]\n",
      " [-0.16412066]\n",
      " [ 0.0754715 ]\n",
      " [ 0.03759389]\n",
      " [-0.23020664]\n",
      " [-0.09380667]\n",
      " [-0.14111056]\n",
      " [-0.0169519 ]\n",
      " [-0.18450247]\n",
      " [-0.14206767]\n",
      " [-0.30909179]\n",
      " [-0.37137507]\n",
      " [-0.45143809]\n",
      " [-0.2095355 ]\n",
      " [-0.20776792]\n",
      " [-0.46628585]\n",
      " [-0.56087798]\n",
      " [-0.57627177]\n",
      " [-0.5205481 ]\n",
      " [-0.35714324]]\n",
      "X_train (344, 5, 6)\n",
      "y_train (344, 1)\n",
      "X_test (30, 5, 6)\n",
      "y_test (30, 1)\n"
     ]
    }
   ],
   "source": [
    "df_val = df.values / 1000\n",
    "#for a in range(len(df_val[0])-2):\n",
    "#    df_val[:,a] /= 1000\n",
    "window  =  5\n",
    "X_train, y_train, X_test, y_test = load_data_v2(df_val[::-1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 309 samples, validate on 35 samples\n",
      "Epoch 1/250\n",
      "309/309 [==============================] - 9s 29ms/step - loss: 0.2389 - acc: 0.0032 - val_loss: 0.1511 - val_acc: 0.0000e+00\n",
      "Epoch 2/250\n",
      "309/309 [==============================] - 0s 612us/step - loss: 0.2371 - acc: 0.0032 - val_loss: 0.1519 - val_acc: 0.0000e+00\n",
      "Epoch 3/250\n",
      "309/309 [==============================] - 0s 647us/step - loss: 0.2352 - acc: 0.0032 - val_loss: 0.1529 - val_acc: 0.0000e+00\n",
      "Epoch 4/250\n",
      "309/309 [==============================] - 0s 611us/step - loss: 0.2332 - acc: 0.0032 - val_loss: 0.1542 - val_acc: 0.0000e+00\n",
      "Epoch 5/250\n",
      "309/309 [==============================] - 0s 650us/step - loss: 0.2315 - acc: 0.0032 - val_loss: 0.1558 - val_acc: 0.0000e+00\n",
      "Epoch 6/250\n",
      "309/309 [==============================] - 0s 658us/step - loss: 0.2305 - acc: 0.0032 - val_loss: 0.1579 - val_acc: 0.0000e+00\n",
      "Epoch 7/250\n",
      "309/309 [==============================] - 0s 630us/step - loss: 0.2283 - acc: 0.0032 - val_loss: 0.1606 - val_acc: 0.0000e+00\n",
      "Epoch 8/250\n",
      "309/309 [==============================] - 0s 631us/step - loss: 0.2271 - acc: 0.0032 - val_loss: 0.1638 - val_acc: 0.0000e+00\n",
      "Epoch 9/250\n",
      "309/309 [==============================] - 0s 584us/step - loss: 0.2261 - acc: 0.0032 - val_loss: 0.1677 - val_acc: 0.0000e+00\n",
      "Epoch 10/250\n",
      "309/309 [==============================] - 0s 604us/step - loss: 0.2243 - acc: 0.0032 - val_loss: 0.1722 - val_acc: 0.0000e+00\n",
      "Epoch 11/250\n",
      "309/309 [==============================] - 0s 644us/step - loss: 0.2234 - acc: 0.0032 - val_loss: 0.1772 - val_acc: 0.0000e+00\n",
      "Epoch 12/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.2244 - acc: 0.0032 - val_loss: 0.1819 - val_acc: 0.0000e+00\n",
      "Epoch 13/250\n",
      "309/309 [==============================] - 0s 650us/step - loss: 0.2243 - acc: 0.0032 - val_loss: 0.1855 - val_acc: 0.0000e+00\n",
      "Epoch 14/250\n",
      "309/309 [==============================] - 0s 586us/step - loss: 0.2242 - acc: 0.0032 - val_loss: 0.1874 - val_acc: 0.0000e+00\n",
      "Epoch 15/250\n",
      "309/309 [==============================] - 0s 593us/step - loss: 0.2255 - acc: 0.0032 - val_loss: 0.1874 - val_acc: 0.0000e+00\n",
      "Epoch 16/250\n",
      "309/309 [==============================] - 0s 643us/step - loss: 0.2253 - acc: 0.0032 - val_loss: 0.1860 - val_acc: 0.0000e+00\n",
      "Epoch 17/250\n",
      "309/309 [==============================] - 0s 637us/step - loss: 0.2255 - acc: 0.0032 - val_loss: 0.1837 - val_acc: 0.0000e+00\n",
      "Epoch 18/250\n",
      "309/309 [==============================] - 0s 638us/step - loss: 0.2232 - acc: 0.0032 - val_loss: 0.1810 - val_acc: 0.0000e+00\n",
      "Epoch 19/250\n",
      "309/309 [==============================] - 0s 658us/step - loss: 0.2248 - acc: 0.0032 - val_loss: 0.1783 - val_acc: 0.0000e+00\n",
      "Epoch 20/250\n",
      "309/309 [==============================] - 0s 655us/step - loss: 0.2236 - acc: 0.0032 - val_loss: 0.1757 - val_acc: 0.0000e+00\n",
      "Epoch 21/250\n",
      "309/309 [==============================] - 0s 656us/step - loss: 0.2219 - acc: 0.0032 - val_loss: 0.1735 - val_acc: 0.0000e+00\n",
      "Epoch 22/250\n",
      "309/309 [==============================] - 0s 683us/step - loss: 0.2236 - acc: 0.0032 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
      "Epoch 23/250\n",
      "309/309 [==============================] - 0s 621us/step - loss: 0.2236 - acc: 0.0032 - val_loss: 0.1700 - val_acc: 0.0000e+00\n",
      "Epoch 24/250\n",
      "309/309 [==============================] - 0s 666us/step - loss: 0.2233 - acc: 0.0032 - val_loss: 0.1688 - val_acc: 0.0000e+00\n",
      "Epoch 25/250\n",
      "309/309 [==============================] - 0s 680us/step - loss: 0.2236 - acc: 0.0032 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
      "Epoch 26/250\n",
      "309/309 [==============================] - 0s 625us/step - loss: 0.2234 - acc: 0.0032 - val_loss: 0.1673 - val_acc: 0.0000e+00\n",
      "Epoch 27/250\n",
      "309/309 [==============================] - 0s 630us/step - loss: 0.2233 - acc: 0.0032 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 28/250\n",
      "309/309 [==============================] - 0s 610us/step - loss: 0.2229 - acc: 0.0032 - val_loss: 0.1671 - val_acc: 0.0000e+00\n",
      "Epoch 29/250\n",
      "309/309 [==============================] - 0s 651us/step - loss: 0.2223 - acc: 0.0032 - val_loss: 0.1673 - val_acc: 0.0000e+00\n",
      "Epoch 30/250\n",
      "309/309 [==============================] - 0s 610us/step - loss: 0.2227 - acc: 0.0032 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 31/250\n",
      "309/309 [==============================] - 0s 646us/step - loss: 0.2226 - acc: 0.0032 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
      "Epoch 32/250\n",
      "309/309 [==============================] - 0s 639us/step - loss: 0.2227 - acc: 0.0032 - val_loss: 0.1691 - val_acc: 0.0000e+00\n",
      "Epoch 33/250\n",
      "309/309 [==============================] - 0s 643us/step - loss: 0.2225 - acc: 0.0032 - val_loss: 0.1699 - val_acc: 0.0000e+00\n",
      "Epoch 34/250\n",
      "309/309 [==============================] - 0s 627us/step - loss: 0.2220 - acc: 0.0032 - val_loss: 0.1707 - val_acc: 0.0000e+00\n",
      "Epoch 35/250\n",
      "309/309 [==============================] - 0s 648us/step - loss: 0.2228 - acc: 0.0032 - val_loss: 0.1713 - val_acc: 0.0000e+00\n",
      "Epoch 36/250\n",
      "309/309 [==============================] - 0s 688us/step - loss: 0.2234 - acc: 0.0032 - val_loss: 0.1717 - val_acc: 0.0000e+00\n",
      "Epoch 37/250\n",
      "309/309 [==============================] - 0s 757us/step - loss: 0.2224 - acc: 0.0032 - val_loss: 0.1718 - val_acc: 0.0000e+00\n",
      "Epoch 38/250\n",
      "309/309 [==============================] - 0s 636us/step - loss: 0.2226 - acc: 0.0032 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
      "Epoch 39/250\n",
      "309/309 [==============================] - 0s 638us/step - loss: 0.2227 - acc: 0.0032 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
      "Epoch 40/250\n",
      "309/309 [==============================] - 0s 604us/step - loss: 0.2210 - acc: 0.0032 - val_loss: 0.1701 - val_acc: 0.0000e+00\n",
      "Epoch 41/250\n",
      "309/309 [==============================] - 0s 626us/step - loss: 0.2223 - acc: 0.0032 - val_loss: 0.1691 - val_acc: 0.0000e+00\n",
      "Epoch 42/250\n",
      "309/309 [==============================] - 0s 665us/step - loss: 0.2220 - acc: 0.0032 - val_loss: 0.1680 - val_acc: 0.0000e+00\n",
      "Epoch 43/250\n",
      "309/309 [==============================] - 0s 587us/step - loss: 0.2211 - acc: 0.0032 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
      "Epoch 44/250\n",
      "309/309 [==============================] - 0s 623us/step - loss: 0.2217 - acc: 0.0032 - val_loss: 0.1656 - val_acc: 0.0000e+00\n",
      "Epoch 45/250\n",
      "309/309 [==============================] - 0s 641us/step - loss: 0.2205 - acc: 0.0032 - val_loss: 0.1644 - val_acc: 0.0000e+00\n",
      "Epoch 46/250\n",
      "309/309 [==============================] - 0s 645us/step - loss: 0.2199 - acc: 0.0032 - val_loss: 0.1634 - val_acc: 0.0000e+00\n",
      "Epoch 47/250\n",
      "309/309 [==============================] - 0s 654us/step - loss: 0.2205 - acc: 0.0032 - val_loss: 0.1623 - val_acc: 0.0000e+00\n",
      "Epoch 48/250\n",
      "309/309 [==============================] - 0s 612us/step - loss: 0.2196 - acc: 0.0032 - val_loss: 0.1612 - val_acc: 0.0000e+00\n",
      "Epoch 49/250\n",
      "309/309 [==============================] - 0s 643us/step - loss: 0.2193 - acc: 0.0032 - val_loss: 0.1604 - val_acc: 0.0000e+00\n",
      "Epoch 50/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.2193 - acc: 0.0032 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
      "Epoch 51/250\n",
      "309/309 [==============================] - 0s 622us/step - loss: 0.2189 - acc: 0.0032 - val_loss: 0.1591 - val_acc: 0.0000e+00\n",
      "Epoch 52/250\n",
      "309/309 [==============================] - 0s 587us/step - loss: 0.2190 - acc: 0.0032 - val_loss: 0.1591 - val_acc: 0.0000e+00\n",
      "Epoch 53/250\n",
      "309/309 [==============================] - 0s 598us/step - loss: 0.2176 - acc: 0.0032 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 54/250\n",
      "309/309 [==============================] - 0s 636us/step - loss: 0.2179 - acc: 0.0032 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 55/250\n",
      "309/309 [==============================] - 0s 723us/step - loss: 0.2163 - acc: 0.0032 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 56/250\n",
      "309/309 [==============================] - 0s 636us/step - loss: 0.2163 - acc: 0.0032 - val_loss: 0.1591 - val_acc: 0.0000e+00\n",
      "Epoch 57/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.2164 - acc: 0.0032 - val_loss: 0.1584 - val_acc: 0.0000e+00\n",
      "Epoch 58/250\n",
      "309/309 [==============================] - 0s 658us/step - loss: 0.2146 - acc: 0.0032 - val_loss: 0.1592 - val_acc: 0.0000e+00\n",
      "Epoch 59/250\n",
      "309/309 [==============================] - 0s 615us/step - loss: 0.2137 - acc: 0.0032 - val_loss: 0.1616 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/250\n",
      "309/309 [==============================] - 0s 650us/step - loss: 0.2127 - acc: 0.0032 - val_loss: 0.1678 - val_acc: 0.0000e+00\n",
      "Epoch 61/250\n",
      "309/309 [==============================] - 0s 668us/step - loss: 0.2102 - acc: 0.0032 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
      "Epoch 62/250\n",
      "309/309 [==============================] - 0s 626us/step - loss: 0.2098 - acc: 0.0032 - val_loss: 0.1755 - val_acc: 0.0000e+00\n",
      "Epoch 63/250\n",
      "309/309 [==============================] - 0s 642us/step - loss: 0.2089 - acc: 0.0032 - val_loss: 0.1776 - val_acc: 0.0000e+00\n",
      "Epoch 64/250\n",
      "309/309 [==============================] - 0s 611us/step - loss: 0.2107 - acc: 0.0032 - val_loss: 0.1899 - val_acc: 0.0000e+00\n",
      "Epoch 65/250\n",
      "309/309 [==============================] - 0s 608us/step - loss: 0.2076 - acc: 0.0032 - val_loss: 0.2060 - val_acc: 0.0000e+00\n",
      "Epoch 66/250\n",
      "309/309 [==============================] - 0s 644us/step - loss: 0.2103 - acc: 0.0032 - val_loss: 0.2021 - val_acc: 0.0000e+00\n",
      "Epoch 67/250\n",
      "309/309 [==============================] - 0s 638us/step - loss: 0.2103 - acc: 0.0032 - val_loss: 0.1893 - val_acc: 0.0000e+00\n",
      "Epoch 68/250\n",
      "309/309 [==============================] - 0s 621us/step - loss: 0.2067 - acc: 0.0032 - val_loss: 0.1958 - val_acc: 0.0000e+00\n",
      "Epoch 69/250\n",
      "309/309 [==============================] - 0s 660us/step - loss: 0.2054 - acc: 0.0032 - val_loss: 0.2092 - val_acc: 0.0000e+00\n",
      "Epoch 70/250\n",
      "309/309 [==============================] - 0s 652us/step - loss: 0.2034 - acc: 0.0032 - val_loss: 0.2157 - val_acc: 0.0000e+00\n",
      "Epoch 71/250\n",
      "309/309 [==============================] - 0s 688us/step - loss: 0.2020 - acc: 0.0032 - val_loss: 0.2074 - val_acc: 0.0000e+00\n",
      "Epoch 72/250\n",
      "309/309 [==============================] - 0s 671us/step - loss: 0.2058 - acc: 0.0032 - val_loss: 0.1967 - val_acc: 0.0000e+00\n",
      "Epoch 73/250\n",
      "309/309 [==============================] - 0s 635us/step - loss: 0.2015 - acc: 0.0032 - val_loss: 0.2067 - val_acc: 0.0000e+00\n",
      "Epoch 74/250\n",
      "309/309 [==============================] - 0s 648us/step - loss: 0.1997 - acc: 0.0032 - val_loss: 0.2253 - val_acc: 0.0000e+00\n",
      "Epoch 75/250\n",
      "309/309 [==============================] - 0s 627us/step - loss: 0.2019 - acc: 0.0032 - val_loss: 0.2246 - val_acc: 0.0000e+00\n",
      "Epoch 76/250\n",
      "309/309 [==============================] - 0s 642us/step - loss: 0.2015 - acc: 0.0032 - val_loss: 0.2061 - val_acc: 0.0000e+00\n",
      "Epoch 77/250\n",
      "309/309 [==============================] - 0s 698us/step - loss: 0.1975 - acc: 0.0032 - val_loss: 0.1939 - val_acc: 0.0000e+00\n",
      "Epoch 78/250\n",
      "309/309 [==============================] - 0s 637us/step - loss: 0.1969 - acc: 0.0032 - val_loss: 0.1949 - val_acc: 0.0000e+00\n",
      "Epoch 79/250\n",
      "309/309 [==============================] - 0s 659us/step - loss: 0.1979 - acc: 0.0032 - val_loss: 0.2052 - val_acc: 0.0000e+00\n",
      "Epoch 80/250\n",
      "309/309 [==============================] - 0s 617us/step - loss: 0.1934 - acc: 0.0032 - val_loss: 0.2181 - val_acc: 0.0000e+00\n",
      "Epoch 81/250\n",
      "309/309 [==============================] - 0s 628us/step - loss: 0.1941 - acc: 0.0032 - val_loss: 0.2143 - val_acc: 0.0000e+00\n",
      "Epoch 82/250\n",
      "309/309 [==============================] - 0s 675us/step - loss: 0.1923 - acc: 0.0032 - val_loss: 0.2026 - val_acc: 0.0000e+00\n",
      "Epoch 83/250\n",
      "309/309 [==============================] - 0s 638us/step - loss: 0.1940 - acc: 0.0032 - val_loss: 0.1972 - val_acc: 0.0000e+00\n",
      "Epoch 84/250\n",
      "309/309 [==============================] - 0s 658us/step - loss: 0.1953 - acc: 0.0032 - val_loss: 0.2031 - val_acc: 0.0000e+00\n",
      "Epoch 85/250\n",
      "309/309 [==============================] - 0s 664us/step - loss: 0.1948 - acc: 0.0032 - val_loss: 0.2143 - val_acc: 0.0000e+00\n",
      "Epoch 86/250\n",
      "309/309 [==============================] - 0s 653us/step - loss: 0.1916 - acc: 0.0032 - val_loss: 0.2074 - val_acc: 0.0000e+00\n",
      "Epoch 87/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1905 - acc: 0.0032 - val_loss: 0.1941 - val_acc: 0.0000e+00\n",
      "Epoch 88/250\n",
      "309/309 [==============================] - 0s 646us/step - loss: 0.1907 - acc: 0.0032 - val_loss: 0.1921 - val_acc: 0.0000e+00\n",
      "Epoch 89/250\n",
      "309/309 [==============================] - 0s 633us/step - loss: 0.1903 - acc: 0.0032 - val_loss: 0.1997 - val_acc: 0.0000e+00\n",
      "Epoch 90/250\n",
      "309/309 [==============================] - 0s 654us/step - loss: 0.1862 - acc: 0.0032 - val_loss: 0.2011 - val_acc: 0.0000e+00\n",
      "Epoch 91/250\n",
      "309/309 [==============================] - 0s 631us/step - loss: 0.1876 - acc: 0.0032 - val_loss: 0.1907 - val_acc: 0.0000e+00\n",
      "Epoch 92/250\n",
      "309/309 [==============================] - 0s 628us/step - loss: 0.1880 - acc: 0.0032 - val_loss: 0.1798 - val_acc: 0.0000e+00\n",
      "Epoch 93/250\n",
      "309/309 [==============================] - 0s 667us/step - loss: 0.1859 - acc: 0.0032 - val_loss: 0.1837 - val_acc: 0.0000e+00\n",
      "Epoch 94/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.1871 - acc: 0.0032 - val_loss: 0.2018 - val_acc: 0.0000e+00\n",
      "Epoch 95/250\n",
      "309/309 [==============================] - 0s 659us/step - loss: 0.1854 - acc: 0.0032 - val_loss: 0.2021 - val_acc: 0.0000e+00\n",
      "Epoch 96/250\n",
      "309/309 [==============================] - 0s 634us/step - loss: 0.1825 - acc: 0.0032 - val_loss: 0.1840 - val_acc: 0.0000e+00\n",
      "Epoch 97/250\n",
      "309/309 [==============================] - 0s 648us/step - loss: 0.1856 - acc: 0.0032 - val_loss: 0.1816 - val_acc: 0.0000e+00\n",
      "Epoch 98/250\n",
      "309/309 [==============================] - 0s 605us/step - loss: 0.1861 - acc: 0.0032 - val_loss: 0.1935 - val_acc: 0.0000e+00\n",
      "Epoch 99/250\n",
      "309/309 [==============================] - 0s 670us/step - loss: 0.1842 - acc: 0.0032 - val_loss: 0.1954 - val_acc: 0.0000e+00\n",
      "Epoch 100/250\n",
      "309/309 [==============================] - 0s 618us/step - loss: 0.1834 - acc: 0.0032 - val_loss: 0.1926 - val_acc: 0.0000e+00\n",
      "Epoch 101/250\n",
      "309/309 [==============================] - 0s 667us/step - loss: 0.1808 - acc: 0.0032 - val_loss: 0.1780 - val_acc: 0.0000e+00\n",
      "Epoch 102/250\n",
      "309/309 [==============================] - 0s 635us/step - loss: 0.1862 - acc: 0.0032 - val_loss: 0.1860 - val_acc: 0.0000e+00\n",
      "Epoch 103/250\n",
      "309/309 [==============================] - 0s 648us/step - loss: 0.1807 - acc: 0.0032 - val_loss: 0.2245 - val_acc: 0.0000e+00\n",
      "Epoch 104/250\n",
      "309/309 [==============================] - 0s 606us/step - loss: 0.1856 - acc: 0.0032 - val_loss: 0.2058 - val_acc: 0.0000e+00\n",
      "Epoch 105/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.1786 - acc: 0.0032 - val_loss: 0.1788 - val_acc: 0.0000e+00\n",
      "Epoch 106/250\n",
      "309/309 [==============================] - 0s 651us/step - loss: 0.1800 - acc: 0.0032 - val_loss: 0.1789 - val_acc: 0.0000e+00\n",
      "Epoch 107/250\n",
      "309/309 [==============================] - 0s 617us/step - loss: 0.1822 - acc: 0.0032 - val_loss: 0.2039 - val_acc: 0.0000e+00\n",
      "Epoch 108/250\n",
      "309/309 [==============================] - 0s 669us/step - loss: 0.1786 - acc: 0.0032 - val_loss: 0.2077 - val_acc: 0.0000e+00\n",
      "Epoch 109/250\n",
      "309/309 [==============================] - 0s 613us/step - loss: 0.1745 - acc: 0.0032 - val_loss: 0.1964 - val_acc: 0.0000e+00\n",
      "Epoch 110/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.1831 - acc: 0.0032 - val_loss: 0.2025 - val_acc: 0.0000e+00\n",
      "Epoch 111/250\n",
      "309/309 [==============================] - 0s 613us/step - loss: 0.1747 - acc: 0.0032 - val_loss: 0.1864 - val_acc: 0.0000e+00\n",
      "Epoch 112/250\n",
      "309/309 [==============================] - 0s 636us/step - loss: 0.1749 - acc: 0.0032 - val_loss: 0.1930 - val_acc: 0.0000e+00\n",
      "Epoch 113/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1795 - acc: 0.0032 - val_loss: 0.2184 - val_acc: 0.0000e+00\n",
      "Epoch 114/250\n",
      "309/309 [==============================] - 0s 732us/step - loss: 0.1813 - acc: 0.0032 - val_loss: 0.1943 - val_acc: 0.0000e+00\n",
      "Epoch 115/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1664 - acc: 0.0032 - val_loss: 0.1847 - val_acc: 0.0000e+00\n",
      "Epoch 116/250\n",
      "309/309 [==============================] - 0s 651us/step - loss: 0.1751 - acc: 0.0032 - val_loss: 0.2080 - val_acc: 0.0000e+00\n",
      "Epoch 117/250\n",
      "309/309 [==============================] - 0s 666us/step - loss: 0.1743 - acc: 0.0032 - val_loss: 0.2239 - val_acc: 0.0000e+00\n",
      "Epoch 118/250\n",
      "309/309 [==============================] - 0s 617us/step - loss: 0.1779 - acc: 0.0032 - val_loss: 0.1836 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/250\n",
      "309/309 [==============================] - 0s 666us/step - loss: 0.1688 - acc: 0.0032 - val_loss: 0.1777 - val_acc: 0.0000e+00\n",
      "Epoch 120/250\n",
      "309/309 [==============================] - 0s 664us/step - loss: 0.1736 - acc: 0.0032 - val_loss: 0.1824 - val_acc: 0.0000e+00\n",
      "Epoch 121/250\n",
      "309/309 [==============================] - 0s 671us/step - loss: 0.1707 - acc: 0.0032 - val_loss: 0.2073 - val_acc: 0.0000e+00\n",
      "Epoch 122/250\n",
      "309/309 [==============================] - 0s 690us/step - loss: 0.1693 - acc: 0.0032 - val_loss: 0.2064 - val_acc: 0.0000e+00\n",
      "Epoch 123/250\n",
      "309/309 [==============================] - 0s 645us/step - loss: 0.1623 - acc: 0.0032 - val_loss: 0.2192 - val_acc: 0.0000e+00\n",
      "Epoch 124/250\n",
      "309/309 [==============================] - 0s 643us/step - loss: 0.1726 - acc: 0.0032 - val_loss: 0.2629 - val_acc: 0.0000e+00\n",
      "Epoch 125/250\n",
      "309/309 [==============================] - 0s 631us/step - loss: 0.1675 - acc: 0.0032 - val_loss: 0.2374 - val_acc: 0.0000e+00\n",
      "Epoch 126/250\n",
      "309/309 [==============================] - 0s 651us/step - loss: 0.1718 - acc: 0.0032 - val_loss: 0.1835 - val_acc: 0.0000e+00\n",
      "Epoch 127/250\n",
      "309/309 [==============================] - 0s 596us/step - loss: 0.1659 - acc: 0.0032 - val_loss: 0.1725 - val_acc: 0.0000e+00\n",
      "Epoch 128/250\n",
      "309/309 [==============================] - 0s 633us/step - loss: 0.1675 - acc: 0.0032 - val_loss: 0.1833 - val_acc: 0.0000e+00\n",
      "Epoch 129/250\n",
      "309/309 [==============================] - 0s 609us/step - loss: 0.1626 - acc: 0.0032 - val_loss: 0.1917 - val_acc: 0.0000e+00\n",
      "Epoch 130/250\n",
      "309/309 [==============================] - 0s 645us/step - loss: 0.1668 - acc: 0.0032 - val_loss: 0.1835 - val_acc: 0.0000e+00\n",
      "Epoch 131/250\n",
      "309/309 [==============================] - 0s 634us/step - loss: 0.1652 - acc: 0.0032 - val_loss: 0.1827 - val_acc: 0.0000e+00\n",
      "Epoch 132/250\n",
      "309/309 [==============================] - 0s 649us/step - loss: 0.1600 - acc: 0.0032 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 133/250\n",
      "309/309 [==============================] - 0s 610us/step - loss: 0.1691 - acc: 0.0032 - val_loss: 0.2003 - val_acc: 0.0000e+00\n",
      "Epoch 134/250\n",
      "309/309 [==============================] - 0s 611us/step - loss: 0.1597 - acc: 0.0032 - val_loss: 0.1911 - val_acc: 0.0000e+00\n",
      "Epoch 135/250\n",
      "309/309 [==============================] - 0s 676us/step - loss: 0.1594 - acc: 0.0032 - val_loss: 0.1994 - val_acc: 0.0000e+00\n",
      "Epoch 136/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1618 - acc: 0.0032 - val_loss: 0.1940 - val_acc: 0.0000e+00\n",
      "Epoch 137/250\n",
      "309/309 [==============================] - 0s 644us/step - loss: 0.1619 - acc: 0.0032 - val_loss: 0.1913 - val_acc: 0.0000e+00\n",
      "Epoch 138/250\n",
      "309/309 [==============================] - 0s 628us/step - loss: 0.1610 - acc: 0.0032 - val_loss: 0.2003 - val_acc: 0.0000e+00\n",
      "Epoch 139/250\n",
      "309/309 [==============================] - 0s 707us/step - loss: 0.1641 - acc: 0.0032 - val_loss: 0.2017 - val_acc: 0.0000e+00\n",
      "Epoch 140/250\n",
      "309/309 [==============================] - 0s 655us/step - loss: 0.1619 - acc: 0.0032 - val_loss: 0.1980 - val_acc: 0.0000e+00\n",
      "Epoch 141/250\n",
      "309/309 [==============================] - 0s 655us/step - loss: 0.1617 - acc: 0.0032 - val_loss: 0.1924 - val_acc: 0.0000e+00\n",
      "Epoch 142/250\n",
      "309/309 [==============================] - 0s 637us/step - loss: 0.1671 - acc: 0.0032 - val_loss: 0.2236 - val_acc: 0.0000e+00\n",
      "Epoch 143/250\n",
      "309/309 [==============================] - 0s 612us/step - loss: 0.1600 - acc: 0.0032 - val_loss: 0.2230 - val_acc: 0.0000e+00\n",
      "Epoch 144/250\n",
      "309/309 [==============================] - 0s 790us/step - loss: 0.1576 - acc: 0.0032 - val_loss: 0.1872 - val_acc: 0.0000e+00\n",
      "Epoch 145/250\n",
      "309/309 [==============================] - 0s 638us/step - loss: 0.1662 - acc: 0.0032 - val_loss: 0.1865 - val_acc: 0.0000e+00\n",
      "Epoch 146/250\n",
      "309/309 [==============================] - 0s 604us/step - loss: 0.1669 - acc: 0.0032 - val_loss: 0.2179 - val_acc: 0.0000e+00\n",
      "Epoch 147/250\n",
      "309/309 [==============================] - 0s 637us/step - loss: 0.1601 - acc: 0.0032 - val_loss: 0.2197 - val_acc: 0.0000e+00\n",
      "Epoch 148/250\n",
      "309/309 [==============================] - 0s 621us/step - loss: 0.1587 - acc: 0.0032 - val_loss: 0.2138 - val_acc: 0.0000e+00\n",
      "Epoch 149/250\n",
      "309/309 [==============================] - 0s 661us/step - loss: 0.1583 - acc: 0.0032 - val_loss: 0.2229 - val_acc: 0.0000e+00\n",
      "Epoch 150/250\n",
      "309/309 [==============================] - 0s 665us/step - loss: 0.1592 - acc: 0.0032 - val_loss: 0.2040 - val_acc: 0.0000e+00\n",
      "Epoch 151/250\n",
      "309/309 [==============================] - 0s 629us/step - loss: 0.1543 - acc: 0.0032 - val_loss: 0.1979 - val_acc: 0.0000e+00\n",
      "Epoch 152/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1500 - acc: 0.0032 - val_loss: 0.1923 - val_acc: 0.0000e+00\n",
      "Epoch 153/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1496 - acc: 0.0032 - val_loss: 0.1987 - val_acc: 0.0000e+00\n",
      "Epoch 154/250\n",
      "309/309 [==============================] - 0s 629us/step - loss: 0.1528 - acc: 0.0032 - val_loss: 0.2534 - val_acc: 0.0000e+00\n",
      "Epoch 155/250\n",
      "309/309 [==============================] - 0s 642us/step - loss: 0.1554 - acc: 0.0032 - val_loss: 0.2445 - val_acc: 0.0000e+00\n",
      "Epoch 156/250\n",
      "309/309 [==============================] - 0s 712us/step - loss: 0.1636 - acc: 0.0032 - val_loss: 0.2034 - val_acc: 0.0000e+00\n",
      "Epoch 157/250\n",
      "309/309 [==============================] - 0s 629us/step - loss: 0.1514 - acc: 0.0032 - val_loss: 0.1996 - val_acc: 0.0000e+00\n",
      "Epoch 158/250\n",
      "309/309 [==============================] - 0s 689us/step - loss: 0.1493 - acc: 0.0032 - val_loss: 0.2105 - val_acc: 0.0000e+00\n",
      "Epoch 159/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1511 - acc: 0.0032 - val_loss: 0.1932 - val_acc: 0.0000e+00\n",
      "Epoch 160/250\n",
      "309/309 [==============================] - 0s 633us/step - loss: 0.1513 - acc: 0.0032 - val_loss: 0.1995 - val_acc: 0.0000e+00\n",
      "Epoch 161/250\n",
      "309/309 [==============================] - 0s 655us/step - loss: 0.1550 - acc: 0.0032 - val_loss: 0.2284 - val_acc: 0.0000e+00\n",
      "Epoch 162/250\n",
      "309/309 [==============================] - 0s 637us/step - loss: 0.1439 - acc: 0.0032 - val_loss: 0.2448 - val_acc: 0.0000e+00\n",
      "Epoch 163/250\n",
      "309/309 [==============================] - 0s 700us/step - loss: 0.1452 - acc: 0.0032 - val_loss: 0.2333 - val_acc: 0.0000e+00\n",
      "Epoch 164/250\n",
      "309/309 [==============================] - 0s 579us/step - loss: 0.1467 - acc: 0.0032 - val_loss: 0.1965 - val_acc: 0.0000e+00\n",
      "Epoch 165/250\n",
      "309/309 [==============================] - 0s 648us/step - loss: 0.1587 - acc: 0.0032 - val_loss: 0.2038 - val_acc: 0.0000e+00\n",
      "Epoch 166/250\n",
      "309/309 [==============================] - 0s 610us/step - loss: 0.1502 - acc: 0.0032 - val_loss: 0.2332 - val_acc: 0.0000e+00\n",
      "Epoch 167/250\n",
      "309/309 [==============================] - 0s 673us/step - loss: 0.1604 - acc: 0.0032 - val_loss: 0.2107 - val_acc: 0.0000e+00\n",
      "Epoch 168/250\n",
      "309/309 [==============================] - 0s 661us/step - loss: 0.1523 - acc: 0.0032 - val_loss: 0.1922 - val_acc: 0.0000e+00\n",
      "Epoch 169/250\n",
      "309/309 [==============================] - 0s 666us/step - loss: 0.1500 - acc: 0.0032 - val_loss: 0.2060 - val_acc: 0.0000e+00\n",
      "Epoch 170/250\n",
      "309/309 [==============================] - 0s 625us/step - loss: 0.1489 - acc: 0.0032 - val_loss: 0.2346 - val_acc: 0.0000e+00\n",
      "Epoch 171/250\n",
      "309/309 [==============================] - 0s 646us/step - loss: 0.1450 - acc: 0.0032 - val_loss: 0.2574 - val_acc: 0.0000e+00\n",
      "Epoch 172/250\n",
      "309/309 [==============================] - 0s 708us/step - loss: 0.1513 - acc: 0.0032 - val_loss: 0.2695 - val_acc: 0.0000e+00\n",
      "Epoch 173/250\n",
      "309/309 [==============================] - 0s 748us/step - loss: 0.1552 - acc: 0.0032 - val_loss: 0.2894 - val_acc: 0.0000e+00\n",
      "Epoch 174/250\n",
      "309/309 [==============================] - 0s 721us/step - loss: 0.1473 - acc: 0.0032 - val_loss: 0.2474 - val_acc: 0.0000e+00\n",
      "Epoch 175/250\n",
      "309/309 [==============================] - 0s 600us/step - loss: 0.1471 - acc: 0.0032 - val_loss: 0.1973 - val_acc: 0.0000e+00\n",
      "Epoch 176/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.1537 - acc: 0.0032 - val_loss: 0.1782 - val_acc: 0.0000e+00\n",
      "Epoch 177/250\n",
      "309/309 [==============================] - 0s 660us/step - loss: 0.1506 - acc: 0.0032 - val_loss: 0.2020 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/250\n",
      "309/309 [==============================] - 0s 601us/step - loss: 0.1427 - acc: 0.0032 - val_loss: 0.2863 - val_acc: 0.0000e+00\n",
      "Epoch 179/250\n",
      "309/309 [==============================] - 0s 743us/step - loss: 0.1583 - acc: 0.0032 - val_loss: 0.2818 - val_acc: 0.0000e+00\n",
      "Epoch 180/250\n",
      "309/309 [==============================] - 0s 628us/step - loss: 0.1493 - acc: 0.0032 - val_loss: 0.2223 - val_acc: 0.0000e+00\n",
      "Epoch 181/250\n",
      "309/309 [==============================] - 0s 734us/step - loss: 0.1453 - acc: 0.0032 - val_loss: 0.2034 - val_acc: 0.0000e+00\n",
      "Epoch 182/250\n",
      "309/309 [==============================] - 0s 887us/step - loss: 0.1414 - acc: 0.0032 - val_loss: 0.2060 - val_acc: 0.0000e+00\n",
      "Epoch 183/250\n",
      "309/309 [==============================] - 0s 613us/step - loss: 0.1481 - acc: 0.0032 - val_loss: 0.2047 - val_acc: 0.0000e+00\n",
      "Epoch 184/250\n",
      "309/309 [==============================] - 0s 670us/step - loss: 0.1365 - acc: 0.0032 - val_loss: 0.2509 - val_acc: 0.0000e+00\n",
      "Epoch 185/250\n",
      "309/309 [==============================] - 0s 642us/step - loss: 0.1449 - acc: 0.0032 - val_loss: 0.2999 - val_acc: 0.0000e+00\n",
      "Epoch 186/250\n",
      "309/309 [==============================] - 0s 647us/step - loss: 0.1515 - acc: 0.0032 - val_loss: 0.3013 - val_acc: 0.0000e+00\n",
      "Epoch 187/250\n",
      "309/309 [==============================] - 0s 601us/step - loss: 0.1482 - acc: 0.0032 - val_loss: 0.2460 - val_acc: 0.0000e+00\n",
      "Epoch 188/250\n",
      "309/309 [==============================] - 0s 595us/step - loss: 0.1424 - acc: 0.0032 - val_loss: 0.2288 - val_acc: 0.0000e+00\n",
      "Epoch 189/250\n",
      "309/309 [==============================] - 0s 663us/step - loss: 0.1437 - acc: 0.0032 - val_loss: 0.2355 - val_acc: 0.0000e+00\n",
      "Epoch 190/250\n",
      "309/309 [==============================] - 0s 638us/step - loss: 0.1479 - acc: 0.0032 - val_loss: 0.2270 - val_acc: 0.0000e+00\n",
      "Epoch 191/250\n",
      "309/309 [==============================] - 0s 645us/step - loss: 0.1429 - acc: 0.0032 - val_loss: 0.2391 - val_acc: 0.0000e+00\n",
      "Epoch 192/250\n",
      "309/309 [==============================] - 0s 664us/step - loss: 0.1443 - acc: 0.0032 - val_loss: 0.2624 - val_acc: 0.0000e+00\n",
      "Epoch 193/250\n",
      "309/309 [==============================] - 0s 665us/step - loss: 0.1487 - acc: 0.0032 - val_loss: 0.2652 - val_acc: 0.0000e+00\n",
      "Epoch 194/250\n",
      "309/309 [==============================] - 0s 629us/step - loss: 0.1414 - acc: 0.0032 - val_loss: 0.2415 - val_acc: 0.0000e+00\n",
      "Epoch 195/250\n",
      "309/309 [==============================] - 0s 647us/step - loss: 0.1388 - acc: 0.0032 - val_loss: 0.2151 - val_acc: 0.0000e+00\n",
      "Epoch 196/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1405 - acc: 0.0032 - val_loss: 0.2107 - val_acc: 0.0000e+00\n",
      "Epoch 197/250\n",
      "309/309 [==============================] - 0s 657us/step - loss: 0.1391 - acc: 0.0032 - val_loss: 0.2166 - val_acc: 0.0000e+00\n",
      "Epoch 198/250\n",
      "309/309 [==============================] - 0s 622us/step - loss: 0.1442 - acc: 0.0032 - val_loss: 0.2457 - val_acc: 0.0000e+00\n",
      "Epoch 199/250\n",
      "309/309 [==============================] - 0s 629us/step - loss: 0.1386 - acc: 0.0032 - val_loss: 0.2440 - val_acc: 0.0000e+00\n",
      "Epoch 200/250\n",
      "309/309 [==============================] - 0s 641us/step - loss: 0.1380 - acc: 0.0032 - val_loss: 0.2402 - val_acc: 0.0000e+00\n",
      "Epoch 201/250\n",
      "309/309 [==============================] - 0s 639us/step - loss: 0.1410 - acc: 0.0032 - val_loss: 0.2183 - val_acc: 0.0000e+00\n",
      "Epoch 202/250\n",
      "309/309 [==============================] - 0s 750us/step - loss: 0.1371 - acc: 0.0032 - val_loss: 0.2159 - val_acc: 0.0000e+00\n",
      "Epoch 203/250\n",
      "309/309 [==============================] - 0s 692us/step - loss: 0.1461 - acc: 0.0032 - val_loss: 0.2454 - val_acc: 0.0000e+00\n",
      "Epoch 204/250\n",
      "309/309 [==============================] - 0s 639us/step - loss: 0.1386 - acc: 0.0032 - val_loss: 0.2442 - val_acc: 0.0000e+00\n",
      "Epoch 205/250\n",
      "309/309 [==============================] - 0s 648us/step - loss: 0.1412 - acc: 0.0032 - val_loss: 0.2551 - val_acc: 0.0000e+00\n",
      "Epoch 206/250\n",
      "309/309 [==============================] - 0s 619us/step - loss: 0.1400 - acc: 0.0032 - val_loss: 0.2481 - val_acc: 0.0000e+00\n",
      "Epoch 207/250\n",
      "309/309 [==============================] - 0s 651us/step - loss: 0.1392 - acc: 0.0032 - val_loss: 0.2170 - val_acc: 0.0000e+00\n",
      "Epoch 208/250\n",
      "309/309 [==============================] - 0s 611us/step - loss: 0.1385 - acc: 0.0032 - val_loss: 0.2269 - val_acc: 0.0000e+00\n",
      "Epoch 209/250\n",
      "309/309 [==============================] - 0s 667us/step - loss: 0.1431 - acc: 0.0032 - val_loss: 0.2374 - val_acc: 0.0000e+00\n",
      "Epoch 210/250\n",
      "309/309 [==============================] - 0s 609us/step - loss: 0.1367 - acc: 0.0032 - val_loss: 0.2375 - val_acc: 0.0000e+00\n",
      "Epoch 211/250\n",
      "309/309 [==============================] - 0s 652us/step - loss: 0.1377 - acc: 0.0032 - val_loss: 0.2490 - val_acc: 0.0000e+00\n",
      "Epoch 212/250\n",
      "309/309 [==============================] - 0s 630us/step - loss: 0.1401 - acc: 0.0032 - val_loss: 0.2666 - val_acc: 0.0000e+00\n",
      "Epoch 213/250\n",
      "309/309 [==============================] - 0s 689us/step - loss: 0.1364 - acc: 0.0032 - val_loss: 0.2597 - val_acc: 0.0000e+00\n",
      "Epoch 214/250\n",
      "309/309 [==============================] - 0s 674us/step - loss: 0.1338 - acc: 0.0032 - val_loss: 0.2474 - val_acc: 0.0000e+00\n",
      "Epoch 215/250\n",
      "309/309 [==============================] - 0s 770us/step - loss: 0.1348 - acc: 0.0032 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
      "Epoch 216/250\n",
      "309/309 [==============================] - 0s 642us/step - loss: 0.1341 - acc: 0.0032 - val_loss: 0.2518 - val_acc: 0.0000e+00\n",
      "Epoch 217/250\n",
      "309/309 [==============================] - 0s 632us/step - loss: 0.1335 - acc: 0.0032 - val_loss: 0.2644 - val_acc: 0.0000e+00\n",
      "Epoch 218/250\n",
      "309/309 [==============================] - 0s 640us/step - loss: 0.1378 - acc: 0.0032 - val_loss: 0.2772 - val_acc: 0.0000e+00\n",
      "Epoch 219/250\n",
      "309/309 [==============================] - 0s 621us/step - loss: 0.1341 - acc: 0.0032 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 220/250\n",
      "309/309 [==============================] - 0s 650us/step - loss: 0.1391 - acc: 0.0032 - val_loss: 0.2945 - val_acc: 0.0000e+00\n",
      "Epoch 221/250\n",
      "309/309 [==============================] - 0s 651us/step - loss: 0.1423 - acc: 0.0032 - val_loss: 0.2617 - val_acc: 0.0000e+00\n",
      "Epoch 222/250\n",
      "309/309 [==============================] - 0s 715us/step - loss: 0.1363 - acc: 0.0032 - val_loss: 0.2301 - val_acc: 0.0000e+00\n",
      "Epoch 223/250\n",
      "309/309 [==============================] - 0s 663us/step - loss: 0.1322 - acc: 0.0032 - val_loss: 0.2214 - val_acc: 0.0000e+00\n",
      "Epoch 224/250\n",
      "309/309 [==============================] - 0s 620us/step - loss: 0.1378 - acc: 0.0032 - val_loss: 0.2219 - val_acc: 0.0000e+00\n",
      "Epoch 225/250\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.1338 - acc: 0.0032 - val_loss: 0.2658 - val_acc: 0.0000e+00\n",
      "Epoch 226/250\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.1340 - acc: 0.0032 - val_loss: 0.2729 - val_acc: 0.0000e+00\n",
      "Epoch 227/250\n",
      "309/309 [==============================] - 0s 881us/step - loss: 0.1378 - acc: 0.0032 - val_loss: 0.2515 - val_acc: 0.0000e+00\n",
      "Epoch 228/250\n",
      "309/309 [==============================] - 0s 702us/step - loss: 0.1387 - acc: 0.0032 - val_loss: 0.2489 - val_acc: 0.0000e+00\n",
      "Epoch 229/250\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.1350 - acc: 0.0032 - val_loss: 0.2664 - val_acc: 0.0000e+00\n",
      "Epoch 230/250\n",
      "309/309 [==============================] - 0s 803us/step - loss: 0.1393 - acc: 0.0032 - val_loss: 0.2658 - val_acc: 0.0000e+00\n",
      "Epoch 231/250\n",
      "309/309 [==============================] - 0s 869us/step - loss: 0.1341 - acc: 0.0032 - val_loss: 0.2806 - val_acc: 0.0000e+00\n",
      "Epoch 232/250\n",
      "309/309 [==============================] - 0s 772us/step - loss: 0.1345 - acc: 0.0032 - val_loss: 0.3352 - val_acc: 0.0000e+00\n",
      "Epoch 233/250\n",
      "309/309 [==============================] - 0s 802us/step - loss: 0.1311 - acc: 0.0032 - val_loss: 0.3575 - val_acc: 0.0000e+00\n",
      "Epoch 234/250\n",
      "309/309 [==============================] - 0s 874us/step - loss: 0.1359 - acc: 0.0032 - val_loss: 0.2837 - val_acc: 0.0000e+00\n",
      "Epoch 235/250\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.1304 - acc: 0.0032 - val_loss: 0.2402 - val_acc: 0.0000e+00\n",
      "Epoch 236/250\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.1334 - acc: 0.0032 - val_loss: 0.2191 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/250\n",
      "309/309 [==============================] - 0s 943us/step - loss: 0.1374 - acc: 0.0032 - val_loss: 0.2480 - val_acc: 0.0000e+00\n",
      "Epoch 238/250\n",
      "309/309 [==============================] - 0s 769us/step - loss: 0.1303 - acc: 0.0032 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 239/250\n",
      "309/309 [==============================] - 0s 863us/step - loss: 0.1372 - acc: 0.0032 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 240/250\n",
      "309/309 [==============================] - 0s 719us/step - loss: 0.1384 - acc: 0.0032 - val_loss: 0.2679 - val_acc: 0.0000e+00\n",
      "Epoch 241/250\n",
      "309/309 [==============================] - 0s 788us/step - loss: 0.1397 - acc: 0.0032 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 242/250\n",
      "309/309 [==============================] - 0s 794us/step - loss: 0.1265 - acc: 0.0032 - val_loss: 0.2715 - val_acc: 0.0000e+00\n",
      "Epoch 243/250\n",
      "309/309 [==============================] - 0s 682us/step - loss: 0.1350 - acc: 0.0032 - val_loss: 0.2462 - val_acc: 0.0000e+00\n",
      "Epoch 244/250\n",
      "309/309 [==============================] - 0s 814us/step - loss: 0.1286 - acc: 0.0032 - val_loss: 0.2509 - val_acc: 0.0000e+00\n",
      "Epoch 245/250\n",
      "309/309 [==============================] - 0s 720us/step - loss: 0.1414 - acc: 0.0032 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 246/250\n",
      "309/309 [==============================] - 0s 767us/step - loss: 0.1321 - acc: 0.0032 - val_loss: 0.3738 - val_acc: 0.0000e+00\n",
      "Epoch 247/250\n",
      "309/309 [==============================] - 0s 789us/step - loss: 0.1335 - acc: 0.0032 - val_loss: 0.3430 - val_acc: 0.0000e+00\n",
      "Epoch 248/250\n",
      "309/309 [==============================] - 0s 723us/step - loss: 0.1327 - acc: 0.0032 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 249/250\n",
      "309/309 [==============================] - 0s 831us/step - loss: 0.1359 - acc: 0.0032 - val_loss: 0.2557 - val_acc: 0.0000e+00\n",
      "Epoch 250/250\n",
      "309/309 [==============================] - 0s 799us/step - loss: 0.1301 - acc: 0.0032 - val_loss: 0.2566 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88b08f0320>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = build_model([3,lag,1])\n",
    "#model = build_model2([3,window,1])\n",
    "model = build_model2([len(df_val[0])-1,5,1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=576,\n",
    "    epochs=250,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 0s 920us/step\n",
      "Train Score: 0.14 MSE (0.37 RMSE)\n",
      "[[[ 0.254       0.249       0.252       0.252      39.183\n",
      "    0.24137633]\n",
      "  [ 0.256       0.248       0.256       0.25089999 25.495\n",
      "    0.2465565 ]\n",
      "  [ 0.25595     0.253       0.253       0.254      26.239\n",
      "    0.24356793]\n",
      "  [ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]]\n",
      "\n",
      " [[ 0.256       0.248       0.256       0.25089999 25.495\n",
      "    0.2465565 ]\n",
      "  [ 0.25595     0.253       0.253       0.254      26.239\n",
      "    0.24356793]\n",
      "  [ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]]\n",
      "\n",
      " [[ 0.25595     0.253       0.253       0.254      26.239\n",
      "    0.24356793]\n",
      "  [ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]]\n",
      "\n",
      " [[ 0.2585      0.25205     0.2585      0.253       9.733\n",
      "    0.23808891]\n",
      "  [ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]]\n",
      "\n",
      " [[ 0.263       0.253       0.253       0.2585     17.803\n",
      "    0.24700479]\n",
      "  [ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]]\n",
      "\n",
      " [[ 0.25689999  0.251       0.25689999  0.25539999 12.527\n",
      "    0.25103935]\n",
      "  [ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]]\n",
      "\n",
      " [[ 0.26789999  0.257       0.26789999  0.25770001 35.862\n",
      "    0.24994356]\n",
      "  [ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]]\n",
      "\n",
      " [[ 0.26820001  0.26260001  0.26695001  0.267      33.888\n",
      "    0.25303172]\n",
      "  [ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]]\n",
      "\n",
      " [[ 0.26920001  0.26354999  0.26920001  0.267      39.602\n",
      "    0.25203554]\n",
      "  [ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]]\n",
      "\n",
      " [[ 0.265       0.26        0.2645      0.261      17.853\n",
      "    0.25751462]\n",
      "  [ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]]\n",
      "\n",
      " [[ 0.26525     0.259       0.2615      0.264      28.015\n",
      "    0.25442639]\n",
      "  [ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]]\n",
      "\n",
      " [[ 0.26695001  0.26114999  0.266       0.262      15.064\n",
      "    0.25671765]\n",
      "  [ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]]\n",
      "\n",
      " [[ 0.266       0.26310001  0.26425     0.265      17.396\n",
      "    0.26598218]\n",
      "  [ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]]\n",
      "\n",
      " [[ 0.26720001  0.264       0.26720001  0.266      14.868\n",
      "    0.26598218]\n",
      "  [ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]]\n",
      "\n",
      " [[ 0.26889999  0.265       0.2665      0.26714999 12.141\n",
      "    0.26000507]\n",
      "  [ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]]\n",
      "\n",
      " [[ 0.26904999  0.26575     0.26579999  0.2665     55.597\n",
      "    0.26299362]\n",
      "  [ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]]\n",
      "\n",
      " [[ 0.26860001  0.265       0.26604999  0.26575    33.121\n",
      "    0.26100122]\n",
      "  [ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]]\n",
      "\n",
      " [[ 0.268       0.26054999  0.268       0.26545001 41.839\n",
      "    0.26398981]\n",
      "  [ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]]\n",
      "\n",
      " [[ 0.272       0.268       0.2715      0.271      29.736\n",
      "    0.26498599]\n",
      "  [ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]]\n",
      "\n",
      " [[ 0.274       0.27        0.274       0.271      43.966\n",
      "    0.26613159]\n",
      "  [ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]]\n",
      "\n",
      " [[ 0.27629999  0.27139999  0.276       0.275      42.158\n",
      "    0.26548404]\n",
      "  [ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]]\n",
      "\n",
      " [[ 0.28        0.273       0.27704999  0.276      45.931\n",
      "    0.26473694]\n",
      "  [ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]]\n",
      "\n",
      " [[ 0.28        0.273       0.27845001  0.278      22.846\n",
      "    0.26443808]\n",
      "  [ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]]\n",
      "\n",
      " [[ 0.279       0.274       0.276       0.27679999 59.641\n",
      "    0.26996695]\n",
      "  [ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]]\n",
      "\n",
      " [[ 0.287       0.27504999  0.287       0.27675    59.924\n",
      "    0.26996695]\n",
      "  [ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]]\n",
      "\n",
      " [[ 0.29239999  0.2875      0.29239999  0.28845001 12.32\n",
      "    0.27395166]\n",
      "  [ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]]\n",
      "\n",
      " [[ 0.297       0.292       0.296       0.29239999 19.862\n",
      "    0.27494781]\n",
      "  [ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]]\n",
      "\n",
      " [[ 0.298       0.291       0.293       0.295      73.167\n",
      "    0.27694022]\n",
      "  [ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]\n",
      "  [ 0.28895001  0.2855      0.28639999  0.286      22.531\n",
      "    0.29128537]]\n",
      "\n",
      " [[ 0.292       0.28510001  0.2885      0.292      49.43\n",
      "    0.27574478]\n",
      "  [ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]\n",
      "  [ 0.28895001  0.2855      0.28639999  0.286      22.531\n",
      "    0.29128537]\n",
      "  [ 0.28895001  0.28        0.28320001  0.2865     23.484\n",
      "    0.29387543]]\n",
      "\n",
      " [[ 0.29395001  0.286       0.291       0.287      38.158\n",
      "    0.27569501]\n",
      "  [ 0.2905      0.28639999  0.28639999  0.29       35.837\n",
      "    0.2873504 ]\n",
      "  [ 0.28895001  0.2855      0.28639999  0.286      22.531\n",
      "    0.29128537]\n",
      "  [ 0.28895001  0.28        0.28320001  0.2865     23.484\n",
      "    0.29387543]\n",
      "  [ 0.28460001  0.28        0.2845      0.283      15.736\n",
      "    0.29088684]]]\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "print (X_test)\n",
    "\n",
    "#testScore = model.evaluate(X_test, y_test, verbose=1)\n",
    "#print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29395001  0.286       0.291       0.287      38.158       0.27569501]\n",
      " [ 0.2905      0.28639999  0.28639999  0.29       35.837       0.2873504 ]\n",
      " [ 0.28895001  0.2855      0.28639999  0.286      22.531       0.29128537]\n",
      " [ 0.28895001  0.28        0.28320001  0.2865     23.484       0.29387543]\n",
      " [ 0.28460001  0.28        0.2845      0.283      15.736       0.29088684]]\n",
      "pred [[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.12679464]\n",
      " [0.08343387]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.06557583]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.0011571 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "print (\"pred\",p)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    #print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot((p * 1000 ) ,color='red', label='prediction')\n",
    "plt2.plot(y_test * 1000,color='blue', label='y_test')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_last(stock_name, seq_len, window ):\n",
    "    from pandas_datareader import data\n",
    "\n",
    "    # Only get the adjusted close.\n",
    "    df = data.DataReader(stock_name,\n",
    "                       start='2016-1-1',\n",
    "                       end='2018-09-03',\n",
    "                       data_source='yahoo')\n",
    "\n",
    "    \n",
    "\n",
    "    df = df[-10:-1]\n",
    "    data_x = df\n",
    "    \n",
    "    #print(\"DATA Y 0 :\",data_y)\n",
    "    data_x = data_x.values / 1000\n",
    "    print(\"data_x input:\",data_x)\n",
    "    data_x = np.delete(data_x,np.s_[len(data_x[0])-1],axis=1)\n",
    "    \n",
    "    #print(\"DATA Y :\",data_y)\n",
    "    amount_of_features = len(data_x[0]) \n",
    "    \n",
    "    sequence_length = seq_len \n",
    "    result_x = []\n",
    "\n",
    "    for index in range(len(data_x) - sequence_length ):\n",
    "        result_x.append(data_x[index: index + sequence_length + 1])\n",
    "\n",
    "    x_train = np.array(result_x)\n",
    "    x_train = x_train[:, :-1] \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features ))\n",
    "    \n",
    "    print (\"x_train:\",x_train)\n",
    "  \n",
    "    return [x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x input: [[ 0.516       0.505       0.515       0.51359998 29.859       0.51359998]\n",
      " [ 0.523       0.513       0.515       0.52215002 29.058       0.52215002]\n",
      " [ 0.53884998  0.52504999  0.52504999  0.53370001 84.355       0.53370001]\n",
      " [ 0.553       0.53        0.53        0.54779999 47.823       0.54779999]\n",
      " [ 0.556       0.54415002  0.55        0.55315002 34.555       0.55315002]\n",
      " [ 0.60495001  0.55        0.553       0.60029999 58.823       0.60029999]\n",
      " [ 0.681       0.595       0.595       0.64995001 70.135       0.64995001]\n",
      " [ 0.652       0.61704999  0.64995001  0.62465002 54.83        0.62465002]\n",
      " [ 0.675       0.62        0.625       0.62184998 31.015       0.62184998]]\n",
      "x_train: [[[ 0.516       0.505       0.515       0.51359998 29.859     ]\n",
      "  [ 0.523       0.513       0.515       0.52215002 29.058     ]\n",
      "  [ 0.53884998  0.52504999  0.52504999  0.53370001 84.355     ]\n",
      "  [ 0.553       0.53        0.53        0.54779999 47.823     ]\n",
      "  [ 0.556       0.54415002  0.55        0.55315002 34.555     ]]\n",
      "\n",
      " [[ 0.523       0.513       0.515       0.52215002 29.058     ]\n",
      "  [ 0.53884998  0.52504999  0.52504999  0.53370001 84.355     ]\n",
      "  [ 0.553       0.53        0.53        0.54779999 47.823     ]\n",
      "  [ 0.556       0.54415002  0.55        0.55315002 34.555     ]\n",
      "  [ 0.60495001  0.55        0.553       0.60029999 58.823     ]]\n",
      "\n",
      " [[ 0.53884998  0.52504999  0.52504999  0.53370001 84.355     ]\n",
      "  [ 0.553       0.53        0.53        0.54779999 47.823     ]\n",
      "  [ 0.556       0.54415002  0.55        0.55315002 34.555     ]\n",
      "  [ 0.60495001  0.55        0.553       0.60029999 58.823     ]\n",
      "  [ 0.681       0.595       0.595       0.64995001 70.135     ]]\n",
      "\n",
      " [[ 0.553       0.53        0.53        0.54779999 47.823     ]\n",
      "  [ 0.556       0.54415002  0.55        0.55315002 34.555     ]\n",
      "  [ 0.60495001  0.55        0.553       0.60029999 58.823     ]\n",
      "  [ 0.681       0.595       0.595       0.64995001 70.135     ]\n",
      "  [ 0.652       0.61704999  0.64995001  0.62465002 54.83      ]]]\n",
      "[array([[[ 0.516     ,  0.505     ,  0.515     ,  0.51359998,\n",
      "         29.859     ],\n",
      "        [ 0.523     ,  0.513     ,  0.515     ,  0.52215002,\n",
      "         29.058     ],\n",
      "        [ 0.53884998,  0.52504999,  0.52504999,  0.53370001,\n",
      "         84.355     ],\n",
      "        [ 0.553     ,  0.53      ,  0.53      ,  0.54779999,\n",
      "         47.823     ],\n",
      "        [ 0.556     ,  0.54415002,  0.55      ,  0.55315002,\n",
      "         34.555     ]],\n",
      "\n",
      "       [[ 0.523     ,  0.513     ,  0.515     ,  0.52215002,\n",
      "         29.058     ],\n",
      "        [ 0.53884998,  0.52504999,  0.52504999,  0.53370001,\n",
      "         84.355     ],\n",
      "        [ 0.553     ,  0.53      ,  0.53      ,  0.54779999,\n",
      "         47.823     ],\n",
      "        [ 0.556     ,  0.54415002,  0.55      ,  0.55315002,\n",
      "         34.555     ],\n",
      "        [ 0.60495001,  0.55      ,  0.553     ,  0.60029999,\n",
      "         58.823     ]],\n",
      "\n",
      "       [[ 0.53884998,  0.52504999,  0.52504999,  0.53370001,\n",
      "         84.355     ],\n",
      "        [ 0.553     ,  0.53      ,  0.53      ,  0.54779999,\n",
      "         47.823     ],\n",
      "        [ 0.556     ,  0.54415002,  0.55      ,  0.55315002,\n",
      "         34.555     ],\n",
      "        [ 0.60495001,  0.55      ,  0.553     ,  0.60029999,\n",
      "         58.823     ],\n",
      "        [ 0.681     ,  0.595     ,  0.595     ,  0.64995001,\n",
      "         70.135     ]],\n",
      "\n",
      "       [[ 0.553     ,  0.53      ,  0.53      ,  0.54779999,\n",
      "         47.823     ],\n",
      "        [ 0.556     ,  0.54415002,  0.55      ,  0.55315002,\n",
      "         34.555     ],\n",
      "        [ 0.60495001,  0.55      ,  0.553     ,  0.60029999,\n",
      "         58.823     ],\n",
      "        [ 0.681     ,  0.595     ,  0.595     ,  0.64995001,\n",
      "         70.135     ],\n",
      "        [ 0.652     ,  0.61704999,  0.64995001,  0.62465002,\n",
      "         54.83      ]]])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_13_input to have shape (5, 6) but got array with shape (5, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-ce88ec0bc76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luch/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luch/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luch/.local/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_13_input to have shape (5, 6) but got array with shape (5, 5)"
     ]
    }
   ],
   "source": [
    "df_new = load_data_last ('TS.BA', 5, 10 )\n",
    "\n",
    "window  =  5\n",
    "\n",
    "print(df_new)\n",
    "pred = model.predict(df_new) \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
